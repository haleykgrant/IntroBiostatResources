{
  "hash": "508db4676769ae7215af4506db8fb6ca",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Bootstrapping\"\nauthor: \"Haley Grant\"\nformat: \n  html:\n    toc: true\n    toc-location: left\nengine: knitr\nfilters: \n  - webr\nwebr:\n  packages: ['tidyverse']\n  autoload-packages: false\ncategories:\n    - Bootstrapping\n    - Statistical Inference\ntitle-block-banner: \"#FC8888\"\n---\n\n\n## Introduction\n\nThe purpose of this recitation is to demonstrate the concept of bootstrapping and show how it relates to the concept of a sampling distribution.\n\n```{webr-r}\n#| context: setup\nlibrary(tidyverse)\n```\n\n# The Population\n\nFirst, let's consider a Poisson distribution with a rate of lambda = 2.5\n\nTo see what the distribution looks like we could plot the exact value of the probability mass function, or we could just simulate a very large number of draws from the distribution.\n\n## Create data set with populaiton\n\nFill in the following code with the appropriate parameters so that 'pop' is a sample of size 10000 drawn from a Poisson distribution with lambda = 2.5. We will treat this as our population for the remainder of the exercise.\n\n```{webr-r}\nset.seed(123) # set seed for consistent results\n\n# draw a sample of size 10,000 from Poisson(2.5)\npop <- data.frame(x = rpois(n = , lambda = ) )\n\n\n```\n\n::: {.callout-tip collapse=\"true\" icon=\"false\"}\n## Solution\n\n```{webr-r}\n#| autorun: true\n\nset.seed(123) # set seed for consistent results\n\n# draw a sample of size 10,000 from Poisson(2.5)\npop <- data.frame(x = rpois(n = 10000 , lambda = 2.5) )\n\n\n```\n:::\n\n## Plot the Population\n\nMake a plot of the simulated data to display the population distribution. *Hint: think about the type of variable this is (quantitative/qualitative) and the types of plots that are used for this type of variable.*\n\n```{webr-r}\n# make a plot of simulated data\n\n\n\n```\n\n::: {.callout-tip collapse=\"true\" icon=\"false\"}\n## Solution\n\n```{webr-r}\n# make histogram\npop %>%\n  ggplot(aes(x = x)) + \n  geom_histogram(binwidth = 1, \n                 color = \"black\", fill = \"steelblue3\") + # black outline with blue fill\n  theme_bw() +\n  labs(title = \"Population of size 10,000\")\n\n\n```\n:::\n\n## Summary values on the population\n\nCalculate the mean, standard deviation, and variance in the population. Is it what you would expect?\n\n```{webr-r}\n# mean in population\n\n# variance in population\n\n# standard deviation in population\n\n```\n\n::: {.callout-tip collapse=\"true\" icon=\"false\"}\n## Solution\n\n```{webr-r}\n\n# true mean in population \nmean(pop$x)\n# true variance in population \nvar(pop$x)\n# true standard deviation in population \nsd(pop$x)\n\n```\n\nThis is what we would expect, since the population was drawn randomly from a Poisson distribution with lambda = 2.5 (the mean and variance of a Poisson distribution are equal to lambda). We observe a mean of 2.4759 and a variance of 2.449064, which are very close to 2.5. The standard deviation is the square root of the variance, about 1.565.\n:::\n\n# The Sample\n\n## Sample of size 100\n\nFill in the code below so that 'samp' contains a sample of size 100 sampled without replacement from our population.\n\n```{webr-r}\nset.seed(2468) # re-setting seed to make sure we get the same numbers\n# draw a sample of size 100 without replacement\nsamp <- data.frame(x = sample(pop$x, size =  \"SAMPLE SIZE HERE\", replace = \"ENTER VALUE HERE\"))\n\n```\n\n::: {.callout-tip collapse=\"true\" icon=\"false\"}\n## Solution\n\n```{webr-r}\n#| autorun: true\n\nset.seed(2468) # re-setting seed to make sure we get the same numbers\n# draw a sample of size 100 without replacement\nsamp <- data.frame(x = sample(pop$x, size = 100, replace = FALSE))\n\n```\n:::\n\n## Plot the data.\n\nMake a plot to show the distribution of the sampled data.\n\n```{webr-r}\n# make a plot of the sample data\n\n\n```\n\n::: {.callout-tip collapse=\"true\" icon=\"false\"}\n## Solution\n\n```{webr-r}\n# make a plot of the sample data\nsamp %>%\n  ggplot(aes(x = x)) +\n  geom_histogram(color = \"black\", fill = \"firebrick1\", binwidth = 1) + \n  theme_bw() + \n  labs(title = \"Sample of size 100\")\n\n```\n\nThe sample looks very similar to the population distribution, which is expected since we sampled randomly. The population has a few more extreme values (around 9, 10, 11, etc) than we observe in the sample. This also makes sense, given that these are rare observations and it's less likely to pull one of these randomly than to pull a value near the center of the distribution (around 2-3, for example).\n:::\n\n# The Bootstrap\n\n## Bootstrapped means\n\nHere I've included code to produce 10,000 bootstrap samples from our original sample and saved the mean from each bootstrap sample. You don't need to write the code for this-- I've done it for you. This code chunk is just so you can see how the code works. The procedure is:\n\n1.  Resample with replacement from the original sample to get a new sample of size 100 (the same size as the original sample). This is a bootstrap sample.\n\n2.  Calculate the mean value on the on the bootstrap sample.\n\n3.  Repeat this process many times (I chose 10,000 in this example, but we just want it large enough that we can visualize the distribution of the means that we calculated in step 2).\n\nThe result is a set of 10,000 (or whatever number of bootstrap iterations you chose to run) bootstrap means.\n\n```{webr-r}\n#| autorun: true\nset.seed(321) # re-setting seed to make sure we get the same numbers\n# empty data frame to store means  \nboot_10000 <- data.frame(mean=rep(NA, 10000))\n\n# bootstrap 10,000 samples each of size 100 (the same as our original sample size)\nfor(i in 1:10000){\n  # sample with replacement from the SAMPLE (not the population)\n  samp_10000 <- sample(samp$x, size = 100, replace=TRUE)\n  # record the mean\n  boot_10000$mean[i] <- mean(samp_10000)\n}\n```\n\n## Plot the bootstrapped means\n\nPlot the distribution of the means of the bootstrapped samples. Describe the distribution.\n\nAssuming the central limit theorem (CLT), what would we expect this distribution to be? Is our observed distribution close to what we would expect?\n\n```{webr-r}\n# plot the means from the 10,000 bootstrapped samples\n\n\n```\n\n```{webr-r}\n# calculate summary statistics (mean/sd/etc) for the boostrapped means\n\n\n```\n\n::: {.callout-tip collapse=\"true\" icon=\"false\"}\n## Solution\n\n```{webr-r}\n# plot the means from the 10,000 bootstrapped samples\nboot_10000 %>%\n  ggplot(aes(x = mean)) +\n  geom_histogram(color = \"black\", fill = \"lightcoral\", binwidth = .1) + \n  theme_bw()\n```\n\n```{webr-r}\n# calculate summary statistics (mean/sd/etc) for the boostrapped means\n# calculate mean\nmean(boot_10000$mean)\n\n# calculated standard deviation of means (also called standard error)\nsd(boot_10000$mean)\n\n## Under the CLT, we would expect these to be \n# mean\nmean(pop$x)\n\n# standard error\nsd(pop$x)/sqrt(nrow(samp))\n\n```\n\nThe distribution appears approximately normal centered at around 2.5 (mean = 2.56) with a standard deviation of 0.17. This is very similar to what we would expect from the central limit theorem CLT, which tells us that the mean should be centered at the true population mean (our population had a mean of 2.48) and the standard error should be our population standard deviation/(root n) (1.56/sqrt(100) = 0.156).\n:::\n\n# Resampling from the population (sampling distribution)\n\nFor this part of the recitation, you don't need to write any code. I've written all of the code for you-- I just want to use this part of the recitation to demonstrate the concept of a confidence interval and show how the bootstrap ties in.\n\n## Resample from population\n\nNow draw we're going 10000 samples of size 100 without replacement from the population and calculate the mean for each and a 95% confidence interval.\n\nWe haven't learned the specific formula for confidence intervals yet so I have provided the code for you here.\n\n```{webr-r}\n#| autorun: true\nset.seed(1298) # re-setting seed to make sure we get the same numbers\n# empty data frame to store mean and bounds of confidence interval\nsampdist100 <- data.frame(mean=rep(NA, 10000), \n                          lower = rep(NA, 10000), \n                          upper = rep(NA, 10000))\n\n# resample 10000 times\nfor(i in 1:10000){\n  # sample without replacement from the POPULATION\n  resamp_100 <- sample(pop$x, size = 100, replace = FALSE)\n  # calculate the mean\n  sampdist100$mean[i] <- mean(resamp_100)\n  # lower bound of confidence interval\n  sampdist100$lower[i] <- mean(resamp_100) - qt(0.975, df = 99)*sd(resamp_100)/sqrt(100)\n  # upper bound of confidence interval\n  sampdist100$upper[i] <- mean(resamp_100) + qt(0.975, df = 99)*sd(resamp_100)/sqrt(100)\n}\n\n```\n\n## Comparison: boostrap vs resampling from the population\n\nTo compare the distribution obtained in part 4 to that obtained in part 2, we're going to plot the two distributions next to each other. Here I'm just showing the plot output, but you can toggle to the next tab to see the code that produced this plot if you're interested.\n\n::: {.panel-tabset group=\"boostrapplots\"}\n#### Plot\n\n```{webr-r}\n#| autorun: true\n#| context: output\n# plot the two next to each other using ggplot\ndata.frame(x = c(sampdist100$mean, boot_10000$mean), \n           sampling = rep(c(\"Resample from population\", \"Bootstrap\"), each = 10000)) %>%\n  mutate(pop_mean = mean(pop$x),\n         samp_mean = mean(samp$x)) %>%\n  ggplot(aes(x = x, fill = sampling)) + # color by which method was used\n  geom_histogram(color = \"black\", binwidth = 0.1) + \n  facet_wrap(.~ sampling, nrow = 2) + # separate plots\n  theme_bw() + \n  labs(x = \"Sample Means\", fill = \"Method\") +\n  scale_fill_manual(values = c(\"lightcoral\",\"skyblue\")) + \n  geom_vline(aes(xintercept = samp_mean, color = \"Sample Mean\", linetype = \"Sample Mean\" ), show.legend = TRUE) + # add a dashed vertical line at the original sample mean\n  geom_vline(aes(xintercept = pop_mean, color = \"Population Mean\", linetype = \"Population Mean\"), show.legend = TRUE) +# add a vertical line at the population mean \n  scale_color_manual(name = \"\",\n                     values = c(\"Sample Mean\" = \"firebrick1\", \"Population Mean\" = \"blue\")) +\n  scale_linetype_manual(name = \"\",\n                     values = c(\"Sample Mean\" = 2, \"Population Mean\" = 1)) \n\n```\n\n#### Plot Code\n\n```` md\n```{webr-r}\n# plot the two next to each other using ggplot\ndata.frame(x = c(sampdist100$mean, boot_10000$mean), \n           sampling = rep(c(\"Resample from population\", \"Bootstrap\"), each = 10000)) %>%\n  mutate(pop_mean = mean(pop$x),\n         samp_mean = mean(samp$x)) %>%\n  ggplot(aes(x = x, fill = sampling)) + # color by which method was used\n  geom_histogram(color = \"black\", binwidth = 0.1) + \n  facet_wrap(.~ sampling, nrow = 2) + # separate plots\n  theme_bw() + \n  labs(x = \"Sample Means\", fill = \"Method\") +\n  scale_fill_manual(values = c(\"lightcoral\",\"skyblue\")) + \n  geom_vline(aes(xintercept = samp_mean, color = \"Sample Mean\", linetype = \"Sample Mean\" ), show.legend = TRUE) + # add a dashed vertical line at the original sample mean\n  geom_vline(aes(xintercept = pop_mean, color = \"Population Mean\", linetype = \"Population Mean\"), show.legend = TRUE) +# add a vertical line at the population mean \n  scale_color_manual(name = \"\",\n                     values = c(\"Sample Mean\" = \"firebrick1\", \"Population Mean\" = \"blue\")) +\n  scale_linetype_manual(name = \"\",\n                     values = c(\"Sample Mean\" = 2, \"Population Mean\" = 1)) \n\n```\n````\n:::\n\nNotice that the two distributions are fairly similar, though the bootstrap is centered at the sample mean observed in our data, while the distribution obtained from resampling from the actual population is centered near the true population mean (as expected). Both distributions are symmetric and they have similar spread.\n\n# Confidence intervals\n\n## The boostrap confidence interval\n\nHere we will compute a 95% confidence interval for the bootstrapped sample means with 10,000 repetitions by taking the 2.5th percentile and the 97.5th percentile of the bootstrapped means that we got above. These two values will tell us the range of values that contains the middle 95% of the observed bootstrapped means.\n\n```{webr-r}\n# find 2.5% and 97.5% of the bootstrapped means\nquantile(boot_10000$mean, c(.025, .975))\n\n```\n\nThis tells us that when we resampled (with replacement) samples of size 100 from our original sample, we obtained sample means between 2.08 and 2.78 in 9,500 of the 10,000 bootstrap samples (95% of the bootstrap iterations) and only 5% of the bootstrap samples gave us a mean outside of this range.\n\n## Comparing this to the theory-based confidence interval\n\nIf we wanted to see what confidence interval we would get from our sample based on the equation, we can use the following code:\n\n```{webr-r}\n# confidence interval for our original sample\nmean(samp$x) + qt(c(0.025, 0.975), df = 99)*sd(samp$x)/sqrt(nrow(samp))\n\n```\n\nThis is very similar to the bootstrap confidence interval we got and does contain the true population mean of 2.4759. The idea here is that the bootstrap empirically simulates a sampling distribution based on our sample, while the theory-based confidence interval uses a few sample statistics (the mean and standard deviation) and statistical theory to estimate the sampling distribution. Then both calculate boundaries between which 95% of the sample distribution lies.\n\n## Coverage of resampled population means\n\nNext we are going to calculate the percentage of the confidence intervals from part 4 (the confidence intervals from resampling from the population) cover the true population mean.\n\n```{webr-r}\n# the population mean\npop_mean = mean(pop$x)\n\n# proportion of intervals that overlap with the true population mean\nsampdist100 %>%\n  mutate(covers = lower <= pop_mean & upper >= pop_mean) %>%\n  summarise(percent = mean(covers))\n\n```\n\nWe can see that almost exactly 95% of the confidence intervals constructed overlap with the true population mean. This is what we would expect based on the interpretation of a confidence interval.\n\nHere is a plot to show the first 200 confidence intervals we calculated above, where the color indicates if the interval covers the true mean or not. Think of each row (interval) as a different sample of size 100 and the 95% confidence interval we would calculate based on that sample. Statistical theory tells us that 95% of these intervals should cover the true population mean, and 5% will not. .\n\n::: {.panel-tabset group=\"plotcis\"}\n#### Plot\n\n```{webr-r}\n#| autorun: true\n#| context: output\n# plotting the first 200 intervals\nsampdist100 %>%\n  slice(1:200) %>%\n  mutate(pop_mean = mean(pop$x)) %>%\n  mutate(iteration = row_number()) %>%\n  mutate(covers = case_when(lower <= pop_mean & upper >= pop_mean ~ \"Covers mean\",\n                           lower > pop_mean | upper < pop_mean ~ \"Does not cover mean\")) %>%\n  ggplot(aes(x = mean, y = iteration, color = covers)) + \n  geom_point(size = 0.5) + \n  geom_errorbarh(aes(xmin=lower, xmax = upper), linewidth = 0.25) + \n  theme_bw() + \n  labs(color = element_blank(), x = \"x\") + \n  geom_vline(aes(xintercept = pop_mean)) +  \n  scale_color_manual(values = c(\"navy\",\"red\"))\n```\n\n#### Plot Code\n\n```` md\n\n```{webr-r}\n# plotting the first 200 intervals\nsampdist100 %>%\n  slice(1:200) %>%\n  mutate(pop_mean = mean(pop$x)) %>%\n  mutate(iteration = row_number()) %>%\n  mutate(covers = case_when(lower <= pop_mean & upper >= pop_mean ~ \"Covers mean\",\n                           lower > pop_mean | upper < pop_mean ~ \"Does not cover mean\")) %>%\n  ggplot(aes(x = mean, y = iteration, color = covers)) + \n  geom_point(size = 0.5) + \n  geom_errorbarh(aes(xmin=lower, xmax = upper), linewidth = 0.25) + \n  theme_bw() + \n  labs(color = element_blank(), x = \"x\") + \n  geom_vline(aes(xintercept = pop_mean)) + \n  scale_color_manual(values = c(\"navy\",\"red\"))\n```\n````\n:::\n\nIn this set of 200 resampling iterations, we see that 9 out of 200 (4.5%) of the iterations produced a confidence interval that **did not** contain the population mean, and the remaining 191 (95.5%) did contain the true mean.\n\nIn practice, we typically only have one sample. We have no way of knowing if our sample is one of the unlucky 5% of samples that doesn't produce a confidence interval that covers the true mean, but since in the long run most confidence intervals will cover the true mean, we say \"we are 95% confident that our interval covers the true mean.\"\n\n# Word of caution\n\nMany students confuse the number of bootstrap iterations (in our example, N = 10,000) with the sample size drawn at each bootstrap iteration (in our example, n = 100). This distinction is **crucial**. The number of iterations is not pre-defined. We often want at least \\~1,000 iterations to have a set of bootstrapped statistics (in our case, means) large enough to visualize the distribution and enough granularity to accurately calculate percentiles for confidence intervals, for example.\n\nIn contrast, the sample size drawn at each bootstrap iteration **must be equal to the original sample size**. The goal of bootstrapping is to simulate the *sampling distribution from which your original sample was drawn*. Its aim is to quantify the uncertainty in the original sample by resampling to see how different the statistic (the mean) can be from sample to sample **of the same size**. If we artificially inflate the sample size, say in our example drawing bootstrap samples of size 500, this is **invalid** we will artificially reduce the amount of variability in the sample statistic (the mean) if we pretend our original sample was 5 times larger than it actually was.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
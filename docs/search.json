[
  {
    "objectID": "biost2041.html",
    "href": "biost2041.html",
    "title": "BIOST2041",
    "section": "",
    "text": "Welcome To BIOST 2041\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\n\n\n\n\nTutorial 1: Installing R and RStudio\n\n\n\n\n\n\nsoftware\n\n\nR coding\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To BIOST 2041",
    "section": "",
    "text": "This blog will house the R tutorials that I will use this semester."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This is a landing page for R tutorials, course materials, and shiny apps for introductory biostatistics courses taught by Haley Grant.\nThe tutorials on this site were made using webR to incorporate interactive coding exercises inside quarto documents. Documentation for how to use the quarto-webr extension can be found here. Shiny apps on the page are deployed using r-shinylive (also a quarto extension); documentation for which can be found here."
  },
  {
    "objectID": "posts/Tutorial-1/Tutorial1.html#welcome-to-the-installing-r-tutorial",
    "href": "posts/Tutorial-1/Tutorial1.html#welcome-to-the-installing-r-tutorial",
    "title": "Tutorial 1: Installing R and RStudio",
    "section": "Welcome to the Installing R Tutorial",
    "text": "Welcome to the Installing R Tutorial\nThis tutorial was developed based on this resource. The goal is to make sure you have R and Rstudio installed on your computer and make sure you have a folder set up for this class to make your semester go smoother.\n\nOutline\nThis tutorial will help you set up your computer to use R. It is for you if you need to:\n\nInstall R on your computer\nInstall the RStudio IDE\nGet set up with R projects\n\nYou can skip this tutorial if you’ve already done these things."
  },
  {
    "objectID": "posts/Tutorial-1/Tutorial1.html#install-r",
    "href": "posts/Tutorial-1/Tutorial1.html#install-r",
    "title": "Tutorial 1: Installing R and RStudio",
    "section": "Install R",
    "text": "Install R\n\nHow to install R\n\n\n\n\n\nIf you need to download R, head over to the CRAN website to download R.\nIf you’ve already done this, we’ll move to the next step!"
  },
  {
    "objectID": "posts/Tutorial-1/Tutorial1.html#install-rstudio",
    "href": "posts/Tutorial-1/Tutorial1.html#install-rstudio",
    "title": "Tutorial 1: Installing R and RStudio",
    "section": "Install RStudio",
    "text": "Install RStudio\n\nHow to install RStudio\nRStudio is an Integrated Development Environment (IDE) for R. What does that mean? Well, if you think of R as a language, which it is, you can think of RStudio as a program that helps you write and work in the language. RStudio makes programming in R much easier and I suggest that you use it!\n\nIf you need to download RStudio, head over to the RStudio website to download RStudio. There are also some helpful tutorials on this website!\nIf you’ve already done this, we’ll move to the next step!"
  },
  {
    "objectID": "posts/Tutorial-1/Tutorial1.html#r-projects",
    "href": "posts/Tutorial-1/Tutorial1.html#r-projects",
    "title": "Tutorial 1: Installing R and RStudio",
    "section": "R Projects",
    "text": "R Projects\nR projects make it easy to keep files relating to the same content organized. I recommend making a folder and an R project for this class. This will allow you to keep all of your data files, notes, and homowork code in one (organized) place on your computer.\n\nGuide to RStudio IDE and R Projects\nWatch this video for a description of the layout of the RStudio interface and a demonstration for how to create an R project on your computer.\n\n\n\nMaking a class-specific folder and R Project\nI will be making a folder and project for this class where I will keep all of my notes and data sets. If you structure your folder the same way I do, all of my code should work seamlessly on your computer!\n\nCheck In\nHave you created a folder (directory) and an R project for this class on your computer?\n\n Yes! Not yet\n\n\nI also like to keep things organized into sub-folders. For my BIOST 2041 folder, I have the following sub-folders:\n\nData\nLabs\nNotes\nRecitation\n\nI keep all data files for the class in “Data” and then files with code and instructions in their corresponding assignment section.\nThat’s it! The next tutorial will be about using data types, using functions, and downloading packages in R."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Intro Biostatistics Resources",
    "section": "",
    "text": "R Tutorials\n\n\n\n\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR Tutorials\n\n\n\n\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR Tutorials\n\n\n\n\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR Tutorials\n\n\n\n\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR Tutorials\n\n\nExploratory Data Analysis (EDA)\n\n\n\n\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR Tutorials\n\n\nExploratory Data Analysis (EDA)\n\n\n\n\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "About",
      "Home"
    ]
  },
  {
    "objectID": "posts/Tutorial-2/Tutorial2.html",
    "href": "posts/Tutorial-2/Tutorial2.html",
    "title": "Tutorial 2: R Objects, Functions, and Packages",
    "section": "",
    "text": "In this tutorial, you will learn about working with objects in R. In particular, this tutorial will cover…\n\nR objects\nData types in R\nFunctions in R\nInstalling and using R packages\n\n\n\n\n\nIn this tutorial I will introduce a handful of new concepts in R and will include example code to demonstrate how the code works. When you get to a code chunk (an example of a code chunk is shown below), you can edit the code in the chunk if necessary and run the code to see the output by either hitting the “Run Code” button or by placing your cursor in the code chunk you want to execute and typing command (⌘) + return (↩︎) (on mac) or Ctrl + Enter (on windows).\nSometimes certain code chunks will require output from previous code chunks. I have tried to mark these within the tutorial, but if you ever get any errors, go back and make sure you haven’t skipped any sections.\n\n\n\nIf a code chunk produces output, you will see it appear below the code chunk after you execute (run) the code in the chunk. If there are multiple lines of code that produce output, you will see the output appear in order below the code chunk if you hit the “Run Code” button. You can also execute each line separately using the keystrokes mentioned above.\n\n\n\nEach code chunk has a  button in the upper right corner that allows you to reset the code in the chunk. If you make a mistake and want to start from scratch, hit this button!\n\n\n\nYou may notice some lines of code that start with the pound symbol, #, and show up in a different text color inside the code chunks. These are called comments. R doesn’t execute anything when it sees a comment. Comments are just notes to yourself or anyone else reading your code! It’s good practice to add comments to your code at each line to help you remember what the code was meant to do, or to help someone else who may be reading your code understand what the code is supposed to be doing.\n\n# this is an example of a comment!\n\n\n\n\n\n\n\nExercise:\n\n\n\nTry writing your own comment in the code chunk below!\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nHint\n\n\n\n\n\nThink about what the line of code should start with.\nIf you hit “Run Code” you should see that nothing is executed.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "posts/Tutorial-2/Tutorial2.html#introduction",
    "href": "posts/Tutorial-2/Tutorial2.html#introduction",
    "title": "Tutorial 2: R Objects, Functions, and Packages",
    "section": "",
    "text": "In this tutorial, you will learn about working with objects in R. In particular, this tutorial will cover…\n\nR objects\nData types in R\nFunctions in R\nInstalling and using R packages\n\n\n\n\n\nIn this tutorial I will introduce a handful of new concepts in R and will include example code to demonstrate how the code works. When you get to a code chunk (an example of a code chunk is shown below), you can edit the code in the chunk if necessary and run the code to see the output by either hitting the “Run Code” button or by placing your cursor in the code chunk you want to execute and typing command (⌘) + return (↩︎) (on mac) or Ctrl + Enter (on windows).\nSometimes certain code chunks will require output from previous code chunks. I have tried to mark these within the tutorial, but if you ever get any errors, go back and make sure you haven’t skipped any sections.\n\n\n\nIf a code chunk produces output, you will see it appear below the code chunk after you execute (run) the code in the chunk. If there are multiple lines of code that produce output, you will see the output appear in order below the code chunk if you hit the “Run Code” button. You can also execute each line separately using the keystrokes mentioned above.\n\n\n\nEach code chunk has a  button in the upper right corner that allows you to reset the code in the chunk. If you make a mistake and want to start from scratch, hit this button!\n\n\n\nYou may notice some lines of code that start with the pound symbol, #, and show up in a different text color inside the code chunks. These are called comments. R doesn’t execute anything when it sees a comment. Comments are just notes to yourself or anyone else reading your code! It’s good practice to add comments to your code at each line to help you remember what the code was meant to do, or to help someone else who may be reading your code understand what the code is supposed to be doing.\n\n# this is an example of a comment!\n\n\n\n\n\n\n\nExercise:\n\n\n\nTry writing your own comment in the code chunk below!\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nHint\n\n\n\n\n\nThink about what the line of code should start with.\nIf you hit “Run Code” you should see that nothing is executed.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "posts/Tutorial-2/Tutorial2.html#r-objects",
    "href": "posts/Tutorial-2/Tutorial2.html#r-objects",
    "title": "Tutorial 2: R Objects, Functions, and Packages",
    "section": "R Objects",
    "text": "R Objects\nOne very basic function of R is that it can be used essentially as a calculator. For example, if we want to check what 2 + 3 is, we can run the code:\nNote: the spaces I included in this line of code aren’t necessary, but I like to add white space into R code for readability. White spaces generally only matter in R if they are part of character strigns (which we’ll get to later)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWhen you run the code above, it should print out the number 5 (the [1] on the left just indicates that this is the first line of output, which can be helpful later if R code produces more than one line of output). You can try changing the numbers in this code chunk to see how this changes the output.\nThat’s great, but maybe I don’t want to have to re-type that line of code every time I want to use those numbers. This is where R objects come in. For example, maybe I have a variable that I want to call x that will hold the number 2 and a different variable called y that will hold the number 3. To do this, run the following chunk of code:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nNote: = vs &lt;-\n\n\n\n\n\nSometimes you might see the operator &lt;- (for example x &lt;- 2) instead of the equals sign (=). This is an artifact of earlier versions of R when you had to use &lt;- to assign values to objects; both work now and = is shorter so I used it here 🙂\n\n\n\nNote that when you run this code, nothing seems to happen! Or at least, that’s what it looks like. If we were running this in RStudio, we would see in the upper right quadrant under the “Environment” tab that we now have two objects, x and y, that have the values 2 and 3 respectively. To see this here, we can print out the values:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nIf you get an error\n\n\n\n\n\nIf you get an error that looks like this\nError: object ‘x’ not found\nmake sure you hit “Run Code” in the previous code chunk where we assigned x and y values before trying to print the value of x. This type of error means that you are trying to use an object that hasn’t been defined. Just because you wrote a line of code (say, in an R Markdown file), doesn’t mean you’ve executed that line of code.\n\n\n\nGreat! The object x is now a placeholder for the number 2.\n\n\n\n\n\n\nExercise:\n\n\n\nThe goal of the following line of code is to print the value of the object y, but it has an error. Can you find the mistake in the code? See if you can figure out how to fix it so the code returns the correct answer (the value of y is 3).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe problem with the code above is that I used a capital Y instead of lowercase y. R is case-sensitive, so it won’t assume you mean y if you type Y. This is something to be aware of in the future!\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\nCool! Now that x and y are placeholders for the numbers 2 and 3, we can use them just like numbers. For example, we can add them together, multiply them, divide, subtract, etc. If we want to save the value of x + y for later use, we can do that too! Below I’ve shown some examples of calculations you can do using these two variables.\n\nAddition, subtraction, multiplication, division\nWe can do simple arithmetic like adding, subtracting, multiplying, and dividing, using the symbols +, -, *, and /, respectively.\n\n\n\n\n\n\nExercise:\n\n\n\nI’ve shown addition and multiplication below, see if you can do subtraction and division!\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nPowers\nWe can take powers using the ^ operator:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nLogarithm/Exponent\nTo take the natural (base e) logarithm of a numeric object we can use the log() function. The inverse of this function is exp(), which calculates e^x :\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nSaving a new variable z\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "posts/Tutorial-2/Tutorial2.html#types-of-data",
    "href": "posts/Tutorial-2/Tutorial2.html#types-of-data",
    "title": "Tutorial 2: R Objects, Functions, and Packages",
    "section": "Types of Data",
    "text": "Types of Data\nIn the example above, we were using numeric variables. However, there are many different types of data in R. Some of the main types of data we will use are\n\nnumeric: numbers\ncharacter: character strings/words\nfactor: categorical variables that store data in levels\nlogical: binary TRUE/FALSE\nNA: stand-in for missing values\n\nIf you aren’t sure what type of data an R object is, you can use the following code:\n\nclass(name_of_object))\n\nwhere you would replace name_of_object with the name of the R object that you want to check the class (data type) of.\n\nNumeric Data\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThis is a number so we can use the same types of functions as we used above on the object x_numeric (adding, subtracting, etc.).\n\n\nCharacter Data\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThis is a character. Even though it looks like a number, the quotation marks tell R that we don’t want to treat this as the number 5. For example, maybe this is and identifier for hospital number 5 in a study. In this case, we probably don’t want to do typical calculations as if this was the number 5.\nFor example, see what happens when you try to multiply x_character by 2.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nError messages\nOh no! You should see the following error message:\n\nError: non-numeric argument to binary operator\n\nThis is R’s way of telling you that you’re trying to apply a function that requires a number to an object that isn’t a number. R gives helpful error messages like this when you try to run code that doesn’t work. Sometimes the language R uses is hard to understand, but you can always ask me or a TA what the error means, or search the error on Google!\n\n\n\n\n\n\nExercise:\n\n\n\nIf you change x_character to x_numeric in the code above, you should see it works just fine! Try it out yourself!\n\n\n\n\n\nVectors\nWe don’t have to save values in R individually. We can also save a bunch of values (numbers, characters, factors, etc.) together in something called a vector.\nWe can make this type of R object using the c() function (this stands for “concatenate”) to put a bunch of values together in a vector, separated by a comma. The values within a vector can be any type (numeric, character, logical, factor, etc.), but they must all be the same type, i.e. all numeric, all character, etc. (except for missing values).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWe can do lots of fun stuff in R with vectors. For example, we can multiply every entry of a numeric vector by 2, take the mean, sum, or standard deviation of a numeric vector, show the unique entries of the vector, and much more!\n\nMultiply by 2\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nTake the mean\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nTake the sum\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nTake the standard deviation\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nShow the unique values\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nPrint the length of the vector\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nExercise:\n\n\n\nThe goal of the following line of code is to find and print the maximum value of the vector x_vector, but it has an error. Can you find the mistake in the code? See if you can figure out how to fix it so the code returns the correct answer (the maximum value in the vector is 5).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe problem with the code above is that I accidentally included the name of the vector object (x_vector) in quotation marks (\"x_vector\"). If you include the name of an object in quotation marks, R will just think it’s a character string and not the name of a saved object in the directory. If you remove the quotation marks, the code should work as expected!\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\n\nFactor Data\nFactor variables are categorical variables that can either be numeric or character strings. Sometimes we get data that are coded with numbers even though the underlying variable is categorical. For example, we often code No/Yes variables as 0/1. Or maybe we have three levels of health insurance status: public, private, and uninsured. We may label these categories as 1, 2, and 3, but these numbers are just used for convenience, not because “private insurance” has anything to do with the number 2.\nIn these cases, it can be helpful to convert variables to factors. Turning the variable into a factor means R will treat the variable as categorical rather than as a number. We also have the option to choose an order for the variable and we can give the variables nicer, more readable labels, which can both come in handy when making plots and tables from the data. We can accomplish these two tasks using the levels and labels arguments, respectively.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nHere we can see that x_factor is a vector of factor variables. Now instead of showing up as numbers 1 through 5, we see the labels from the Likert scale. Our original vector was 1, 2, 3, 4, 5, 2, 4 which correspond to: Strongly Agree, Agree, Neutral, Disagree, Strongly Disagree, Agree, Disagree. This is the order that is showing up in x_factor. We can also see all possible levels printed when we print our vector of factor variables.\n\n\nLogical Data\nR has another type of data called “logical” values. These are binary TRUE/FALSE (can also abbreviate with T/F) that let you know if a statement is true or false. This can be really useful when we want to filter data. For example, if we want to filter data to everyone over the age of 50, we can use logical variables to check if the age variable is greater than 50.\nIn the example below we’ll make a new variable to tell us if x_numeric from above is equal to the number 5.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nExercise:\n\n\n\nTry changing the value in the code above to check if x_numeric is equal to the number 4 to see how the value would change.\n\n\n\n\n\n\n\n\nNote: White spaces and case in character objects\n\n\n\nRecall that I mentioned above that adding extra white spaces in R generally doesn’t impact your code (but can help with readability). One instance where white spaces do matter is inside characters. Run the code below to see an example of this:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNotice here that the statement is false, these two characters are not equal (because one has an extra space).\nR is also case-sensitive:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\nOther Inequalities/Operators\n\n\n\n\n\nWe saw above that the == operator is R’s way of checking if an object is equal to some value. There some other useful operators such as:\n\n&gt;: “greater than”\n&gt;=: “greater than or equal to”\n&lt;: “less than”\n&lt;=: “less than or equal to”\n%in%: “is an element of” (this will be helpful when we get to vectors later)\n\nGo ahead and play around with the code below to try different operators:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\nMissing Values\nR has a special way of denoting missing values. In R, these show up as NA values. For example, if you have a data set with 100 individuals’ height, weight, and age, if you weren’t able to get the values measured for some of the individuals, those values should show up as NA values to indicate that they are missing.\nNote: this is different from \"NA\" the character. R will change the text color of NA when you type it in your code to show that this is a special kind of variable.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nExercise:\n\n\n\nTry multiplying the x_missing variable by 2 and see what happens.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nGenerally any kind of functions applied to missing values return another NA value unless the function has a special way of handling missing values.\n\n\n\nThe is.na() function\nThere is a special function in R that can help you check if a value is a missing value. This function is is.na(). To see how it works, try running the code below:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "posts/Tutorial-2/Tutorial2.html#vectors",
    "href": "posts/Tutorial-2/Tutorial2.html#vectors",
    "title": "Tutorial 2: R Objects, Functions, and Packages",
    "section": "Vectors",
    "text": "Vectors\nWe don’t have to save values in R individually. We can also save a bunch of values (numbers, characters, factors, etc.) together in something called a vector.\nWe can make this type of R object using the c() function (this stands for “concatenate”) to put a bunch of values together in a vector, separated by a comma. The values within a vector can be any type (numeric, character, logical, factor, etc.), but they must all be the same type, i.e. all numeric, all character, etc. (except for missing values).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWe can do lots of fun stuff in R with vectors. For example, we can multiply every entry of a numeric vector by 2, take the mean, sum, or standard deviation of a numeric vector, show the unique entries of the vector, and much more!\n\nMultiply by 2\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nTake the mean\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nTake the sum\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nTake the standard deviation\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nShow the unique values\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nPrint the length of the vector\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nExercise:\n\n\n\nThe goal of the following line of code is to find and print the maximum value of the vector x_vector, but it has an error. Can you find the mistake in the code? See if you can figure out how to fix it so the code returns the correct answer (the maximum value in the vector is 5).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe problem with the code above is that I accidentally included the name of the vector object (x_vector) in quotation marks (\"x_vector\"). If you include the name of an object in quotation marks, R will just think it’s a character string and not the name of a saved object in the directory. If you remove the quotation marks, the code should work as expected!\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\nFactor Data\nFactor variables are categorical variables that can either be numeric or character strings. Sometimes we get data that are coded with numbers even though the underlying variable is categorical. For example, we often code No/Yes variables as 0/1. Or maybe we have three levels of health insurance status: public, private, and uninsured. We may label these categories as 1, 2, and 3, but these numbers are just used for convenience, not because “private insurance” has anything to do with the number 2.\nIn these cases, it can be helpful to convert variables to factors. Turning the variable into a factor means R will treat the variable as categorical rather than as a number. We also have the option to choose an order for the variable and we can give the variables nicer, more readable labels, which can both come in handy when making plots and tables from the data. We can accomplish these two tasks using the levels and labels arguments, respectively.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nHere we can see that x_factor is a factor variable. Now instead of showing up as numbers 1 through 5, we see the labels from the Likert scale.\n\n\nLogical Data\nR has another type of data called “logical” values. These are binary TRUE/FALSE (can also abbreviate with T/F) that let you know if a statement is true or false. This can be really useful when we want to filter data. For example, if we want to filter data to everyone over the age of 50, we can use logical variables to check if the age variable is greater than 50.\nIn the example below we’ll make a new variable to tell us if x_numeric from above is equal to the number 5.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nExercise:\n\n\n\nTry changing the value in the code above to check if x_numeric is equal to the number 4 to see how the value would change.\n\n\n\n\n\n\n\n\nNote: White spaces and case in character objects\n\n\n\nRecall that I mentioned above that adding extra white spaces in R generally doesn’t impact your code (but can help with readability). One instance where white spaces do matter is inside characters. Run the code below to see an example of this:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNotice here that the statement is false, these two characters are not equal (because one has an extra space).\nR is also case-sensitive:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\nOther Inequalities/Operators\n\n\n\n\n\nWe saw above that the == operator is R’s way of checking if an object is equal to some value. There some other useful operators such as:\n\n&gt;: “greater than”\n&gt;=: “greater than or equal to”\n&lt;: “less than”\n&lt;=: “less than or equal to”\n%in%: “is an element of” (this will be helpful when we get to vectors later)\n\nGo ahead and play around with the code below to try different operators:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\nMissing Values\nR has a special way of denoting missing values. In R, these show up as NA values. For example, if you have a data set with 100 individuals’ height, weight, and age, if you weren’t able to get the values measured for some of the individuals, those values should show up as NA values to indicate that they are missing.\nNote: this is different from \"NA\" the character. R will change the text color of NA when you type it in your code to show that this is a special kind of variable.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nExercise:\n\n\n\nTry multiplying the x_missing variable by 2 and see what happens.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nGenerally any kind of functions applied to missing values return another NA value unless the function has a special way of handling missing values.\n\n\n\nThe is.na() function\nThere is a special function in R that can help you check if a value is a missing value. This function is is.na(). To see how it works, try running the code below:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "posts/Tutorial-2/Tutorial2.html#functions",
    "href": "posts/Tutorial-2/Tutorial2.html#functions",
    "title": "Tutorial 2: R Objects, Functions, and Packages",
    "section": "Functions",
    "text": "Functions\nWe’ve already shown some examples of functions in R. You can think of R functions kind of like a recipe. You need to tell R what dish you want to make (the function) and give it some ingredients (called arguments), and then R will make the dish for you!\nFunctions in R all use the same general syntax:\n\nfunction_name(argument1 , argument2 , ...)\n\nwhere here the name of the function is function_name and the arguments for the function are passed to the function inside a set of parentheses. Some functions have no arguments, some have one, and some have many.\nFor example, the mean() function we used above is a built-in R function that takes a vector of numbers (it can also take a vector of logical values or some more advanced data types like dates) and returns the mean (average) value by adding up all of the entries in the vector and dividing by the length. Functions in R are really helpful because it means we don’t have to write out the full code ourselves.\nFor example, both lines of code below do the same thing, but one is a lot easier (imagine if the vector had been even longer)!\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nNote: Argument Names\n\n\n\n\n\nSometimes the functions we use will take multiple arguments, and sometimes they only need one. With all R functions, the arguments are given names. For example, technically the argument name for the function mean() is called x, which is just a placeholder for any R objects that you can calculate the mean of. If we wanted to be really technical, we could have used the following line of code:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nI try to use argument names in functions that use multiple arguments, because if you don’t assign the inputs to specific argument names, R has to assume that you’ve put the input in a specific order. Sometimes, if I’m only using the most basic argument (like x in the mean() function), I may forget to or choose not to include the name of the argument to make the code simpler.\nIf you ever need help figuring out what arguments a certain function in R takes, you can use the ‘Help’ tab in R Studio (in the bottom right quadrant) or type ?function_name in your R Console (for example, ?mean). This will open a documentation page for the function and should include information about the argument names and the types of objects can be used as input for the function."
  },
  {
    "objectID": "posts/Tutorial-2/Tutorial2.html#r-packages",
    "href": "posts/Tutorial-2/Tutorial2.html#r-packages",
    "title": "Tutorial 2: R Objects, Functions, and Packages",
    "section": "R Packages",
    "text": "R Packages\n\nWhat is an R package\nR comes with a lot of great built-in, ready-to-use functions, but there are plenty of other functions that we might want to use that don’t come built in to R. You can write your own functions in R if you want, but usually someone else has already written the kind of function you want to use. This is where R packages come in.\nThe following description of R packages comes from this R Basics Tutorial from R-Ladies Sydney.\n\nA package is a bundle of code that a generous person has written, tested, and then given away. Most of the time packages are designed to solve a specific problem, so they to pull together functions related to a particular data science problem (e.g., data wrangling, visualisation, inference). Anyone can write a package, and you can get packages from lots of different places, but for beginners the best thing to do is get packages from CRAN, the Comprehensive R Archive Network. It’s easier than any of the alternatives, and people tend to wait until their package is stable before submitting it to CRAN, so you’re less likely to run into problems. You can find a list of all the packages on CRAN here.\n\n\n\nHow to install R packages\n\n\n\n\n\n\n\nNote: Installing packages\n\n\n\nYou should generally only need to install a package one time on your computer. Installing packages is just like downloading any other piece of software on your computer; once you’ve downloaded it once, you have it on your computer unless you delete it.\nInstalling packages is different from loading packages, which we’ll get to next.\n\n\n\n\nLoading Packages\nJust because you installed an R package once, doesn’t mean you want to use it for every task you do in R. Because of this, R will only automatically load a small set of default packages when you launch a new session. Other than the small set of default packages, you’ll need to tell it if you want to use any additional packages. To load a library that isn’t loaded by default, we use the following code:\n\nlibrary(package_name)\n\n\n\n\n\n\n\nNote: Argument Names (continued)\n\n\n\n\n\nJust to reiterate the previous point about argument names, technically the argument name used here in the library() function is called package. This is assumed to be the first argument, and we generally won’t utilize any of the other arguments, which allow you to customize how you want to load a library and if you want anything printed when you load it, etc. But again, we could utilize the argument name like so:\nlibrary(package =  package_name)\n\n\n\nThink of installing and loading R packages as similar to using the Microsoft Word application on your computer. Once you have Microsoft Word installed on your computer, you have the software available to you. But that doesn’t mean Word is always running on your computer. In order to use Word, you have to open the application. This is essentially what we are doing when we load a library–we’re opening it up so we can use it.\n\n\n\n\n\n\nNote: loading packages\n\n\n\n\n\nAnother reason we don’t automatically load all of the packages we’ve ever installed on our computer is because sometimes different packages have functions that are named the same thing (this is because R is open-source)! When this happens, it can be frustrating to try to figure out which version of the function R is using and requires extra code to tell R which version of the function you want to use. To avoid this it is best practice to only load the packages you currently need.\n\n\n\n\n\n\n\n\n\nLoading uninstalled packages\n\n\n\n\n\nRemember that you have to install an R package once before you ever use it. After you’ve installed it once, you don’t need to re-install it, you just need to load it into your session to have access to its contents.\nIf you ever run a line of code like this:\n\nlibrary(mypackage)\n\nand get an error message like this:\n\nError in library(mypackage) : there is no package called ‘mypackage’\n\nthis means you are trying to load a package you haven’t installed yet and you need to run install.packages(\"mypackage\") once first.\n\n\n\n\n\nThe tidyverse package\nThe R tidyverse package is a very useful suite of packages that make data manipulation and visualization clean and efficient. To see all of the packages included in the tidyverse package run the following code to print the names of all packages within the tidyverse suite:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nError message\nOh no! We got another error message. You should see the following error:\n\nError: could not find function “tidyverse_packages”\n\nThis is R’s way of telling you that you’re trying to use a function that it doesn’t have access to. The tidyverse_packages() function comes from the tidyverse package. I have already installed the tidyverse for you in the setup of this tutorial, but I didn’t load it.\nTo give ourselves access to the functions from the tidyverse package, let’s add the line of code library(tidyverse) before the line of code in the chunk above. That should fix the problem.\n\n\n\n\n\n\nExercise:\n\n\n\nAdd the line of code library(tidyverse) before the line of code in the chunk above and try rerunning the code chunk.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\nThe pipe operator from the tidyverse\nOne of the unique functions provided by the tidyverse is called the “pipe operator.” The pipe operator looks like this: %&gt;%. The pipe operator is a way of stringing together a bunch of functions and the purpose is to make your code easier to read.\n\n\n\n\n\n\nNote: %&gt;% vs |&gt;\n\n\n\n\n\nRecent updates to R also let you use |&gt; as the pipe operator, but I’m old so I still use %&gt;% 🙂\n\n\n\nTo see an example of this, consider the following task:\nWe want to know how many unique values are contained in the vector x_vector.\nTo do this, we can start by having R tell us the unique values in x_vector using unique(x_vector). This will give us a vector of the unique values in x_vector. Then, we can print the length of the output of unique(x_vector) using the length() function. This will print out the number of entries in the vector of unique entries of x_vector.\nTo do this, we can use multiple functions simultaneously by nesting the parentheses:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNotice how the order of operations was:\n\nStart with your input x_vector\nDetermine the unique values of x_vector\nCalculate length of unique(x_vector)\n\nHowever, reading left-to-right we see the last step first. This can get particularly confusing when we want to apply multiple sequential functions to the same object in R. Imagine we had wanted to do 3 more functions! This would have read as:\n\nfunction3(function2(function1(length(unique(x_vector)))))\n\nThat’s a lot of parentheses and it’s hard to even figure out where the operation starts! The pipe operator can be helpful in these scenarios. Returning to our example, we can print the number of unique entries of x_vector as follows:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nSee how the output is the same but the order of operations is much clearer in this example? It’s clear that we start with the object x_vector, which we then extract just the unique values from, then finally calculate the length of just the vector of unique values.\nIn the example above with an extra 3 functions at the end, this would read as:\n\nx_vector %&gt;% unique() %&gt;% length() %&gt;% function1() %&gt;% function2()  %&gt;% function3()\n\nStill long, but a lot easier to follow (at least I think so)!"
  },
  {
    "objectID": "posts/Tutorial-2/Tutorial2.html#end-of-tutorial",
    "href": "posts/Tutorial-2/Tutorial2.html#end-of-tutorial",
    "title": "Tutorial 2: R Objects, Functions, and Packages",
    "section": "End of tutorial",
    "text": "End of tutorial\nThat’s it! The next tutorial will be about importing data into R."
  },
  {
    "objectID": "index.html#biost-2041",
    "href": "index.html#biost-2041",
    "title": "BIOST2041",
    "section": "",
    "text": "Resources for learning R"
  },
  {
    "objectID": "posts/Tutorial-3/Tutorial3.html",
    "href": "posts/Tutorial-3/Tutorial3.html",
    "title": "Tutorial 3: Importing and Manipulating Data in R",
    "section": "",
    "text": "In this tutorial, you will learn about working with data in R. In particular, this tutorial will cover…\n\nReading in data from different file types\nData frame structure in R\nUpdating and making new variables\nFiltering data"
  },
  {
    "objectID": "posts/Tutorial-3/Tutorial3.html#introduction",
    "href": "posts/Tutorial-3/Tutorial3.html#introduction",
    "title": "Tutorial 3: Importing Data into R",
    "section": "Introduction",
    "text": "Introduction\nIn this tutorial, you will learn about working with data in R. In particular, this tutorial will cover importing data from various file types into R including:\n\ncsv files\nExcel files\nR data files"
  },
  {
    "objectID": "posts/Tutorial-3/Tutorial3.html#files-on-your-local-computer",
    "href": "posts/Tutorial-3/Tutorial3.html#files-on-your-local-computer",
    "title": "Tutorial 3: Importing and Manipulating Data in R",
    "section": "Files on your local computer",
    "text": "Files on your local computer\nWhen you are working in R on your local computer and you want to import a data file into your R session for an analysis, you will need to tell R where it can find the data file. This is why I suggested creating a ‘data’ folder in your class folder. If you save all of the data files for this class in that folder, you can always use the same general syntax for telling R where your file is.\nFor this tutorial, we are working on the web, so R doesn’t have access to the local files on your device. I have included all of the data files we will be using in this tutorial on a webpage that we can access online. You may need to change this code slightly to when running code for your assignments in this class to work with your computer’s file structure.\n\nChecking your working directory\nOne good idea when you start working on a new analysis is to make sure you know where within your computer’s file structure you are working so you can figure out how to access various files.\nWe can use the function getwd() to have R print out the path to the directory (folder) we are currently working in.\nTry running the code in this block:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nYou should see the output is\n\n“/home/web_user”\n\nThis is because we are working in R on the web. This is telling us that we are in a subdirectory of the “home” directory called “web_user”. That is, “web_user” is a directory (folder) inside the larger directory (folder) called “home”. You read file paths from left to right\nTry running this in your Console in RStudio on your computer, and you should see a file path that corresponds to the file structure on your computer.\n\n\nList files in working directory\nTo check the files that are present in our current directory, we can use the function list.files() to list out all of the files that are stored in the directory where we are currently working.\nTry running the code in this block:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe output should look something like this:\n\n[1] “Rplots.pdf” “cdc.samp.csv” “census.rda” “dds.xlsx”\n\nThis tells us that there are 4 files that we have access to in this directory:\n\na file called “cdc.samp.csv”\na file called “census.rda”\na file called “dds.xlsx”\n\nThere are the data files that we will be working with in this tutorial."
  },
  {
    "objectID": "posts/Tutorial-3/Tutorial3.html#types-of-files",
    "href": "posts/Tutorial-3/Tutorial3.html#types-of-files",
    "title": "Tutorial 3: Importing Data into R",
    "section": "Types of Files",
    "text": "Types of Files\nThe main types of files that we will work with in this class are:\n\n\n\n\n\n\n\n\n\nFile Type\nDescription\nFile Extension\n\n\n\n\nCSV files\nThis stands for “comma separated value”. These are files that have rows with entries separated by commas to indicate the different columns\n.csv\n\n\nExcel files\nFiles in Excel workbook/sheet format\n.xls or .xlsx\n\n\nR data files\nFiles with saved R objects\n.RData or .rda\n\n\n\nThe three files we will use today have the following names:\n\n“cdc_samp.csv” : a csv file with demographic data from the CDC\n“dds.xlsx” : an Excel file with data from the Department of Disability Services in California\n“census.rda”: an R data file with data from the US Census Bureau"
  },
  {
    "objectID": "posts/Tutorial-3/Tutorial3.html#data",
    "href": "posts/Tutorial-3/Tutorial3.html#data",
    "title": "Tutorial 3: Importing and Manipulating Data in R",
    "section": "Data",
    "text": "Data\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "posts/Tutorial-3/Tutorial3.html#importing-data",
    "href": "posts/Tutorial-3/Tutorial3.html#importing-data",
    "title": "Tutorial 3: Importing Data into R",
    "section": "Importing Data",
    "text": "Importing Data\n\nImporting a csv file\nTo import a csv file to R, we can use the function read.csv(). There is a similar function in the tidyverse package called read_csv() that we can also use. We’ll go ahead and use the tidyverse version.\nThe syntax to use this function is:\n\nname_for_data = read_csv(\"path_to_data\")\n\n\nHere name_for_data is any name you choose to call the data frame object that you will be creating with the read_csv() function. It can be helpful to give it a name that is relevant to the data, but you can call it whatever you want (with some limits–for example, the name can’t start with a number).\n\"path_to_data\" is the file path that will tell R where to look for your data. You can either provide the function with an absolute path to the file (starting with the root directory of your computer) or a relative path, starting at the current working directory.\n\n\n\n\n\n\n\nAssigning a name\n\n\n\nWarning: Naming the object is very important!\nIf you forget to choose a name for your data frame, R will import the data and print it, but it won’t save it as an object. If you just use read_csv() without the name_for_data = part, you won’t be able to manipulate or analyze the data.\n\n\n\n\n\n\n\n\nDuplicate names\n\n\n\nAnother warning: If you import two data sets and accidentally give them the same name, the one you import second will overwrite the first one! Sometimes this is useful; for example, if you just want to make a change to a dataset (more on this later). But be careful and when in doubt, give new data frames new names!\n\n\nLet’s try reading in the “cdc_samp.csv” file and give the data frame the name cdc. You may need to add an extra line of code to get this to work (think back to our last tutorial about R functions and packages).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nHint (if you get an error)\n\n\n\n\n\nIf you get the following error:\n\nError: could not find function “read_csv”\n\nyou forgot to load the tidyverse package!\nAdd a line of code above your read_csv() line to load the tidyverse (library(tidyverse)).\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nMaking sure it worked\nGreat! If you were able to get the code chunk above to run without any error messages, then the code should have worked and we should now have an R object named cdc in our environment that we can work with.\nIf we were working in RStudio, we could check to make sure there is an object named cdc under the “Data” heading of the Environment tab (in the upper right-hand corner for most RStudio setups if you didn’t change the panel layout). Since we aren’t working in RStudio, we will use a function to make sure our read_csv() code worked. The function we will use is the exists() function and, as the name suggests, it just tells us if the object we are checking exists in our environment or not. It will return a logical value TRUE if the object exists and FALSE if it does not. The function expects the name of the object in “quotation marks.”\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nIf you were able to run the code above, the output here should be TRUE. If your output says FALSE, go back to the previous section and make sure you can run the code without producing any errors.\n\n\n\nImporting an Excel file\nWe’ve successfully imported a csv file, but what if we get a different file type? For example, a lot of people store data in Excel. Can R handle those files? Yep! But we’re going to need to use a new package called the readxl package.\n\n\n\n\n\n\nReminder: Installing readxl\n\n\n\n\n\nRemember that if you don’t have this package installed on your local computer, you’ll need to install it once before you can load and use it. I’ve already installed it here, but remember that to install the package you can just run install.packages(\"readxl\") in your console in RStudio.\n\n\n\nOnce we have the readxl package loaded, the syntax is very similar to read_csv() from above. There are a few different functions that could work from this package, but the most generic one is read_excel(). The syntax is:\n\nname_for_data = read_excel(\"path_to_data\")\n\nLet’s try it using our ‘dds.xlsx’ file!\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nExercise:\n\n\n\nTry checking to see if this code worked (like we did above) by checking if an object called “dds” exists in our environment.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nRemember to put \"dds\" in quotation marks!\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\nOnce again, this should output the logical value TRUE if the code worked properly. Once you have the readxl package, importing Excel files works just like importing csv files!\n\n\nImporting R data files\nThere is one other type of file that we will use from time to time in this class. This is a special kind of file called an R data file that saves R objects. The syntax is slightly different for this kind of file.\nThe syntax for importing an R data file is:\n\nload(\"path_to_data\")\n\n\n\n\n\n\n\nload()\n\n\n\nNotice how we didn’t include anything on the left side of the load() function here. We didn’t give the data a name!\n\n\nThe reason we don’t assign names to data loaded from an R data file is because these objects already come with a name. Since these are R objects that were saved specifically in a file format that R understands, they keep the name that they were given when they were first created in R. So how do we know what the name is? We can add an extra argument to this function called verbose. The syntax will become:\n\nload(\"path_to_data\", verbose = TRUE)\n\nThis tells R to print out the name of the data object once it is loaded so we know what to call it.\nLet’s see an example of this using our ‘census.rda’ file.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWe can see the message:\n\nLoading objects:  census\n\nThis is telling us that the object we loaded came with the name census. This is the name we should use to refer to that data object.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nNote: file names vs object names\n\n\n\n\n\nThe name of the R object doesn’t have to match with the file name like it did in this example. The file name “census.rda” and the object name census are two independent things. However, it can be helpful to have the file name and object name match, so they often will by convention.\n\n\n\n\n\nOther file types\nThere are other types of files that you may want to import into R. These include text files (.txt) and files from other statistical software packages like SAS (.sas7bdat) or stata (.dta). The syntax for reading in these files is very similar to reading in csv or Excel files so we won’t go into these data types in detail. There are lots of helpful tutorials and R documentation online if you ever need them (for example, this page goes through reading in files from multiple sources)."
  },
  {
    "objectID": "posts/Tutorial-3/Tutorial3.html#getting-set-up",
    "href": "posts/Tutorial-3/Tutorial3.html#getting-set-up",
    "title": "Tutorial 3: Importing Data in R",
    "section": "Getting Set Up",
    "text": "Getting Set Up\n\nFiles on your local computer\nWhen you are working in R on your local computer and you want to import a data file into your R session for an analysis, you will need to tell R where it can find the data file. This is why I suggested creating a ‘data’ folder in your class folder. If you save all of the data files for this class in that folder, you can always use the same general syntax for telling R where your file is.\nFor this tutorial, we are working on the web, so R doesn’t have access to the local files on your device. I have included all of the data files we will be using in this tutorial on a webpage that we can access online. You may need to change this code slightly to when running code for your assignments in this class to work with your computer’s file structure.\n\n\nChecking your working directory\nOne good idea when you start working on a new analysis is to make sure you know where within your computer’s file structure you are working so you can figure out how to access various files.\nWe can use the function getwd() to have R print out the path to the directory (folder) we are currently working in.\nTry running the code in this block:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nYou should see the output is:\n\n\"/home/web_user\"\n\nThis is because we are working in R on the web. This is telling us that we are in a sub-directory of the “home” directory called “web_user”. That is, “web_user” is a directory (folder) inside the larger directory (folder) called “home”. You read file paths from left to right.\n\nTry running this in your Console in RStudio on your computer, and you should see a file path that corresponds to the file structure on your computer.\n\n\n\nFile paths\nFile paths are a way of specifying the location of a file within a computer’s file system. There are two kinds of file paths, absolute paths and relative paths. Both can be useful in different situations.\n\nAbsolute file paths are file paths that start at the root node of your computer (often starting with something like C:\\ in Windows and /Users/ in Unix-like operating systems like mac OS). Absolute paths can get fairly long if files are contained within many levels of sub-directories.\nRelative file paths are paths that start at the current working directory, and are therefore often shorter than absolute paths.\n\nThe function we used above, getwd(), prints absolute paths, so we are currently working in the “web_user” sub-directory of the root directory called “home”. The image below is a visual representation of the file structure.\n\n\n\nList files in working directory\nTo check the files that exist in our current directory, we can use the function list.files() to print a list of all the files that are stored in the directory where we are currently working. If we just want to print the current files we can run the function without giving it a file path (this will assume you want to list the files in your current directory). We could also input a file path to the function\nTry running the code in this block:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nExercise:\n\n\n\nTry running the line of code above with but remove the file path from inside the set of parentheses. Do you notice a difference?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThere shouldn’t be any difference since we used the abosulte path to the current working directory!\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\nThe output should look something like this:\n\n[1] \"Rplots.pdf\" \"data\"\n\nThis tells us that there are 2 objects that we have access to in this directory:\n\na file called “Rplots.pdf”\n\nwe won’t be working with this file\n\na folder called “data”\n\none clue that it’s a folder instead of a file is that it doesn’t have a file extension on the end\n\n\nIf we want to see the files contained within the sub-folder “data”, we can pass the updated file path to the “data” folder by using the absolute path:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nEquivalently, with Relative Path\n\n\n\n\n\nThis code will give us the same output as above:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nOr we could add an argument to the original code that allows us to print files within subdirectoryies recursively.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nAll of these tell us that within the sub-folder called “data”, we have three files:\n\na file called “cdc_samp.csv”\na file called “census.rda”\na file called “dds.xlsx”\n\nThese are the data files that we will be working with in this tutorial."
  },
  {
    "objectID": "posts/Tutorial-3/Tutorial3.html#view-your-data",
    "href": "posts/Tutorial-3/Tutorial3.html#view-your-data",
    "title": "Tutorial 3: Importing and Manipulating Data in R",
    "section": "View your data",
    "text": "View your data\nGreat! We’ve now read our first data file into R. But how do we know if it worked?\n\nThe head() function\nIn RStudio, you should be able to see a new object in your ‘Environment’ tab in the upper-right quadrant of your screen when you import a new data set. Since we’re working on the web, we’ll go ahead and use a different function to take a look at the top few rows of the dataset. The function that will allow us to do this is head() that shows us the top few entries of a data frame, vector, or list.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nHint (if you get an error)\n\n\n\n\n\nIf you get the following error:\n\nError: object ‘cdc’ not found\n\nthis is R’s way of telling you that you don’t currently have an object loaded into your environment called ‘cdc’.\nWhen you see an error like this, you should make sure the code used to import the data worked properly and that you don’t have any spelling errors (R is case sensitive so you have to be very careful to spell things exactly correctly).\nMake sure you were able to successfully run the code above with the read_csv() function without any errors before running this code block.\n\n\n\nAwesome! Here we see the top 6 rows of the cdc dataframe. There are 9 columns:  genhlth, exerany, hlthplan, smoke100, height, weight, wtdesire, age, gender.\n\n\nThe skim() function\nAnother way we can start to take a look at the data is to use a function from the R package skmir. The function is called skim and gives us a nice overview of the contents included in our data.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThis function breaks our columns into groups based on the type of variable they are. Here we see that  genhlth and  gender are characters and the rest are being treated as numeric (even though it looks like we may have a few other binary variables that were coded as 0/1—more on this later).\nThe columns for categorical variables are:\n\n\n\nAttribute\n\n\nDescription\n\n\n\n\nn_missing\n\n\nthe number of rows with missing value (NA) in the corresponding columns\n\n\n\n\ncomplete_rate\n\n\nproportion of rows that are not missing (not NAs)\n\n\n\n\nmin\n\n\nthe minimum character length of values in the column\n\n\n\n\nmax\n\n\nthe maximum character length of values in the column\n\n\n\n\nempty\n\n\nthe number of empty characters in the column\n\n\n\n\nn_unique\n\n\nthe number of unique values in the column\n\n\n\n\nwhitespace\n\n\nthe number of rows containing only white space in the column\n\n\n\nThe columns for numeric variables are:\n\n\n\nAttribute\n\n\nDescription\n\n\n\n\nn_missing\n\n\nthe number of rows with missing value (NA) in the corresponding columns\n\n\n\n\ncomplete_rate\n\n\nproportion of rows that are not missing (not NAs)\n\n\n\n\nmean\n\n\nthe mean (average) value of the non-missing values in the column\n\n\n\n\nsd\n\n\nthe standard deviation of the non-missing values in the column\n\n\n\n\np0\n\n\nthe minimum value observed in the column\n\n\n\n\np25\n\n\nthe 25th percentile of values observed in the column\n\n\n\n\np50\n\n\nthe median (50th percentile) of values observed in the column\n\n\n\n\np75\n\n\nthe 75th percentile of values observed in the column\n\n\n\n\np100\n\n\nthe maximum value observed in the column\n\n\n\n\nhist\n\n\na histogram showing the shape of the distribution of values in the column"
  },
  {
    "objectID": "posts/Tutorial-3/Tutorial3.html#viewing-your-data",
    "href": "posts/Tutorial-3/Tutorial3.html#viewing-your-data",
    "title": "Tutorial 3: Importing Data into R",
    "section": "Viewing Your Data",
    "text": "Viewing Your Data\nGreat! We’ve now imported our first few data files into R. But how do we see the data we imported?\n\nThe head() function\nAgain, in RStudio, you should be able to see a new object in your ‘Environment’ tab in the upper-right quadrant of your screen when you import a new data set. Within this tab, there is an option to view the data by clicking the small white box that appears next to the object name. Since we’re working on the web, we’ll go ahead and use a different function to take a look at the top few rows of the dataset. The function that will allow us to do this is head() that shows us the top few entries of a data frame, vector, or list.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nHint (if you get an error)\n\n\n\n\n\nIf you get the following error:\n\nError: object ‘cdc’ not found\n\nthis is R’s way of telling you that you don’t currently have an object loaded into your environment called ‘cdc’.\nWhen you see an error like this, you should make sure the code used to import the data worked properly and that you don’t have any spelling errors (R is case sensitive so you have to be very careful to spell things exactly correctly).\nMake sure you were able to successfully run the code above with the read_csv() function without any errors before running this code block.\n\n\n\nAwesome! Here we see the top 6 rows of the cdc data frame. There are 9 columns: genhlth, exerany, hlthplan, smoke100, height, weight, wtdesire, age, gender.\n\n\n\n\n\n\ntail() function\n\n\n\n\n\nIf you want to look at the last few entries of an R object, there is a similar function to the head() function called tail().\n\n\n\n\n\nThe skim() function\nAnother way we can start to take a look at the data is to use a function from the R package skmir. The function is called skim and gives us a nice overview of the contents included in our data.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThis function breaks our columns into groups based on the type of variable they are. Here we see that genhlth and gender are characters and the rest are being treated as numeric (even though it looks like we may have a few other binary variables that were coded as 0/1—more on this later). The summary information gives us a snapshot of the contents of each column in the data. More information about the specific sections of the output can be found below.\n\n\n\n\n\n\nUnderstanding skim() output\n\n\n\n\n\nThe columns for categorical variables are:\n\n\n\n\n\n\n\nAttribute\nDescription\n\n\n\n\nn_missing\nthe number of rows with missing value (NA) in the corresponding columns\n\n\ncomplete_rate\nproportion of rows that are not missing (not NAs)\n\n\nmin\nthe minimum character length of values in the column\n\n\nmax\nthe maximum character length of values in the column\n\n\nempty\nthe number of empty characters in the column\n\n\nn_unique\nthe number of unique values in the column\n\n\nwhitespace\nthe number of rows containing only white space in the column\n\n\n\nThe columns for numeric variables are:\n\n\n\n\n\n\n\nAttribute\nDescription\n\n\n\n\nn_missing\nthe number of rows with missing value (NA) in the corresponding columns\n\n\ncomplete_rate\nproportion of rows that are not missing (not NAs)\n\n\nmean\nthe mean (average) value of the non-missing values in the column\n\n\nsd\nthe standard deviation of the non-missing values in the column\n\n\np0\nthe minimum value observed in the column\n\n\np25\nthe 25th percentile of values observed in the column\n\n\np50\nthe median (50th percentile) of values observed in the column\n\n\np75\nthe 75th percentile of values observed in the column\n\n\np100\nthe maximum value observed in the column\n\n\nhist\na histogram showing the shape of the distribution of values in the column\n\n\n\n\n\n\n\n\nThe View() function\nWhen we’re working in RStudio, we can also use the View() function to look at an entire data frame. This will open up a spreadsheet-like data viewer in a new tab in RStudio where you can scroll through all the rows and columns in a data frame. We can’t use this here or in R Markdown files (which can knit to PDF or HTML, for example) because it requires opening a new data viewer tab. It is a useful function when you’re working interactively in RStudio, though!"
  },
  {
    "objectID": "posts/Tutorial-3/Tutorial3.html#reading-in-an-excel-file",
    "href": "posts/Tutorial-3/Tutorial3.html#reading-in-an-excel-file",
    "title": "Tutorial 3: Importing and Manipulating Data in R",
    "section": "Reading in an Excel file",
    "text": "Reading in an Excel file\nWe’ve successfully read in a csv file, but what if we get a different file type? For example, a lot of people store data in Excel. Can R handle those files? Yep! But we’re going to need to use a new package called the readxl package.\n\n\n\n\n\n\nReminder: Installing readxl\n\n\n\n\n\nRemember that if you don’t have this package installed on your local computer, you’ll need to install it before you can load and use it. I’ve already installed it here, but remember that to install the package you can just run install.packages(\"readxl\") in your console in R Studio.\n\n\n\nOnce we have the readxl package loaded, the syntax is very similar to read_csv() from above. There are a few different functions that could work from this package, but the most generic one is read_excel(). The syntax is:\n\nname_for_data = read_excel(\"path_to_data\")\n\nLet’s try it using our ‘dds.xlsx’ file!\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nAwesome! We can see that there are 6 columns in this data set:  id, age.cohort, age, gender, expenditure, ethnicity.\nOnce you have the readxl package, importing Excel files works just like reading in csv files!"
  },
  {
    "objectID": "posts/Tutorial-3/Tutorial3.html#r-data-files",
    "href": "posts/Tutorial-3/Tutorial3.html#r-data-files",
    "title": "Tutorial 3: Importing and Manipulating Data in R",
    "section": "R data files",
    "text": "R data files\nThere is one other type of file that we will use from time to time in this class. This is a special kind of file called an R data file that saves R objects. The syntax is slightly different for these kinds of files.\nThe syntax for importing an R data file is:\n\nload(\"path_to_data\")\n\n\n\n\n\n\n\nload()\n\n\n\nNotice how we didn’t include anything on the left side of the load() function here. We didn’t give the data a name!\n\n\nThe reason we don’t assign names to data loaded from an R data file is because these objects already come with a name. Since these are R objects that were saved specifically in a file format that R understands, they keep the name that they were given when they were first created in R. So how do we know what the name is? We can add an extra argument to this function called verbose. The syntax will become:\n\nload(\"path_to_data\", verbose = TRUE)\n\nThis tells R to print out the name of the data object once it is loaded so we know what to call it.\nLet’s see an example of this using our ‘census.rda’ file.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWe can see the message:\n\nLoading objects: census"
  },
  {
    "objectID": "posts/QQ_plot_shiny/QQshiny.html",
    "href": "posts/QQ_plot_shiny/QQshiny.html",
    "title": "QQ Plot Visualization Tool",
    "section": "",
    "text": "#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 600\n\nlibrary(shiny)\nlibrary(tidyverse)\n\n# Define UI for application that draws a histogram\nui &lt;- fluidPage(\n   \n   # Application title\n   titlePanel(\"QQ Plot Visualization\"),\n   \n      \n      # Show a plot of the generated distribution\n        tabsetPanel(type = \"tabs\",\n          tabPanel(\"Data-to-Normal Comparison\",\n                  sidebarLayout( \n                    sidebarPanel(\n                      radioButtons(\"skew\", \"Distribution\",\n                                 choices = c(\"Right Skew\",\n                                           \"Left Skew\",\n                                              \"Symmetric (light tails)\",\n                                              \"Symmetric (heavy tails)\",\n                                              \"Symmetric (Normal)\"),\n                                             selected = \"Symmetric (Normal)\"),\n                                checkboxInput(\"scaled\",\n                                              \"Scaled QQ-Plot\",\n                                              value = FALSE)\n                   ),\n                   mainPanel( plotOutput(\"dataPlot\",height = \"300px\"),\n                      plotOutput(\"quantPlot\",height = \"350px\"),\n                       plotOutput(\"qqPlot\")))),\n          tabPanel(\"Data-to-Data Comparison\",\n                   sidebarLayout( \n                     sidebarPanel(\n                          radioButtons(\"x1\", \"Sample 1 Distribution\",\n                                             choices = c(\"Right Skew\",\"Left Skew\",\n                                                         \"Symmetric (light tails)\",\n                                                         \"Symmetric (heavy tails)\",\n                                                         \"Symmetric (Normal)\"),\n                                             selected = \"Symmetric (Normal)\"),\n                                radioButtons(\"x2\", \"Sample 2 Distribution\",\n                                             choices = c(\"Right Skew\",\"Left Skew\",\n                                                         \"Symmetric (light tails)\",\n                                                         \"Symmetric (heavy tails)\",\n                                                         \"Symmetric (Normal)\"),\n                                             selected = \"Right Skew\"),\n                                sliderInput(\"VR\",\n                                            HTML(\"SD Ratio (&#963;&lt;sub&gt;2&lt;/sub&gt;/&#963;&lt;sub&gt;1&lt;/sub&gt;)\"),\n                                            min = 0.1, max = 2, value = 1,round=-1,ticks = F),\n                                sliderInput(\"means\",\n                                            HTML(\"Mean Shift (&#956;&lt;sub&gt;2&lt;/sub&gt;-&#956;&lt;sub&gt;1&lt;/sub&gt;)\"),\n                                            min = -2, max = 2, value = 0,step=.1,round=-1,ticks = F),\n                                \n                   ),\n                   mainPanel(\n                     plotOutput(\"dataPlot2\",height = \"300px\"),\n                   plotOutput(\"quantPlot2\",height = \"300px\"),\n                   plotOutput(\"qqPlot2\")))\n        )\n    \n      )\n)\n\n\n# Define server logic required to draw a histogram\nserver &lt;- function(input, output) {\n\n  set.seed(1234)\n  \n  vals&lt;-reactiveValues(x=NULL, quants=NULL, quants_t=NULL,m=NULL,s=NULL,x2=NULL)\n  \nobserveEvent({input$skew\n             input$scaled},{\n  if(input$skew == \"Left Skew\"){vals$x&lt;-rbeta(10000,5,1)\n  } else if(input$skew == \"Right Skew\"){vals$x&lt;-rbeta(10000,1,5)\n  } else if(input$skew == \"Symmetric (light tails)\"){vals$x&lt;-c(rnorm(5000,mean=-1.5),rnorm(5000,mean=1.5))\n  } else if (input$skew == \"Symmetric (heavy tails)\"){vals$x&lt;-c(rt(10000,df=4))\n  }else {vals$x&lt;-rnorm(10000,mean = 0, sd = 1)}\n\n  vals$quants=data.frame( q5 = quantile(vals$x,.05),\n                     q10 = quantile(vals$x,.1),\n                     q25 = quantile(vals$x,.25),\n                     q50 = quantile(vals$x,.5),\n                     q75 = quantile(vals$x,.75),\n                     q90 = quantile(vals$x,.9),\n                     q95 = quantile(vals$x,.95))%&gt;%\n    pivot_longer(1:7, names_to = \"quantile\",values_to=\"qx\")%&gt;%\n    mutate(type=\"Sample Data\")%&gt;%\n    mutate(quantile = factor(quantile,levels = paste0(\"q\",c(5,10,25,50,75,90,95))))\n\n  \n  if(input$scaled){\n    vals$m = 0\n    vals$s = 1\n    vals$quants_t=data.frame(q5 = qnorm(.05),\n                        q10 = qnorm(.1),\n                        q25 = qnorm(.25),\n                        q50 = qnorm(.5),\n                        q75 = qnorm(.75),\n                        q90 = qnorm(.9),\n                        q95 = qnorm(.95)\n    )%&gt;%\n      pivot_longer(1:7, names_to = \"quantile\",values_to=\"qx\")%&gt;%\n      mutate(type=\"Theoretical Normal\")%&gt;%\n      mutate(quantile = factor(quantile,levels = paste0(\"q\",c(5,10,25,50,75,90,95))))\n  } else {\n    vals$m = mean(vals$x)\n    vals$s = (quantile(vals$x,.75)-quantile(vals$x,.25))/(qnorm(.75)-qnorm(.25))\n    s=vals$s; m=vals$m\n    vals$quants_t=data.frame(q5 = qnorm(.05,mean=m,sd=s),\n                              q10 = qnorm(.1,mean=m,sd=s),\n                              q25 = qnorm(.25,mean=m,sd=s),\n                              q50 = qnorm(.5,mean=m,sd=s),\n                              q75 = qnorm(.75,mean=m,sd=s),\n                              q90 = qnorm(.9,mean=m,sd=s),\n                              q95 = qnorm(.95,mean=m,sd=s)\n  )%&gt;%\n    pivot_longer(1:7, names_to = \"quantile\",values_to=\"qx\")%&gt;%\n    mutate(type=\"Theoretical Normal\")%&gt;%\n    mutate(quantile = factor(quantile,levels = paste0(\"q\",c(5,10,25,50,75,90,95))))}\n})\n   \n   output$dataPlot &lt;- renderPlot({\n     data.frame(x=vals$x)%&gt;%\n       ggplot(aes(x=x))+\n       geom_histogram(aes(y = ..density..),\n                      fill=\"grey\",color = \"black\")+\n       geom_function(fun = function(x) dnorm(x, mean=mean(vals$x),sd=sd(vals$x)),color = \"blue\")+\n       theme_bw()+\n       labs(title=\"Sample Data\")+xlim(mean(vals$x)-4*sd(vals$x),mean(vals$x)+4*sd(vals$x))\n   })\n   \n   output$quantPlot &lt;- renderPlot({\n     p1=vals$quants%&gt;%\n       ggplot()+\n       geom_density(data = data.frame(x=vals$x),aes(x=x))+\n       theme_bw()+\n       labs(title = \"Smoothed Data with Quantiles\")+\n       geom_vline(aes(xintercept=qx,color = quantile),size=.4)+\n       theme(legend.position = \"none\")+xlim(mean(vals$x)-4*sd(vals$x),mean(vals$x)+4*sd(vals$x))\n     \n     if(input$scaled){min=-4; mx = 4;clr = \"darkred\"\n     }else{min =mean(vals$x)-4*sd(vals$x);mx = mean(vals$x)+4*sd(vals$x);clr=\"blue\" }\n     p2 = data.frame(x = seq(min(vals$x),max(vals$x),by=sd(vals$x)/20))%&gt;%\n       ggplot(aes(x=x))+\n       geom_function(fun = dnorm,args=list(mean=vals$m, sd=vals$s),color = clr)+\n       theme_bw()+\n       labs(title = \"Theoretical Normal Distribution\",y=\"density\")+\n       geom_vline(data=vals$quants_t,aes(xintercept=qx,color = quantile),size=.4)+\n       theme(legend.position = \"bottom\",legend.title = element_blank())+xlim(min,mx)\n     gridExtra::grid.arrange(p1,p2,nrow=2,heights=c(.85,1.1))\n   })\n\n  \n   output$qqPlot &lt;- renderPlot({\n     if(input$scaled){clr = \"darkred\"\n     }else{clr=\"blue\" }\n     data.frame(smp=vals$x)%&gt;%\n       ggplot()+\n       geom_qq(aes(sample=smp),\n               dparams = list(mean = vals$m, sd = vals$s))+\n       geom_qq_line(aes(sample=smp),\n                    dparams = list(mean = vals$m, sd = vals$s))+\n       geom_point(data = left_join(vals$quants%&gt;%rename(y=qx),vals$quants_t%&gt;%rename(x=qx),\n                                   by=\"quantile\")%&gt;%\n                    mutate(quantile = factor(quantile,levels = paste0(\"q\",c(5,10,25,50,75,90,95)))),\n                  aes(x=x,y=y,color = quantile),size=2)+\n       theme_bw()+\n       labs(x = \"Theoretical Quantiles\", y = \"Observed Quantiles\")+\n       theme(legend.position = \"bottom\",legend.title = element_blank(),axis.title.x = element_text(color = clr))\n     \n     \n     \n   })\n   vals2&lt;-reactiveValues(x1=NULL, x2= NULL, quants1=NULL, quants2=NULL)\n   \n   observeEvent({input$x1\n     input$x2\n     input$means\n     input$VR},{\n       if(input$x1 == \"Left Skew\"){vals2$x1&lt;-(rbeta(10000,5,1)-5/6)/sd(rbeta(10000,5,1))\n       } else if(input$x1 == \"Right Skew\"){vals2$x1&lt;-(rbeta(10000,1,5)-1/6)/sd(rbeta(10000,1,5))\n       } else if(input$x1 == \"Symmetric (light tails)\"){vals2$x1&lt;-c(rnorm(5000,mean=-1.5),rnorm(5000,mean=1.5))/1.8\n       } else if (input$x1 == \"Symmetric (heavy tails)\"){vals2$x1&lt;-c(rt(10000,df=4))/sd(rt(10000,df=4))\n       }else {vals2$x1&lt;-rnorm(10000,mean = 0, sd = 1)}\n\n\n       if(input$x2 == \"Left Skew\"){vals2$x2&lt;-(rbeta(10000,5,1)-5/6)/sd(rbeta(10000,5,1))\n       } else if(input$x2 == \"Right Skew\"){vals2$x2&lt;-(rbeta(10000,1,5)-1/6)/sd(rbeta(10000,1,5))\n       } else if(input$x2 == \"Symmetric (light tails)\"){vals2$x2&lt;-c(rnorm(5000,mean=-1.5),rnorm(5000,mean=1.5))/1.8\n       } else if (input$x2 == \"Symmetric (heavy tails)\"){vals2$x2&lt;-c(rt(10000,df=4))/sd(rt(10000,df=4))\n       }else {vals2$x2&lt;-rnorm(10000,mean = 0, sd = 1)}\n      \n       \n       vals2$x2 =vals2$x2*input$VR+input$means\n       \n       vals2$quants1=data.frame( q5 = quantile(vals2$x1,.05),\n                               q10 = quantile(vals2$x1,.1),\n                               q25 = quantile(vals2$x1,.25),\n                               q50 = quantile(vals2$x1,.5),\n                               q75 = quantile(vals2$x1,.75),\n                               q90 = quantile(vals2$x1,.9),\n                               q95 = quantile(vals2$x1,.95))%&gt;%\n         pivot_longer(1:7, names_to = \"quantile\",values_to=\"qx\")%&gt;%\n         mutate(type=\"Sample Data 1\")%&gt;%\n         mutate(quantile = factor(quantile,levels = paste0(\"q\",c(5,10,25,50,75,90,95))))\n       vals2$quants2=data.frame( q5 = quantile(vals2$x2,.05),\n                                 q10 = quantile(vals2$x2,.1),\n                                 q25 = quantile(vals2$x2,.25),\n                                 q50 = quantile(vals2$x2,.5),\n                                 q75 = quantile(vals2$x2,.75),\n                                 q90 = quantile(vals2$x2,.9),\n                                 q95 = quantile(vals2$x2,.95))%&gt;%\n         pivot_longer(1:7, names_to = \"quantile\",values_to=\"qx\")%&gt;%\n         mutate(type=\"Sample Data 2\")%&gt;%\n         mutate(quantile = factor(quantile,levels = paste0(\"q\",c(5,10,25,50,75,90,95))))\n       \n     })\n   \n   output$dataPlot2 &lt;- renderPlot({\n     data.frame(x=c(vals2$x1, vals2$x2),\n                dt = rep(c(\"Sample 1\",\"Sample 2\"), each = 10000))%&gt;%\n       ggplot(aes(x=x,group = dt))+\n       geom_histogram(aes(y = ..density..),\n                      fill=\"grey\",color = \"black\")+\n       theme_bw()+\n       facet_wrap(.~dt, nrow = 2)+\n       labs(title=\"Sample Data\")\n   })\n   \n   \n   \n   output$quantPlot2 &lt;- renderPlot({\n     plotmin = min(c(mean(vals2$x1)-4*sd(vals2$x1),mean(vals2$x2)-4*sd(vals2$x2)) )\n     plotmx = max(c(mean(vals2$x1)+4*sd(vals2$x1),mean(vals2$x2)+4*sd(vals2$x2)) )\n     p1=vals2$quants1%&gt;%\n       ggplot()+\n       geom_density(data = data.frame(x=vals2$x1),aes(x=x))+\n       theme_bw()+\n       labs(title = \"Smoothed Sample 1 with Quantiles\")+\n       geom_vline(aes(xintercept=qx,color = quantile),size=.4)+\n       theme(legend.position = \"none\")+xlim(plotmin, plotmx)\n     \n     p2=vals2$quants2%&gt;%\n       ggplot()+\n       geom_density(data = data.frame(x=vals2$x2),aes(x=x))+\n       theme_bw()+\n       labs(title = \"Smoothed Sample 2 with Quantiles\")+\n       geom_vline(aes(xintercept=qx,color = quantile),size=.4)+\n       theme(legend.position = \"none\")+xlim(plotmin, plotmx)\n     \n     gridExtra::grid.arrange(p1,p2,nrow=2)\n   })\n   \n   \n   \n   output$qqPlot2 &lt;- renderPlot({\n     plotmin = min(quantile(vals2$x1,.001),quantile(vals2$x2,.001) )\n     plotmx = max(quantile(vals2$x1,.999),quantile(vals2$x2,.999) )\n     data.frame(x=vals2$x1, y = vals2$x2)%&gt;%\n       ggplot()+\n       geom_point(aes(x=sort(x),y=sort(y)))+\n       geom_abline(slope = 1, intercept = 0)+\n       geom_point(data = left_join(vals2$quants1%&gt;%rename(x=qx),vals2$quants2%&gt;%rename(y=qx),\n                                   by=\"quantile\")%&gt;%\n                    mutate(quantile = factor(quantile,levels = paste0(\"q\",c(5,10,25,50,75,90,95)))),\n                  aes(x=x,y=y,color = quantile),size=2)+\n       theme_bw()+\n       labs(x = \"Sample 1\", y = \"Sample 2\")+\n       theme(legend.position = \"bottom\",legend.title = element_blank())+\n       xlim(plotmin,plotmx)+ylim(plotmin,plotmx)\n    \n     \n     \n   })\n}\n\n# Run the application \nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "index.html#shiny-apps",
    "href": "index.html#shiny-apps",
    "title": "Intro Biostatistics Resources",
    "section": "Shiny Apps",
    "text": "Shiny Apps\n\n\n\n\n\n\n\n\n\n\nANOVA\n\n\n\nStatistical Inference\n\n\n\nApp to demonstrate intuition behind ANOVA\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCollinearity in MLR\n\n\n\nRegression\n\n\n\nApp to demonstrate how collinearity leads to variance inflation\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConfidence Intervals and Prediction Intervals\n\n\n\nStatistical Inference\n\n\nRegression\n\n\n\nApp to demonstrate intuition behind confidence vs prediction intervals\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInference For Proportions\n\n\n\nSampling Distributions\n\n\nStatistical Inference\n\n\n\nApp to visualize Z-test and exact binomial tests for proportions\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInference Visualization\n\n\n\nSampling Distributions\n\n\nStatistical Inference\n\n\n\nApp to visualize the relationship between confidence intervals and hypothesis testing\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLOESS Smoother\n\n\n\nRegression\n\n\n\nApp to demonstrate underlying mechanism of LOESS smoother\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeast Squares Regression Visualization\n\n\n\nRegression\n\n\n\nApp to visualize the method of least squares\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLogistic Function Visualization\n\n\n\nRegression\n\n\n\nApp to show the relationship between log odds and probability (logistic regression)\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultiple Linear Regression\n\n\n\nRegression\n\n\n\nApp to visualize regression with multiple predictors; adjusting for other covariates\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaired vs Unpaired T: Variance\n\n\n\nStatistical Inference\n\n\n\nApp to the variance of the difference of two sample means when data are correlated vs uncorrelated\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPower and Sample Size\n\n\n\nSampling Distributions\n\n\nStatistical Inference\n\n\n\nApp to visualize statistical power\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQQ Plot Visualization Tool\n\n\n\nProbability Distributions\n\n\n\nApp to understand QQ plots\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nROC Curves\n\n\n\nRegression\n\n\n\nApp to visualize ROC curves, sensitivity, and specificity\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRegularization\n\n\n\nRegression\n\n\n\nApp to demonstrate how regularized regression works\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSampling Activity\n\n\n\nSampling Distributions\n\n\n\nIn-class activity to simulate a sampling distribution\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSampling Distributions and Bootstrapping\n\n\n\nStatistical Inference\n\n\n\nApp to visualize bootstrapping\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStandard Normal Distribution Visualization\n\n\n\nProbability Distributions\n\n\n\nApp to visualize standard normal probabilities and quantiles\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nT Test Visualization\n\n\n\nStatistical Inference\n\n\n\nApp to show intuition behind t-tests\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nT under null vs alt\n\n\n\nStatistical Inference\n\n\n\nApp to demonstrate distribution of test statistics under null and alternative\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "About",
      "Home"
    ]
  },
  {
    "objectID": "index.html#r-tutorials",
    "href": "index.html#r-tutorials",
    "title": "Intro Biostatistics Resources",
    "section": "",
    "text": "R Tutorials\n\n\n\n\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR Tutorials\n\n\n\n\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR Tutorials\n\n\n\n\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR Tutorials\n\n\n\n\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR Tutorials\n\n\nExploratory Data Analysis (EDA)\n\n\n\n\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR Tutorials\n\n\nExploratory Data Analysis (EDA)\n\n\n\n\n\n\n\nHaley Grant\n\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "About",
      "Home"
    ]
  },
  {
    "objectID": "posts/SamplingDistShiny/SampDist_shiny.html",
    "href": "posts/SamplingDistShiny/SampDist_shiny.html",
    "title": "Sampling Distributions and Bootstrapping",
    "section": "",
    "text": "#| standalone: true\n#| viewerHeight: 600\n#\n\nlibrary(shiny)\nlibrary(tidyverse)\n\n# Define UI for application that draws a histogram\nui &lt;- fluidPage(\n  \n  tags$style(type=\"text/css\",\n             \".shiny-output-error { visibility: hidden; }\",\n             \".shiny-output-error:before { visibility: hidden; }\"\n  ),\n    # Application title\n    titlePanel(\"Sampling Distributions and Bootstrapping\"),\n\n    # Sidebar with a slider input for number of bins \n    sidebarLayout(\n        sidebarPanel(\n            sliderInput(\"n\",\n                        \"Sample Size:\",\n                        min = 5,\n                        max = 200,\n                        value = 15),\n            selectInput(\"shape\", \n                        label = \"Shape of Original Variable\", \n                        choices = list(\"Normal\", \"Skewed\"),\n                        selected = \"Normal\"),\n            selectInput(\"stat\", \n                        label = \"Statistic of Interest\", \n                        choices = list(\"Mean\", \"Median\",\"75th Percentile\"),\n                        selected = \"Mean\"),\n            selectInput(\"sig.level\",\n                        label = \"Significance Level\",\n                        choices = c(0.01, 0.05, 0.10),\n                        selected = 0.05),\n            actionButton(\"resamp\",\n                          \"Sample from Population\"),\n            actionButton(\"reset\",\n                         \"Reset\")\n        ),\n\n        # Show a plot of the generated distribution\n        mainPanel(\n          textOutput(\"popstats\"), \n          fluidRow(\n            splitLayout(cellWidths = c(\"50%\", \"50%\"), \n                        plotOutput(\"popPlot\",height = \"200px\"), \n                        plotOutput(\"sampPlot\", height = \"200px\")\n          )),\n          plotOutput(\"bootsamps3\",height = \"200px\"),\n          fluidRow(\n            splitLayout(cellWidths = c(\"50%\", \"50%\"), \n                        plotOutput(\"bootstatdist\",height = \"200px\"),\n                        plotOutput(\"iterplot\",height = \"200px\")))\n          \n        )\n    )\n)\n\n# Define server logic required to draw a histogram\nserver &lt;- function(input, output) {\n  \n  vals&lt;-reactiveValues(x = NULL, bootsamps = NULL,popstat = NULL,\n                       bootci = NULL, iters = data.frame(), i = 0)\n  \n  observeEvent({input$shape\n    input$stat\n    input$sig.level\n    input$n\n    input$resamp},{\n  \n  if(input$shape==\"Normal\"){vals$x = rnorm(input$n, mean = 10, sd = 3) \n  if(input$stat == \"Mean\"){vals$popstat = 10\n  } else if(input$stat == \"Median\"){vals$popstat = 10\n  } else if (input$stat == \"75th Percentile\"){vals$popstat = qnorm(0.75,mean = 10, sd = 3 ) }\n  \n  } else{vals$x = rexp(input$n, rate = 0.1) \n  if(input$stat == \"Mean\"){vals$popstat = 1/.1\n  } else if(input$stat == \"Median\"){vals$popstat = qexp(0.5, rate = 0.1)\n  } else if (input$stat == \"75th Percentile\"){vals$popstat = qexp(0.75,rate = 0.1 ) }\n  }\n      \n  vals$bootsamps &lt;- lapply(1:10000, function(i) \n      data.frame(iter=i, s=sample(vals$x, length(vals$x), replace = T)))%&gt;%\n    plyr::ldply() %&gt;%\n    group_by(iter) %&gt;%\n    mutate(stat = ifelse(input$stat==\"Mean\", mean(s),\n                         ifelse(input$stat==\"Median\", median(s),\n                                quantile(s,.75))))\n  \n  vals$bootci &lt;- list(lower = quantile(vals$bootsamps$stat[seq(1,input$n*10000, by = input$n )],as.numeric(input$sig.level)/2)%&gt;%round(4),\n                 upper = quantile(vals$bootsamps$stat[seq(1,input$n*10000, by = input$n )],1-as.numeric(input$sig.level)/2)%&gt;%round(4))\n  \n  vals$i = vals$i+1\n  vals$iters = bind_rows(vals$iters,\n    data.frame(x=vals$x)%&gt;%\n    summarise(stat = ifelse(input$stat==\"Mean\", mean(x),\n                         ifelse(input$stat==\"Median\", median(x),\n                                      quantile(x,.75)))) %&gt;%\n    mutate(upper = vals$bootci$upper, lower =vals$bootci$lower, \n           iter = vals$i))\n  \n  })\n\n  observeEvent({input$reset}, {\n\n    vals$iters=data.frame()\n    vals$i = 0\n    vals$bootsamps = NULL\n    vals$x = NULL\n\n    })\n  \n  \n  output$popstats &lt;- renderText({\n    paste0(input$stat, \" in population: \", vals$popstat)\n  })\n  output$popPlot &lt;- renderPlot({\n    if(input$shape==\"Normal\"){\n    data.frame(x=0:20) %&gt;%\n      ggplot(aes(x = x)) + \n      stat_function(fun = dnorm, args = list(mean = 10, sd = 3) ) +\n      theme_bw() +\n      labs(x = \"Variable X\", title = \"Population Distribution\")\n    } else {\n      data.frame(x=0:50) %&gt;%\n        ggplot(aes(x = x)) + \n        stat_function(fun = dexp, args = list(rate=.1) ) +\n        theme_bw() +\n        labs(x = \"Variable X\", title = \"Population Distribution\")\n    }\n    \n  })\n    output$sampPlot &lt;- renderPlot({\n      data.frame(x = vals$x) %&gt;%\n        ggplot(aes(x = x)) + \n        geom_histogram(bins = min(round(input$n/2),30),\n                       color = \"black\", fill = \"skyblue\") + \n        theme_bw()+\n        labs(x = \"Variable X\", title = \"Sample\")\n    })\n    \n    output$bootsamps3 &lt;- renderPlot({\n      vals$bootsamps%&gt;%\n        filter(iter&lt;=3)%&gt;%\n        mutate(iter = paste0(\"Boostrap Sample \",iter))%&gt;%\n      ggplot(aes(x=s)) + \n        geom_histogram(bins = min(round(input$n/2),30),\n                       color = \"black\", fill = \"skyblue4\") + \n        theme_bw() +\n        facet_wrap(.~iter, nrow = 1) + \n        geom_vline(aes(xintercept = stat), color = \"firebrick1\") + \n        labs(x = \"Variable X\", title = \"Example Bootstrap Samples\")\n    })\n    \n    output$bootstatdist &lt;- renderPlot({\n     vals$bootsamps %&gt;%\n        group_by(iter)%&gt;%\n        summarise(stat = first(stat))%&gt;%\n        ggplot(aes(x=stat)) + \n        geom_histogram(bins = min(round(input$n/2),30),\n                       color = \"black\", fill = \"firebrick1\") + \n        theme_bw() +\n        geom_vline(xintercept = unlist(vals$bootci), linetype = 2) + \n        labs(x = paste0(\"Bootstrap\", input$stat), title = \"Bootstrap Sampling Distribution\",\n             subtitle = input$stat)\n    })\n    \n \n    output$bootci = renderText(\n      paste0(\"Bootstrap CI: (\",vals$bootci$lower, \", \", \n             vals$bootci$upper,\")\" ))\n    \n    output$iterplot = renderPlot({\n      vals$iters %&gt;%\n        mutate(covers = case_when(\n          upper&gt;=vals$popstat & lower &lt;= vals$popstat ~ \"Covers True Parameter\",\n          upper&lt;vals$popstat | lower &gt; vals$popstat~\"Does Not Cover Parameter\"))%&gt;%\n        bind_rows(data.frame(covers = \"Covers True Parameter\", lower = NA, upper = NA, stat = NA))%&gt;%\n        ggplot(aes(x = stat, y = iter, color = covers))+\n        geom_point()+\n        theme_bw()+\n        scale_color_manual(values = c( \"#00BFC4\",\"#F8766D\")) + \n        geom_errorbarh(aes(xmin = lower, xmax = upper))+\n        geom_vline(xintercept = vals$popstat) + \n        labs(x = \"Bootstrap CI\", y = \"Iteration\",color = element_blank())\n    })\n\n  \n}\n\n# Run the application \nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "posts/LeastSquaresShiny/LeastSquares_shiny.html",
    "href": "posts/LeastSquaresShiny/LeastSquares_shiny.html",
    "title": "Least Squares Regression Visualization",
    "section": "",
    "text": "#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 700\n\nlibrary(shiny)\nlibrary(tidyverse)\n\n\n\n# Define UI for application that draws a histogram\nui &lt;- fluidPage(\n\n    # Application title\n    titlePanel(\"Least Squares Regression\"),\n\n    tabsetPanel(\n      tabPanel(\"Slope and Intercept\", fluid = TRUE,\n    # Sidebar with a slider input for number of bins \n    sidebarLayout(\n        sidebarPanel(\n          sliderInput(\"realslope\",\n                      \"True Slope\",\n                      min = -2,\n                      max = 2,\n                      value = 0, step = .01),\n          sliderInput(\"realintercept\",\n                      \"True Intercept\",\n                      min = -10,\n                      max = 10,\n                      value = 0,step = .01),\n            sliderInput(\"slope\",\n                        \"Slope\",\n                        min = -2,\n                        max = 2,\n                        value = 0, step = .01),\n            sliderInput(\"intercept\",\n                        \"Intercept\",\n                        min = -10,\n                        max = 10,\n                        value = 0,step = .01)\n            \n        ),\n\n        # Show a plot of the generated distribution\n        mainPanel(\n          plotOutput(\"regplot\"),\n          plotOutput(\"seplot\")\n        ))\n    ), tabPanel(\"Slope through means\", fluid = TRUE,\n                # Sidebar with a slider input for number of bins \n                sidebarLayout(\n                  sidebarPanel(\n                    sliderInput(\"realslope2\",\n                                \"True Slope\",\n                                min = -2,\n                                max = 2,\n                                value = 0, step = .01),\n                    sliderInput(\"realintercept2\",\n                                \"True Intercept\",\n                                min = -10,\n                                max = 10,\n                                value = 0,step = .01),\n                    sliderInput(\"slope2\",\n                                \"Slope\",\n                                min = -2,\n                                max = 2,\n                                value = 0, step = .01),\n),\n                \n                # Show a plot of the generated distribution\n                mainPanel(\n                  plotOutput(\"regplot2\"),\n                  plotOutput(\"seplot2\")\n                ))\n    )\n)\n)\n\n\n\n# Define server logic required to draw a histogram\nserver &lt;- function(input, output) {\n\n   vals&lt;-reactiveValues(df = NULL, se = NULL, x=NULL, y = NULL)\n   vals2 &lt;-reactiveValues(df = NULL, se = NULL, x=NULL, y = NULL)\n  observeEvent({ input$slope\n     input$intercept\n     input$realslope\n     input$realintercept},\n     {  x = runif(50, min = 18, max = 40)\n     y = input$realintercept + input$realslope*x + rnorm(50, sd = 2)\n       vals$df = data.frame(x=x, y=y)%&gt;% \n       mutate(s = input$slope,\n          i = input$intercept)%&gt;%\n       mutate(estimated = i + s*x)%&gt;%\n       mutate(error = y-estimated)\n     vals$se = sum(vals$df$error^2)/nrow(vals$df)\n     })\n   \n  observeEvent({ input$slope2\n    input$realslope2\n    input$realintercept2},\n    {  x = runif(50, min = 18, max = 40)\n    y = input$realintercept2 + input$realslope2*x + rnorm(50, sd = 2)\n    vals2$df = data.frame(x=x, y=y)%&gt;% \n      mutate(s = input$slope2,\n             i = mean(y) - mean(x)*input$slope2)%&gt;%\n      mutate(estimated = i + s*x)%&gt;%\n      mutate(error = y-estimated)\n    vals2$se = sum(vals2$df$error^2)/nrow(vals2$df)\n    })\n  \n  \n   \n   output$regplot &lt;- renderPlot({\n     vals$df %&gt;%\n       ggplot(aes(x = x, y=y)) + \n       geom_point() +\n       geom_point(aes(y = estimated), color = \"skyblue\", alpha = 0.5) +\n       geom_abline(aes(intercept = i, slope = s), color = \"skyblue\")  +\n     geom_errorbar(aes(ymin = y, ymax = estimated), color = \"skyblue\", linetype=2) + \n     theme_bw()\n     })\n   \n   output$seplot &lt;- renderPlot({\n     vals$df %&gt;%\n       ggplot(aes(x = x, y=y)) + \n       geom_point() +\n       geom_point(aes(y = estimated), color = \"skyblue\", alpha = 0.5) +\n       geom_abline(aes(intercept = i, slope = s), color = \"skyblue\")  +\n       geom_rect(aes(ymin = y, ymax = estimated, xmin = x, xmax = x-error), \n                 fill = \"firebrick1\", alpha = 0.1, color = \"firebrick1\") + \n       theme_bw() + \n       labs(title = paste0(\"Mean Squared Error: \", vals$se)) \n\n   })\n   \n   output$regplot2 &lt;- renderPlot({\n     vals2$df %&gt;%\n       ggplot(aes(x = x, y=y)) + \n       geom_point() +\n       geom_point(aes(y = estimated), color = \"skyblue\", alpha = 0.5) +\n       geom_abline(aes(intercept = i, slope = s), color = \"skyblue\")  +\n       geom_errorbar(aes(ymin = y, ymax = estimated), color = \"skyblue\", linetype=2) + \n       theme_bw() + \n       geom_point(shape = 18, color = \"red\", aes(x=mean(x), y = mean(y)), size = 4) \n   })\n   \n   output$seplot2 &lt;- renderPlot({\n     vals2$df %&gt;%\n       ggplot(aes(x = x, y=y)) + \n       geom_point() +\n       geom_point(aes(y = estimated), color = \"skyblue\", alpha = 0.5) +\n       geom_abline(aes(intercept = i, slope = s), color = \"skyblue\")  +\n       geom_rect(aes(ymin = y, ymax = estimated, xmin = x, xmax = x-error), \n                 fill = \"firebrick1\", alpha = 0.1, color = \"firebrick1\") + \n       theme_bw() + \n       labs(title = paste0(\"Mean Squared Error: \", vals2$se))  + \n       geom_point(shape = 18, color = \"red\", aes(x=mean(x), y = mean(y)), size = 4)\n     \n   })\n\n}\n\n# Run the application \nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "posts/LogisticShiny/Logistic_shiny.html",
    "href": "posts/LogisticShiny/Logistic_shiny.html",
    "title": "Logistic Function Visualization",
    "section": "",
    "text": "#| standalone: true\n#| viewerHeight: 600\n\n# Load necessary libraries\nlibrary(shiny)\nlibrary(ggplot2)\n\n# Define UI for application\nui &lt;- fluidPage(\n  titlePanel(\"Logistic Function Visualization\"),\n  sidebarLayout(\n    sidebarPanel(\n      sliderInput(\"beta\", \"Beta Coefficient\", min = -5, max = 5, value = 1, step = 0.1),\n      sliderInput(\"intercept\", \"Intercept (Log Odds at x=0)\", min = -5, max = 5, value = 0, step = 0.1)\n    ),\n    mainPanel(\n      plotOutput(\"log_odds_plot\"),\n      plotOutput(\"probability_plot\")\n    )\n  )\n)\n\n# Define server logic\nserver &lt;- function(input, output) {\n  # Calculate logistic function\n  logistic_function &lt;- function(x, beta, intercept) {\n    return(1 / (1 + exp(-(intercept + beta * x))))\n  }\n  \n  # Generate x values\n  x_values &lt;- seq(-10, 10, length.out = 100)\n  \n  # Create log odds plot\n  output$log_odds_plot &lt;- renderPlot({\n    log_odds &lt;- input$intercept + input$beta * x_values\n    \n    ggplot() +\n      geom_line(aes(x = x_values, y = log_odds), color = \"blue\") +\n      labs(title = \"Log Odds Plot\", x = \"X\", y = \"Log Odds\") + theme_bw()\n  })\n  \n  # Create probability plot\n  output$probability_plot &lt;- renderPlot({\n    probabilities &lt;- logistic_function(x_values, input$beta, input$intercept)\n    \n    ggplot() +\n      geom_line(aes(x = x_values, y = probabilities), color = \"red\") +\n      labs(title = \"Probability Plot\", x = \"X\", y = \"Probability\") + \n      theme_bw()\n  })\n}\n\n# Run the application\nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "posts/Tutorial-3/Tutorial3.html#manipulating-data",
    "href": "posts/Tutorial-3/Tutorial3.html#manipulating-data",
    "title": "Tutorial 3: Importing and Manipulating Data in R",
    "section": "Manipulating Data",
    "text": "Manipulating Data\nNow that"
  },
  {
    "objectID": "posts/Tutorial-4/Tutorial4.html",
    "href": "posts/Tutorial-4/Tutorial4.html",
    "title": "Tutorial 4: Data Frames in R",
    "section": "",
    "text": "By now you should have learned to install R and R Studio, learned a little about types of objects and functions in R, and learned to import data into R. If you’re not sure about any of those, tutorials for each topic can be found here:\n\nInstalling R and R Studio Tutorial\nR Objects and Functions Tutorial\nImporting Data into R Tutorial\n\n\n\nIn this tutorial, we’re going to go over manipulating data frames in R, including:\n\nData frame structure\nMaking new columns\nUpdating variables\nFiltering data frames\n\nWe’re going to use the cdc data from last time in this tutorial as an example. Here’s a reminder of how we read in that dataset (this code will automatically run when the webpage is ready):\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "posts/Tutorial-4/Tutorial4.html#introduction",
    "href": "posts/Tutorial-4/Tutorial4.html#introduction",
    "title": "Tutorial 4: Data Frames in R",
    "section": "",
    "text": "By now you should have learned to install R and R Studio, learned a little about types of objects and functions in R, and learned to import data into R. If you’re not sure about any of those, tutorials for each topic can be found here:\n\nInstalling R and R Studio Tutorial\nR Objects and Functions Tutorial\nImporting Data into R Tutorial\n\n\n\nIn this tutorial, we’re going to go over manipulating data frames in R, including:\n\nData frame structure\nMaking new columns\nUpdating variables\nFiltering data frames\n\nWe’re going to use the cdc data from last time in this tutorial as an example. Here’s a reminder of how we read in that dataset (this code will automatically run when the webpage is ready):\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "posts/Tutorial-4/Tutorial4.html#rows-and-columns",
    "href": "posts/Tutorial-4/Tutorial4.html#rows-and-columns",
    "title": "Tutorial 4: Data Frames in R",
    "section": "Rows and Columns",
    "text": "Rows and Columns\n\nnrow() and ncol() functions\nThe standard setup for a data frame is to put individual observations (so in this case, different people) in the rows, and different attributes (variables) in the columns. In the cdc data frame, each row corresponds to one individual, and each column corresponds to a variable.\nFrom the output above, we can see that the 1st person in the data set has the value \"very good\" for the variable genhlth, the value 1 for the variable exerany, and so on.\nWe may want to know how many rows and columns are included in our data. We can find this out using the functions nrow() and ncol().\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThis tells us that there are 60 rows (60 observations) and 9 columns (9 variables) recorded in our data.\n\n\ncolnames() function\nIf we want to get a list of all the column names in the dataset, we can use the colnames() function in R, which will just print out the names of all of the columns in the data.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nHere we can see the names of the 9 columns included in our data. Remember that R is case-sensitive so this can be a helpful function when you first start working with a data set. For example, if I was trying to refer to the column named \"age\" but I accidentally spelled it with a capital A, \"Age\", R wouldn’t understand which variable I was referring to. Checking the column names at the start can help avoid future confusion/frustration with misspellings 🙂"
  },
  {
    "objectID": "posts/Tutorial-4/Tutorial4.html#making-a-new-column",
    "href": "posts/Tutorial-4/Tutorial4.html#making-a-new-column",
    "title": "Tutorial 4: Data Frames in R",
    "section": "Making a new column",
    "text": "Making a new column\nAs with most things in R, there are multiple ways to make new columns in a data frame. I will be using the tidyverse syntax and functions to do this, but there are other ways to do this.\nThe function in the tidyverse (and specifically, the dplyr package) to make a new column is mutate().\nThe syntax will be:\n\nmutate(new_column = some_function(existing_column))\n\nYou don’t need to use a pre-existing column to make the new column (you could just type out a vector with the new column values), but we generally will be using pre-existing columns to make new columns.\nFor example, we can see that there is a column called \"exerany\" in our data. This column indicates if the individual has exercised in the past month, where a 1 indicates that they have exercised in the past month and 0 indicates that they have not. This is a fairly common coding of binary variables, but unless you have the codebook readily available, you wouldn’t know for sure which response (yes/no) corresponds to which value (1/0). It can be helpful to make new variable that reads as “Yes”/“No” instead of 1/0 for clarity and to make sure we don’t accidentally treat this categorical variable as a numeric variable in later analyses.\nWe will make a new factor variable called \"exerany_f\" that takes on the values 0 and 1 with the labels \"No exercise in past month\" and \"Exercise in past month\", respectively. We will use the values from the \"exerany\" variable to help us make the new variable.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nColumns names vs object names\nOh no! Why did we get an error?\nLet’s take a look at the error message:\n\nError: object ‘exerany’ not found\n\nThis error message is telling us that there isn’t an object called 'exerany' that R can find. This is because 'exerany' is the name of a column in our data frame cdc, not a standalone object within our R environment.\nTo fix this error, we just need to tell R where to look for the variable called 'exerany'.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNotice that this printed out a data frame that now has 10 columns instead of the previous 9. The new column is the variable we just made, 'exerany_f'. You can’t see it because there is a limit to the number of columns printed, but there is a line telling us that there is 1 more variable: exerany_f &lt;fct&gt;, which means there is also a factor variable called exerany_f that isn’t being shown in the printed output.\nRight now, we haven’t actually saved the new column. To see this, let’s use the colnames() function we learned last time.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nBasically, mutate will add a new column to your data frame and return a data frame (that then gets printed in your output). If you want to save the new variable to be able to use it later, we have to either update the cdc data frame or save this as a new data frame.\n\n\nSaving a new data frame\nTo save a new data frame we can use this code:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nUpdating the old data frame\nIf we don’t want to make a new data frame with a new name, we can also just update the original cdc object by replacing cdc_new in the code above with cdc. This will overwrite the old cdc object with the updated data frame with the additional column (be careful when overwriting objects, especially if you’re removing some entries of the data).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nGreat! If we want to take a look at the new column, we can use a function in the tidyverse package called select() to select just a few columns to look at. Let’s grab the original variable, exerany, and the new one, exerany_f, and look at the first few entries to make sure we defined the new variable correctly.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nIt looks like this worked! The first 6 rows all had a 1 in exerany so they all show up as \"Exercise in the past month\" under exerany_f.\n\n\nUsing the $ symbol to grab a column\nAnother way to grab a specific column from a data frame is to use the $ symbol, using the following syntax\n\ndata_name$column_name\n\nThis will grab the column and treat it as a vector.\nFor example, if we want to grab the new column, exerany_f, and the old column, exerany, and take a look at the last few entries, we can use the tail() function after grabbing the desired column:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "posts/Tutorial-4/Tutorial4.html#updating-existing-variables",
    "href": "posts/Tutorial-4/Tutorial4.html#updating-existing-variables",
    "title": "Tutorial 4: Data Frames in R",
    "section": "Updating existing variables",
    "text": "Updating existing variables\nSometimes instead of making a new column, we just want to update an existing column. We can use the mutate() function for this too. The syntax this time will be:\n\nmutate(existing_column = some_function(existing_column))\n\nThis will overwrite the column with the new values.\nFor example, let’s say the values \"No exercise in the past month\" and \"Exercise in the past month\" that we just created are too long for our liking. Maybe we want to update this column so the values are just \"No exercise\" and \"Exercise\". We can do this with the following code:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNotice that now the same column as before exerany_f has been updated from what we originally created and now contains the shorter labels.\n\n\n\n\n\n\nWarning: Overwriting\n\n\n\nBe careful with updating existing column names (and other R objects for that matter)!\nIf you make a mistake, this will overwrite the old column, so you won’t have access to the original contents anymore and you will have to rerun some of your code (like when you first read in the data) to reset the code and try again."
  },
  {
    "objectID": "posts/Tutorial-4/Tutorial4.html#filtering-data-frames",
    "href": "posts/Tutorial-4/Tutorial4.html#filtering-data-frames",
    "title": "Tutorial 4: Data Frames in R",
    "section": "Filtering Data Frames",
    "text": "Filtering Data Frames\nSometimes we only want to look at a subset of the rows (observations) in our data frame.\nFor example, maybe I want to run an analysis using only individuals who have a genhlth value of \"excellent\" or individuals who are at least 30 years old. To do this, I can use the filter() function (also within the dplyr package from the tidyverse).\nIn this code chunk, I filter so that I am only left with observations who have a “genhlth value of \"excellent\":\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nIn this code chunk, I filter so that I am only left with observations whose age is at least 30:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nUsing the filter function, we can then run functions just on the subsetted data. For example, we could check the number of observations for each subet using the nrow() function.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nHere we can see that there are 17 observations with genhlth value “excellent” and 48 observations with an age of at least 30. If we know we want to continue using these subsets for future statistical analyses, we might choose to save the filtered data sets with new names so we don’t have to keep using the filter() function.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNow if we want to run any further analysis using just the subset of individuals who were at least 30 years old or had “excellent” general health condition, we can use cdc_30y or cdc_excellent, respectively. This can be helpful if you want to run multiple analyses on the same subset of observations but still want access to the full data set too."
  },
  {
    "objectID": "posts/Tutorial-5/Tutorial5.html",
    "href": "posts/Tutorial-5/Tutorial5.html",
    "title": "Tutorial 5: Data Visualization in R",
    "section": "",
    "text": "In this tutorial, we will cover data visualization in R using the ggplot2 package (one of the packages included in the tidyverse). Specifically, we will learn about\n\nGeneral ggplot syntax\nSingle-variable visualizations\n\nhistograms\nboxplots\nbarplots\n\nTwo-variable visualizations\n\nside-by-side histograms\nside-by-side boxplots\nside-by-side barplots\nscatterplots"
  },
  {
    "objectID": "posts/Tutorial-5/Tutorial5.html#introduction",
    "href": "posts/Tutorial-5/Tutorial5.html#introduction",
    "title": "Tutorial 5: Data Visualization in R",
    "section": "Introduction",
    "text": "Introduction\nIn this tutorial, we will cover data visualization in R using the ggplot2 package (one of the packages included in the tidyverse). Specifically, we will learn about\n\nGeneral ggplot syntax\nTypes of plots\n\nhistograms\nbox plots\nbar plots\nscatter plots\n\nMore ggplot aesthetic options"
  },
  {
    "objectID": "posts/Tutorial-5/Tutorial5.html#ggplot-syntax",
    "href": "posts/Tutorial-5/Tutorial5.html#ggplot-syntax",
    "title": "Tutorial 5: Data Visualization in R",
    "section": "ggplot syntax",
    "text": "ggplot syntax\nThe ggplot2 package within the tidyverse suite of packages utilizes similar syntax to create multiple types of graphs.\nAll ggplot2 plots will begin with a call to the ggplot() functions, to which you will supply the data you will be using to make the plot and specify the variables (columns) you would like to use in the plot. We can then add extra features on top of this base plot using other ggplot2 functions, strung together with the + symbol.\nI tend to use the following syntax:\n{data_name} %&gt;%\nggplot(aes(x = {x_axis_variable_name}, y = {y_axis_varible_name})) +\ngeom_{PLOT_TYPE}()\nThe code in the brackets {} are the things you should change based on your data and the type of plot you want to make.\nThe important thing to note about this code is that any variable you want to use from the data frame that you’ve supplied (in this example, data_name) must be wrapped within the aes() function. This is how R understands that you are trying to pull a column from the data frame and use it in the plot.\nThere are lots of different plots that ggplot2 can make, each with a different function. Some common ones that we will use are:\n\ngeom_histogram(): makes a histogram\ngeom_boxplot(): makes a boxplot\ngeom_bar(): makes a bar plot\ngeom_point(): makes a scatterplot\ngeom_qq(): makes a quantile-quantile (QQ) plot\n\nLet’s see some examples! We will use the census.rda data from Tutorial 3. I have already loaded the data for you. Reminder: the data frame is saved under the name census. Here’s a reminder of what the data look like:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nSince we are going to be using the ggplot2 functions, we need to load the tidyverse! I’m going to have this code auto-run but make sure when you’re working in RStudio that you type and run this line at the beginning of any R session/document that you want to use tidyverse functions for!\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "webexercises.html",
    "href": "webexercises.html",
    "title": "Webexercises",
    "section": "",
    "text": "This is a Web Exercise template created by the psychology teaching team at the University of Glasgow, based on ideas from Software Carpentry. This template shows how instructors can easily create interactive web documents that students can use in self-guided learning.\nThe {webexercises} package provides a number of functions that you use in inline R code or through code chunk options to create HTML widgets (text boxes, pull down menus, buttons that reveal hidden content). Examples are given below. Render this file to HTML to see how it works.\nNOTE: To use the widgets in the compiled HTML file, you need to have a JavaScript-enabled browser."
  },
  {
    "objectID": "webexercises.html#example-questions",
    "href": "webexercises.html#example-questions",
    "title": "Webexercises",
    "section": "Example Questions",
    "text": "Example Questions\n\nFill-In-The-Blanks (fitb())\nCreate fill-in-the-blank questions using fitb(), providing the answer as the first argument.\n\n2 + 2 is \n\nYou can also create these questions dynamically, using variables from your R session.\n\nThe square root of 9 is: \n\nThe blanks are case-sensitive; if you don’t care about case, use the argument ignore_case = TRUE.\n\nWhat is the letter after D? \n\nIf you want to ignore differences in whitespace use, use the argument ignore_ws = TRUE (which is the default) and include spaces in your answer anywhere they could be acceptable.\n\nHow do you load the tidyverse package? \n\nYou can set more than one possible correct answer by setting the answers as a vector.\n\nType a vowel: \n\nYou can use regular expressions to test answers against more complex rules.\n\nType any 3 letters: \n\n\n\nMultiple Choice (mcq())\n\n“Never gonna give you up, never gonna: let you goturn you downrun awaylet you down”\n“I bless the rainsguess it rainssense the rain down in Africa” -Toto\n\n\n\nTrue or False (torf())\n\nTrue or False? You can permute values in a vector using sample(). TRUEFALSE\n\n\n\nLonger MCQs (longmcq())\nWhen your answers are very long, sometimes a drop-down select box gets formatted oddly. You can use longmcq() to deal with this. Since the answers are long, It’s probably best to set up the options inside an R chunk with echo=FALSE.\nWhat is a p-value?\n\n the probability that the null hypothesis is true the probability of the observed, or more extreme, data, under the assumption that the null-hypothesis is true the probability of making an error in your conclusion\n\nWhat is true about a 95% confidence interval of the mean?\n\n 95% of the data fall within this range there is a 95% probability that the true mean lies within this range if you repeated the process many times, 95% of intervals calculated in this way contain the true mean"
  },
  {
    "objectID": "webexercises.html#checked-sections",
    "href": "webexercises.html#checked-sections",
    "title": "Webexercises",
    "section": "Checked sections",
    "text": "Checked sections\nCreate sections with the class webex-check to add a button that hides feedback until it is pressed. Add the class webex-box to draw a box around the section (or use your own styles).\n\nI am going to learn a lot: TRUEFALSE\nWhat is a p-value?\n\n the probability that the null hypothesis is true the probability of the observed, or more extreme, data, under the assumption that the null-hypothesis is true the probability of making an error in your conclusion"
  },
  {
    "objectID": "webexercises.html#hidden-solutions-and-hints",
    "href": "webexercises.html#hidden-solutions-and-hints",
    "title": "Webexercises",
    "section": "Hidden solutions and hints",
    "text": "Hidden solutions and hints\nYou can fence off a solution area that will be hidden behind a button using hide() before the solution and unhide() after, each as inline R code. Pass the text you want to appear on the button to the hide() function.\nIf the solution is a code chunk, instead of using hide() and unhide(), simply set the webex.hide chunk option to TRUE, or set it to the string you wish to display on the button.\nRecreate the scatterplot below, using the built-in cars dataset.\n\n\n\n\n\n\n\n\n\n\n\nI need a hint\n\nSee the documentation for plot() (?plot)\n\n\n\n\n\nClick here to see the solution\n\nplot(cars$speed, cars$dist)"
  },
  {
    "objectID": "posts/Tutorial-5/Tutorial5.html#more-ggplot-aesthetic-options",
    "href": "posts/Tutorial-5/Tutorial5.html#more-ggplot-aesthetic-options",
    "title": "Tutorial 5: Data Visualization in R",
    "section": "More ggplot aesthetic options",
    "text": "More ggplot aesthetic options\nSo far we have only made basic plots using ggplot2, however this package makes it really easy to make much nicer looking plots without too much extra coding. We can do things like change the background color, add titles and subtitles, change the axis labels, and much more. I’ll go over a few of these options but much more can be found online at resources like these: ggplot tutorial, ggplot reference page\nWe will return to our side-by-side box plot example showing the total personal income by marital status to demonstrate how we can make the plot look a little nicer.\n\nFacets\nOne really nice feature of ggplot2 is the ability to make multiple plots of the same variable(s) across different subgroups using something called “facets”. For example, let’s say we want to make the same box plots we did before showing the distribution of personal income by marital status, but we want to split by sex to see if there are any different trends between male and female participants in our data set. We can do this using the function facet_wrap():\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nFaceting lets us compare trends across groups. We can facet across more than just one variable, too. For, example, we could facet across both sex and race (column name race_general). In this case, I like to use a slightly different function called facet_grid() because it makes the labeling a little easier to follow.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nCaution: Busy plots\n\n\n\nNotice that this busied up the plot a lot. It’s generally only a good idea to use multiple faceting variables if each only has a few (2-3) possible levels to make sure our figure is still interpretable.\n\n\n\n\n\n\n\n\nFacets: different scales\n\n\n\n\n\nSometimes you’ll notice that when you add facets to a plot, that not every facet takes up the full range of values on either the x-axis or y-axis, so the plots don’t use space very effectively. If you want to change this, you can the following arguments to the facet_wrap() function:\n\nscales = \"free_x : to allow the x-axis to have different scales (ranges/degree of zoom) across the plots\nscales = \"free_y : to allow the y-axis to have different scales (ranges/degree of zoom) across the plots\nscales = \"free : to allow both the x- and y-axes to have different scales (ranges/degree of zoom) across the plots\n\nExample:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\nLabels/titles\nOne issue with our plot right now is that it doesn’t have a title and the axis labels are column names with underscores. If we wanted to include this figure in a paper, we might want to change these. We can do this by adding the labs() function to the plot to update the plot labels.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThese labels are a lot nicer than the default labels!\n\n\nBackground color\nDon’t like the grey grid background? You can change it, too! I like to use a black and white grid background or sometimes just a plain white background. You can achieve this by adding theme_bw() or theme_classic() to the plot. There are many other options for plot themes that you can find here: _____\n\nBlack and white grid with theme_bw()\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nWhite background with theme_classic()\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlot colors\nYou can also add color to plots to help display information. For example, maybe we want to color the box plots by marital status or by sex to further emphasize a comparison that we’re trying to make. If you want to pick your own colors, see this reference for more information about plot colors in ggplot2.\n\nColor by marital status\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nColor by sex\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nUsing color to display information\n\n\n\nGiven that some people have trouble distinguishing color, it is best practice not to have color be the only way in which information is portrayed.\n\n\n\n\nStatic colors\nYou can also change colors without using variables from data. For example, you could make all of the box plots blue by including color=\"blue\" to the geom_boxplot() function. If you are just trying to change the color but not trying to use color to indicate the value of a variable, put this argument doesn’t need to go inside an aes() function. There are lots of colors to choose from in ggplot (link).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\ncolor vs fill\n\n\n\n\n\nFor some types of plots there is an additional argument fill that you can use to color parts of the plot. For example, in bar plots and histograms, changing the color argument will change the outline color of the bars while changing the fill argument will change the color inside the bars.\nExample:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nFormatting axis text\nAs we noted before, the text on the x-axis of our box plots showing the different values of marital_status are overlapping, making it hard to read the plot. One way we can fix this is using the following code to rotate the text:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nLooking up technical code\n\n\n\nThis code is starting to get pretty technical. You probably won’t memorize this (I haven’t! I look up how to do it every time I need to rotate axis labels, including just now while I was making this tutorial 🙂 ).\nYou aren’t expected to know how to do this from memory; you can use old example code or search online references/forums for help with this kind of thing."
  },
  {
    "objectID": "posts/VIF_Shiny/VIF_shiny.html",
    "href": "posts/VIF_Shiny/VIF_shiny.html",
    "title": "Collinearity in MLR",
    "section": "",
    "text": "#| standalone: true\n#| viewerHeight: 600\n\n\nlibrary(shiny)\nlibrary(tidyverse)\nlibrary(GGally)\n\n# Define UI for application that draws a histogram\nui &lt;- fluidPage(\n  \n  # Application title\n  titlePanel(\"Added-Variable Plots and VIF\"),\n  \n  \n  # Show a plot of the generated distribution\n  tabsetPanel(type = \"tabs\",\n              tabPanel(\"Changing the variability in x\",\n                       sidebarLayout( \n                         sidebarPanel(\n                           sliderInput(\"c\", \"Scaling Constant\", \n                                       min = 0.1, max = 3,value = 1)),\n                         mainPanel( \n                           strong(\"Description:\"),\n                           p(\"The goal of this part of the app is to show you how changing the amount of variability in x impacts the standard error of our coefficient estimate for \\u03B2. That is, if we increase or decrease the amount of variability in the predictor (x) relative to the amount of variability in the outcome (y), what happens to the standard error of the slope coefficient? \"),\n                           p(\"We will demonstrate this by scaling x by a constant factor while keeping y the same.\"),\n                           p(\"Below, I have simulated some data with predictor x and outcome y. Move the slider above to increase or decrease the standard deviation of x (scale by &lt;1 to decrease and &gt;1 to increase the standard deviation). The outcome y will stay the same\\u2013only x is changing. Notice how the standard error of the slope coefficient changes as we increase or decrease the variability in x.\"),\n                           plotOutput(\"xplot\",height = \"300px\"),\n                           span(textOutput(\"sd_orig\"), style=\"font-weight:bold\"),\n                           span(textOutput(\"se_orig\"), style=\"font-weight:bold\"),\n                           span(textOutput(\"sd\"), style=\"font-weight:bold; color:green\"),\n                           span(textOutput(\"se\"), style=\"font-weight:bold; color:blue\"),\n                           p(),\n                           strong(\"What's the trend?\"),\n                           p(\"As we decrease the variability in the predictor, x, we increase our uncertainty (the standard error) in our estimate of \\u03B2. Likewise, the standard error decreases if we increase the variability in x.  \"\n                           ),\n                           strong(\"Intuition (example: changing units)\"),\n                           p(\"As a simple example of this to provide a bit more intuition for this phenomenon, imagine that the predictor x represents height and y represents shoe size. If we measure x in inches, the variance or standard deviation of x will be smaller than if we measure x in centimeters, due to the difference in units. For example, a standard deviation of 2 inches would be equivalent to a standard deviation of about 5 centimeters (the smaller the unit, the bigger the standard deviation measured in those units). If we wanted to measure the association between height and shoe size, it makes sense that we would need a wider interval to describe our uncertainty in the expected change in shoe size for a one-inch change in height compared to the interval we need for the expected change in shoe size for a one-centimeter change in height, since a one-inch change in height is a lot bigger than a one-centimeter change! Again we see that the version of x that had the larger standard deviation (centimeters) resulted in the lower standard error for the slope estimate (and vice versa).\"\n                           )\n                         ))),\n              tabPanel(\"MLR and VIF\",\n                       sidebarLayout( \n                         sidebarPanel(\n                           radioButtons(\"cor1\", \"Correlation betweel x1 and x2 (approximate)\",\n                                        choices = c(\"-1\",\"-0.75\",\"0\",\"0.75\",\"1\"),\n                                        selected = \"0.75\")\n                         ),\n                         mainPanel(\n                           h3(\"Simulating the data\"),\n                           p(\"Here we've simulated some data with one outcome (y) and two predictors (x1 and x2). \n                             You can control the amount of correlation between x1 and x2 using the radio buttons on the left panel\"),\n                           h3(\"Plotting the data\"),\n                           p(\"Here we can see the scatterplots between each pair of variables in the data.\"),\n                           fluidRow(\n                             column(12,  plotOutput(\"corplot\",height = \"300px\"))),\n                          p(\"Another way to visualize the data is to plot y by x1 and show x2 using color. Here we can see that as x1 changes, so does y. \n                            Depending on the correlation we chose, we may also see a pattern between x1 and the color of the points (indicating the value fo x2).\"),\n                           fluidRow(\n                             column(12, plotOutput(\"dataPlot1\", height = \"300px\"))\n                           ),\n                          p(\"Let's imagine splitting the data based on the value of x2. \n                            Here we are looking at the relationship between x1 and y for each unique value of x2 (holding x2 constant). We can think \n                            of the slope for x1 in the MLR y ~ x1 + x2 as a sort of average of the slopes in these various plots at each value of x2.\"),\n                          \n                           fluidRow(\n                             column(12, plotOutput(\"dataPlot2\", height = \"300px\"))\n                           ),\n                          p(\"Notice how if we picked a non-zero correlation between x1 and x2, the range of values of x1 for any value we fix for x2 is \n                            smaller than the overall range of x1 that we originally saw.\"),\n                          \n                           p(),\n                          h3(\"Added Variable Plots\"),\n                          p(\"Now imagine that we combine all of these plots together, but first we center them both in terms of x1 and y. \"),\n                          fluidRow(\n                             column(12, plotOutput(\"dataPlot3\", height = \"300px\"))\n                           ),\n                          p(\"This is similar to what an added variable plot is (if x2 is categorical, this is exactly what an added variable plot is; if it is continuous, we add a linearity constraint to the centering process). If we combine all of the centered scatter plots above, we can see that there doesn't appear to be any relationship between x2 and either x1 or y (the colors are scattered without a clear pattern). This is what we mean by \\\"removing the effects of x2.\\\" What we are visualizing now is the relationship between x1 and y, adjusted for x2 (the relationship between x1 and y that is completely independent of x2). The overall slope for x1 in the MLR is the slope in the added variable plot, which you can think of as a sort of average of the slopes across the panels in the plot above.\"),\n                          #fluidRow(\n                           #  column(12, plotOutput(\"dataPlot4\", height = \"300px\"))\n                          # ),\n                          fluidRow(\n                             column(12, plotOutput(\"AVplot1\", height = \"300px\"))),\n                           strong(\"How does this relate to standard error?\"),\n                           p(\"Remember that changing the variability in x impacted the standard error for our \\u03B2 estimate. When we fit a multiple linear regression model we are looking at the association between each variable and the outcome, holding the other variable(s) constant. But if x1 and x2 are correlated, then for each fixed value of x2, the range of values we observe for x1 is smaller than the total amount of variability in x1 overall. So including correlated predictors in a MLR model results in higher standard errors for slope coefficients than if predictors were uncorrelated.\"),\n                           p(\" If x1 and x2 are perfectly correlated, we cannot fix one variable while moving the other. Changing one means the other must change as well. In this case, when we fix the value of x2, we know exactly what x1 will be and there is no variability left in x1 (and vice versa), so the standard error for the slope coefficients for x1 and x2 will be infinity.\"),\n                           p(),\n                           \n                           h3(\"VIF\"),\n                           textOutput(\"vif\")\n                           \n                           \n                         ) )\n              )\n              \n  ) \n  \n)\n\n\n\n# Define server logic required to draw a histogram\nserver &lt;- function(input, output) {\n  \n  set.seed(234)\n  N = 150\n  x1 = runif(n = N, max = 10) %&gt;% round()\n  y = 4.2 + 1.5*x1 + rnorm(n = N, sd = 1.3)\n  origx2&lt;-(3 +rnorm(n = N, sd =.5)) \n  \n  X = cbind(scale(x1),scale(origx2))\n  c1 = var(X)\n  chol1 = solve(chol(c1))\n  newx = X %*% chol1 \n  R2 = matrix(c(1,0.75, 0.75, 1), nrow = 2)\n  \n  chol2 = chol(R2)\n  finalx = newx %*% chol2 * sd(x1) + mean(x1)\n  \n  x2 = finalx[,2]/1.9\n \n\n\n  vals&lt;-reactiveValues( x2=x2,c=1,av.data=NULL,dt=data.frame(x1, x2 =x2,y),cor = 0.75)\n  \n  observeEvent({input$c},{ vals$c=input$c})\n  \n   observeEvent({input$cor1},{ \n     cr = as.numeric(input$cor1)\n     if(!cr%in%c(1,-1)){\n     \n    R2 = matrix(c(1,cr, cr, 1), nrow = 2)\n  \n  chol2 = chol(R2)\n  finalx = newx %*% chol2 * sd(x1) + mean(x1)\n  \n  x2 = finalx[,2]/1.9\n  } else {x2 = cr * x1}\n     \n\n  \n  #observeEvent({input$cor1},{\n  #  if(input$cor1 == \"1\"){x2 = (3 + 0.5*x1 ) \n  #  } else if(input$cor1 == \"-1\"){x2 = -(3 + 0.5*x1 ) \n  #  } else if(input$cor1 == \"-0.75\"){x2 = -origx2\n  #  } else if(input$cor1 == \"0.75\"){x2 = origx2\n  #  } else{x2 = (3 + rnorm(n = N, sd =1))%&gt;% plyr::round_any(.,1) }\n    \n    vals$x2 = x2\n    vals$dt = data.frame(x1, x2 = vals$x2,y) %&gt;% mutate(r_x2 = plyr::round_any(vals$x2, .5)) \n    vals$cor = as.numeric(input$cor1)\n    \n    \n    xres1 = round(lm(x1 ~ x2, data = vals$dt)$residuals,digits = 6)\n    yres1 = round(lm(y ~ x2, data = vals$dt)$residuals , digits = 6)\n    xres2 = round(lm(x2 ~ x1, data = vals$dt)$residuals, digits = 6) \n    yres2 = round(lm(y ~ x1, data = vals$dt)$residuals, digits = 6)\n    \n    vals$av.data = data.frame(x_axis = c(xres1, xres2), \n                              y_axis = c(yres1, yres2),\n                              variable = rep(c(\"Removing x2\", \"Removing x1\"), \n                                             each = 50))\n  })\n  \n  output$xplot &lt;- renderPlot({\n    dt = data.frame(x1,y) %&gt;% mutate(x1c = x1*vals$c)\n    dt %&gt;% \n      ggplot(aes(x = x1c, y=y)) + \n      geom_point() +\n      theme_bw() + \n      labs(x = paste0(vals$c,\" * x\")) + \n      xlim(0, 30) + \n      geom_smooth(method = \"lm\", formula = y~x, se = F)\n  })\n  \n  output$se &lt;- renderText({\n    dt = data.frame(x1,y) %&gt;% mutate(x1c = x1*vals$c)\n    se = (summary(lm(y~x1c, data = dt ))$coef[2,2]) %&gt;% \n      round(digits=5)\n    print(paste0(\"Standard error for slope coefficient (\\u03B2): \",se))\n  })\n  \n  output$se_orig &lt;- renderText({\n    dt = data.frame(x1,y) %&gt;% mutate(x1c = x1*vals$c)\n    se = (summary(lm(y~x1, data = dt ))$coef[2,2]) %&gt;% \n      round(digits=5)\n    print(paste0(\"Standard error for original slope coefficient (\\u03B2): \",se))\n  })\n  \n  \n  output$sd &lt;- renderText({\n    dt = data.frame(x1,y) %&gt;% mutate(x1c = x1*vals$c)\n    sd = sd(dt$x1c) %&gt;% round(digits = 5)\n    print(paste0(\"Standard deviation of scaled x (\",vals$c,\"x): \",sd))\n  })\n  \n  output$sd_orig &lt;- renderText({\n    sd = sd(x1) %&gt;% round(digits = 5)\n    print(paste0(\"Standard deviation of x (original): \",sd))\n  })\n  \n  output$corplot &lt;- renderPlot({\n    \n    #psych::pairs.panels(vals$dt, ellipses = F, hist.col = \"skyblue1\")\n     ggpairs(vals$dt %&gt;% select(-r_x2), \n        # upper = list(continuous = wrap(\"blank\")),\n        lower = list(continuous = \"points\"),\n       diag = list(continuous = \"densityDiag\")) + \n      theme_bw()\n  })\n  \n  output$dataPlot1 &lt;- renderPlot({\n    \n    vals$dt %&gt;% \n      ggplot(aes(x = x1, y=y, color = x2)) + \n      geom_point() +\n      theme_bw() + \n      xlim(0, 10) +\n      scale_color_viridis_c(option=\"turbo\") + \n      labs(title  = \"Data colored by x2 value\")\n  })\n  \n  output$dataPlot2 &lt;- renderPlot({\n    \n    vals$dt %&gt;% \n      ggplot(aes(x = x1, y=y)) + \n      geom_point(aes(color = x2)) +\n      theme_bw() + \n      xlim(0, 10) +\n      scale_color_viridis_c(option=\"turbo\") + \n      facet_wrap(.~r_x2)+\n      labs(title  = \"Data split by x2 value\") + \n      geom_smooth(method = \"lm\", se = F, linewidth = 0.5, aes(color = r_x2)) + \n      labs(color = \"x2\")\n  })\n  \n    output$dataPlot3 &lt;- renderPlot({\n    \n    vals$dt %&gt;% \n      ggplot(aes(x = x1, y=y)) + \n      geom_point(aes(color = x2)) +\n      theme_bw() + \n      xlim(0, 10) +\n      scale_color_viridis_c(option=\"turbo\") + \n      facet_wrap(.~r_x2)+\n      labs(title  = \"Data split by x2 value\") + \n      geom_smooth(method = \"lm\", se = F, size = 0.5, aes(color = r_x2)) + \n      labs(color = \"x2\")+  \n      geom_vline(data = vals$dt %&gt;%  group_by(r_x2) %&gt;% summarize(mean_x = mean(x1)), aes(xintercept = mean_x), linetype = \"dashed\", color = \"black\") +\n        geom_hline(data = vals$dt %&gt;% group_by(r_x2) %&gt;% summarize(mean_y = mean(y)), aes(yintercept = mean_y), linetype = \"dashed\", color = \"black\") + \n        theme(legend.position = \"none\")\n  })\n    \n    \n  \n  output$AVplot1 &lt;- renderPlot({\n    \n    vals$av.data %&gt;%\n      filter(variable==\"Removing x2\") %&gt;%\n      mutate(x2 = vals$x2)%&gt;%\n      ggplot(aes(x = x_axis, y = y_axis)) + \n      theme_bw() + \n      geom_smooth(method = \"lm\",color = \"black\", se = F,linewidth = 0.5) + \n      geom_point(aes(color = x2)) + \n     # geom_smooth(method = \"lm\", aes(color = x2, group = x2), linewidth = 0.5, alpha = 0.1, se = F)+\n      labs(x = \"Residuals (x1 | x2)\", y = \"Residuals (Y | x2)\",\n           title = \"Added Variable Plot\",\n           subtitle = \"Adjusting for x2\") +\n      scale_color_viridis_c(option=\"turbo\") +\n      geom_hline(yintercept = 0, linetype = \"dashed\", color = \"black\") + \n      geom_vline(xintercept = 0,linetype = \"dashed\", color = \"black\")\n    \n  })\n  \n\n  \n  output$vif &lt;- renderText({\n    vif = round(1/(1-as.numeric(vals$cor)^2),5)\n    print(paste0(\"Variance Inflation Factor: \",vif))\n  })\n  \n  \n  \n}\n\n# Run the application \nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "posts/Recitation_M2_2/Recitation_M2_2.html",
    "href": "posts/Recitation_M2_2/Recitation_M2_2.html",
    "title": "Bootstrapping",
    "section": "",
    "text": "The purpose of this recitation is to demonstrate the concept of bootstrapping and show how it relates to the concept of a sampling distribution.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "posts/Recitation_M2_2/Recitation_M2_2.html#introduction",
    "href": "posts/Recitation_M2_2/Recitation_M2_2.html#introduction",
    "title": "Bootstrapping",
    "section": "",
    "text": "The purpose of this recitation is to demonstrate the concept of bootstrapping and show how it relates to the concept of a sampling distribution.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "posts/Recitation_M2_2/Recitation_M2_2.html#step-1-create-data-set-with-populaiton",
    "href": "posts/Recitation_M2_2/Recitation_M2_2.html#step-1-create-data-set-with-populaiton",
    "title": "Bootstrapping",
    "section": "Step 1: Create data set with populaiton",
    "text": "Step 1: Create data set with populaiton\nFill in the following code with the appropriate parameters so that ‘pop’ is a sample of size 10000 drawn from a Poisson distribution with lambda = 2.5. We will treat this as our population for the remainder of the exercise.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "posts/Recitation_M2_2/Recitation_M2_2.html#step-2.-plot-the-population",
    "href": "posts/Recitation_M2_2/Recitation_M2_2.html#step-2.-plot-the-population",
    "title": "Bootstrapping",
    "section": "Step 2. Plot the Population",
    "text": "Step 2. Plot the Population\nMake a plot of the simulated data to display the population distribution. Hint: think about the type of variable this is (quantitative/qualitative) and the types of plots that are used for this type of variable.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "posts/Recitation_M2_2/Recitation_M2_2.html#step-3-summary-values-on-the-population",
    "href": "posts/Recitation_M2_2/Recitation_M2_2.html#step-3-summary-values-on-the-population",
    "title": "Bootstrapping",
    "section": "Step 3: Summary values on the population",
    "text": "Step 3: Summary values on the population\nCalculate the mean, standard deviation, and variance in the population. Is it what you would expect?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThis is what we would expect, since the population was drawn randomly from a Poisson distribution with lambda = 2.5 (the mean and variance of a Poisson distribution are equal to lambda). We observe a mean of 2.4759 and a variance of 2.449064, which are very close to 2.5. The standard deviation is the square root of the variance, about 1.565."
  },
  {
    "objectID": "posts/Recitation_M2_2/Recitation_M2_2.html#step-1-sample-of-size-100",
    "href": "posts/Recitation_M2_2/Recitation_M2_2.html#step-1-sample-of-size-100",
    "title": "Bootstrapping",
    "section": "Step 1: Sample of size 100",
    "text": "Step 1: Sample of size 100\nFill in the code below so that ‘samp’ contains a sample of size 100 sampled without replacement from our population.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "posts/Recitation_M2_2/Recitation_M2_2.html#step-2-plot-the-data.",
    "href": "posts/Recitation_M2_2/Recitation_M2_2.html#step-2-plot-the-data.",
    "title": "Bootstrapping",
    "section": "Step 2: Plot the data.",
    "text": "Step 2: Plot the data.\nMake a plot to show the distribution of the sampled data.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe sample looks very similar to the population distribution, which is expected since we sampled randomly. The population has a few more extreme values (around 9, 10, 11, etc) than we observe in the sample. This also makes sense, given that these are rare observations and it’s less likely to pull one of these randomly than to pull a value near the center of the distribution (around 2-3, for example)."
  },
  {
    "objectID": "posts/Recitation_M2_2/Recitation_M2_2.html#step-1-bootstrapped-means",
    "href": "posts/Recitation_M2_2/Recitation_M2_2.html#step-1-bootstrapped-means",
    "title": "Bootstrapping",
    "section": "Step 1: Bootstrapped means",
    "text": "Step 1: Bootstrapped means\nHere I’ve included code to produce 10,000 bootstrap samples from our original sample and saved the mean from each bootstrap sample. You don’t need to write the code for this– I’ve done it for you. This code chunk is just so you can see how the code works. The procedure is:\n\nResample with replacement from the original sample to get a new sample of size 100 (the same size as the original sample). This is a bootstrap sample.\nCalculate the mean value on the on the bootstrap sample.\nRepeat this process many times (I chose 10,000 in this example, but we just want it large enough that we can visualize the distribution of the means that we calculated in step 2).\n\nThe result is a set of 10,000 (or whatever number of bootstrap iterations you chose to run) bootstrap means.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "posts/Recitation_M2_2/Recitation_M2_2.html#step-2-plot-the-bootstrapped-means",
    "href": "posts/Recitation_M2_2/Recitation_M2_2.html#step-2-plot-the-bootstrapped-means",
    "title": "Bootstrapping",
    "section": "Step 2: Plot the bootstrapped means",
    "text": "Step 2: Plot the bootstrapped means\nPlot the distribution of the means of the bootstrapped samples. Describe the distribution.\nAssuming the central limit theorem (CLT), what would we expect this distribution to be? Is our observed distribution close to what we would expect?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe distribution appears approximately normal centered at around 2.5 (mean = 2.56) with a standard deviation of 0.17. This is very similar to what we would expect from the central limit theorem CLT, which tells us that the mean should be centered at the true population mean (our population had a mean of 2.48) and the standard error should be our population standard deviation/(root n) (1.56/sqrt(100) = 0.156)."
  },
  {
    "objectID": "posts/Recitation_M2_2/Recitation_M2_2.html#step-1-resample-from-population",
    "href": "posts/Recitation_M2_2/Recitation_M2_2.html#step-1-resample-from-population",
    "title": "Bootstrapping",
    "section": "Step 1: Resample from population",
    "text": "Step 1: Resample from population\nNow draw we’re going 10000 samples of size 100 without replacement from the population and calculate the mean for each and a 95% confidence interval.\nWe haven’t learned the specific formula for confidence intervals yet so I have provided the code for you here.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "posts/Recitation_M2_2/Recitation_M2_2.html#step-1-the-boostrap-confidence-interval",
    "href": "posts/Recitation_M2_2/Recitation_M2_2.html#step-1-the-boostrap-confidence-interval",
    "title": "Bootstrapping",
    "section": "Step 1: The boostrap confidence interval",
    "text": "Step 1: The boostrap confidence interval\nHere we will compute a 95% confidence interval for the bootstrapped sample means with 10,000 repetitions by taking the 2.5th percentile and the 97.5th percentile of the bootstrapped means that we got above. These two values will tell us the range of values that contains the middle 95% of the observed bootstrapped means.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThis tells us that when we resampled (with replacement) samples of size 100 from our original sample, we obtained sample means between 2.08 and 2.78 in 9,500 of the 10,000 bootstrap samples (95% of the bootstrap iterations) and only 5% of the bootstrap samples gave us a mean outside of this range."
  },
  {
    "objectID": "posts/Recitation_M2_2/Recitation_M2_2.html#step-2-coverage-of-resampled-population-means",
    "href": "posts/Recitation_M2_2/Recitation_M2_2.html#step-2-coverage-of-resampled-population-means",
    "title": "Bootstrapping",
    "section": "Step 2: Coverage of resampled population means",
    "text": "Step 2: Coverage of resampled population means\nNext we are going to calculate the percentage of the confidence intervals from part 4 (the confidence intervals from resampling from the population) cover the true population mean.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWe can see that almost exactly 95% of the confidence intervals constructed overlap with the true population mean. This is what we would expect based on the interpretation of a confidence interval.\nHere is a plot to show the first 200 confidence intervals we calculated above, where the color indicates if the interval covers the true mean or not. Think of each row (interval) as a different sample of size 100 and the 95% confidence interval we would calculate based on that sample. Statistical theory tells us that 95% of these intervals should cover the true population mean, and 5% will not.\n\nPlotPlot Code\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n```{webr-r}\n# plotting the first 200 intervals\nsampdist100 %&gt;%\n  slice(1:200) %&gt;%\n  mutate(pop_mean = mean(pop$x)) %&gt;%\n  mutate(iteration = row_number()) %&gt;%\n  mutate(covers = case_when(lower &lt;= pop_mean & upper &gt;= pop_mean ~ \"Covers mean\",\n                           lower &gt; pop_mean | upper &lt; pop_mean ~ \"Does not cover mean\")) %&gt;%\n  ggplot(aes(x = mean, y = iteration, color = covers)) + \n  geom_point(size = 0.5) + \n  geom_errorbarh(aes(xmin=lower, xmax = upper), linewidth = 0.25) + \n  theme_bw() + \n  labs(color = element_blank()) + \n  geom_vline(aes(xintercept = pop_mean)) + \n  scale_color_manual(values = c(\"navy\",\"red\"))\n```\n\n\n\nIn practice, we only have one sample. We have no way of knowing if our sample is one of the 5% of unlucky samples that doesn’t produce a confidence interval that covers the true mean, but since in the long run most confidence intervals will cover the true mean, we say “we are 95% confident that our interval covers the true mean.”"
  },
  {
    "objectID": "posts/Recitation_M2_2/Recitation_M2_2.html#comparison-boostrap-vs-resampling-from-the-population",
    "href": "posts/Recitation_M2_2/Recitation_M2_2.html#comparison-boostrap-vs-resampling-from-the-population",
    "title": "Bootstrapping",
    "section": "Comparison: boostrap vs resampling from the population",
    "text": "Comparison: boostrap vs resampling from the population\nTo compare the distribution obtained in part 4 to that obtained in part 2, we’re going to plot the two distributions next to each other. Here I’m just showing the plot output, but you can toggle to the next tab to see the code that produced this plot if you’re interested.\n\nPlotPlot Code\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n```{webr-r}\n# plot the two next to each other using ggplot\ndata.frame(x = c(sampdist100$mean, boot_10000$mean), \n           sampling = rep(c(\"Resample from population\", \"Bootstrap\"), each = 10000)) %&gt;%\n  mutate(pop_mean = mean(pop$x),\n         samp_mean = mean(samp$x)) %&gt;%\n  ggplot(aes(x = x, fill = sampling)) + # color by which method was used\n  geom_histogram(color = \"black\", binwidth = 0.1) + \n  facet_wrap(.~ sampling, nrow = 2) + # separate plots\n  theme_bw() + \n  labs(x = \"Sample Means\", fill = \"Method\") +\n  scale_fill_manual(values = c(\"lightcoral\",\"skyblue\")) + \n  geom_vline(aes(xintercept = samp_mean, color = \"Sample Mean\", linetype = \"Sample Mean\" ), show.legend = TRUE) + # add a dashed vertical line at the original sample mean\n  geom_vline(aes(xintercept = pop_mean, color = \"Population Mean\", linetype = \"Population Mean\"), show.legend = TRUE) +# add a vertical line at the population mean \n  scale_color_manual(name = \"\",\n                     values = c(\"Sample Mean\" = \"firebrick1\", \"Population Mean\" = \"blue\")) +\n  scale_linetype_manual(name = \"\",\n                     values = c(\"Sample Mean\" = 2, \"Population Mean\" = 1)) \n\n```\n\n\n\nNotice that the two distributions are fairly similar, though the bootstrap is centered at the sample mean observed in our data, while the distribution obtained from resampling from the actual population is centered near the true population mean (as expected). Both distributions are symmetric and they have similar spread."
  },
  {
    "objectID": "posts/Recitation_M2_2/Recitation_M2_2.html#comparing-this-to-the-theory-based-confidence-interval",
    "href": "posts/Recitation_M2_2/Recitation_M2_2.html#comparing-this-to-the-theory-based-confidence-interval",
    "title": "Bootstrapping",
    "section": "Comparing this to the theory-based confidence interval",
    "text": "Comparing this to the theory-based confidence interval\nIf we wanted to see what confidence interval we would get from our sample based on the equation, we can use the following code:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThis is very similar to the bootstrap confidence interval we got and does contain the true population mean of 2.4759. The idea here is that the bootstrap empirically simulates a sampling distribution based on our sample, while the theory-based confidence interval uses a few sample statistics (the mean and standard deviation) and statistical theory to estimate the sampling distribution. Then both calculate boundaries between which 95% of the sample distribution lies."
  },
  {
    "objectID": "posts/Recitation_M2_2/Recitation_M2_2.html#create-data-set-with-populaiton",
    "href": "posts/Recitation_M2_2/Recitation_M2_2.html#create-data-set-with-populaiton",
    "title": "Bootstrapping",
    "section": "Create data set with populaiton",
    "text": "Create data set with populaiton\nFill in the following code with the appropriate parameters so that ‘pop’ is a sample of size 10000 drawn from a Poisson distribution with lambda = 2.5. We will treat this as our population for the remainder of the exercise.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "posts/Recitation_M2_2/Recitation_M2_2.html#plot-the-population",
    "href": "posts/Recitation_M2_2/Recitation_M2_2.html#plot-the-population",
    "title": "Bootstrapping",
    "section": "Plot the Population",
    "text": "Plot the Population\nMake a plot of the simulated data to display the population distribution. Hint: think about the type of variable this is (quantitative/qualitative) and the types of plots that are used for this type of variable.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "posts/Recitation_M2_2/Recitation_M2_2.html#summary-values-on-the-population",
    "href": "posts/Recitation_M2_2/Recitation_M2_2.html#summary-values-on-the-population",
    "title": "Bootstrapping",
    "section": "Summary values on the population",
    "text": "Summary values on the population\nCalculate the mean, standard deviation, and variance in the population. Is it what you would expect?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThis is what we would expect, since the population was drawn randomly from a Poisson distribution with lambda = 2.5 (the mean and variance of a Poisson distribution are equal to lambda). We observe a mean of 2.4759 and a variance of 2.449064, which are very close to 2.5. The standard deviation is the square root of the variance, about 1.565."
  },
  {
    "objectID": "posts/Recitation_M2_2/Recitation_M2_2.html#sample-of-size-100",
    "href": "posts/Recitation_M2_2/Recitation_M2_2.html#sample-of-size-100",
    "title": "Bootstrapping",
    "section": "Sample of size 100",
    "text": "Sample of size 100\nFill in the code below so that ‘samp’ contains a sample of size 100 sampled without replacement from our population.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "posts/Recitation_M2_2/Recitation_M2_2.html#plot-the-data.",
    "href": "posts/Recitation_M2_2/Recitation_M2_2.html#plot-the-data.",
    "title": "Bootstrapping",
    "section": "Plot the data.",
    "text": "Plot the data.\nMake a plot to show the distribution of the sampled data.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe sample looks very similar to the population distribution, which is expected since we sampled randomly. The population has a few more extreme values (around 9, 10, 11, etc) than we observe in the sample. This also makes sense, given that these are rare observations and it’s less likely to pull one of these randomly than to pull a value near the center of the distribution (around 2-3, for example)."
  },
  {
    "objectID": "posts/Recitation_M2_2/Recitation_M2_2.html#bootstrapped-means",
    "href": "posts/Recitation_M2_2/Recitation_M2_2.html#bootstrapped-means",
    "title": "Bootstrapping",
    "section": "Bootstrapped means",
    "text": "Bootstrapped means\nHere I’ve included code to produce 10,000 bootstrap samples from our original sample and saved the mean from each bootstrap sample. You don’t need to write the code for this– I’ve done it for you. This code chunk is just so you can see how the code works. The procedure is:\n\nResample with replacement from the original sample to get a new sample of size 100 (the same size as the original sample). This is a bootstrap sample.\nCalculate the mean value on the on the bootstrap sample.\nRepeat this process many times (I chose 10,000 in this example, but we just want it large enough that we can visualize the distribution of the means that we calculated in step 2).\n\nThe result is a set of 10,000 (or whatever number of bootstrap iterations you chose to run) bootstrap means.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "posts/Recitation_M2_2/Recitation_M2_2.html#plot-the-bootstrapped-means",
    "href": "posts/Recitation_M2_2/Recitation_M2_2.html#plot-the-bootstrapped-means",
    "title": "Bootstrapping",
    "section": "Plot the bootstrapped means",
    "text": "Plot the bootstrapped means\nPlot the distribution of the means of the bootstrapped samples. Describe the distribution.\nAssuming the central limit theorem (CLT), what would we expect this distribution to be? Is our observed distribution close to what we would expect?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe distribution appears approximately normal centered at around 2.5 (mean = 2.56) with a standard deviation of 0.17. This is very similar to what we would expect from the central limit theorem CLT, which tells us that the mean should be centered at the true population mean (our population had a mean of 2.48) and the standard error should be our population standard deviation/(root n) (1.56/sqrt(100) = 0.156)."
  },
  {
    "objectID": "posts/Recitation_M2_2/Recitation_M2_2.html#resample-from-population",
    "href": "posts/Recitation_M2_2/Recitation_M2_2.html#resample-from-population",
    "title": "Bootstrapping",
    "section": "Resample from population",
    "text": "Resample from population\nNow draw we’re going 10000 samples of size 100 without replacement from the population and calculate the mean for each and a 95% confidence interval.\nWe haven’t learned the specific formula for confidence intervals yet so I have provided the code for you here.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "posts/Recitation_M2_2/Recitation_M2_2.html#the-boostrap-confidence-interval",
    "href": "posts/Recitation_M2_2/Recitation_M2_2.html#the-boostrap-confidence-interval",
    "title": "Bootstrapping",
    "section": "The boostrap confidence interval",
    "text": "The boostrap confidence interval\nHere we will compute a 95% confidence interval for the bootstrapped sample means with 10,000 repetitions by taking the 2.5th percentile and the 97.5th percentile of the bootstrapped means that we got above. These two values will tell us the range of values that contains the middle 95% of the observed bootstrapped means.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThis tells us that when we resampled (with replacement) samples of size 100 from our original sample, we obtained sample means between 2.08 and 2.78 in 9,500 of the 10,000 bootstrap samples (95% of the bootstrap iterations) and only 5% of the bootstrap samples gave us a mean outside of this range."
  },
  {
    "objectID": "posts/Recitation_M2_2/Recitation_M2_2.html#coverage-of-resampled-population-means",
    "href": "posts/Recitation_M2_2/Recitation_M2_2.html#coverage-of-resampled-population-means",
    "title": "Bootstrapping",
    "section": "Coverage of resampled population means",
    "text": "Coverage of resampled population means\nNext we are going to calculate the percentage of the confidence intervals from part 4 (the confidence intervals from resampling from the population) cover the true population mean.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWe can see that almost exactly 95% of the confidence intervals constructed overlap with the true population mean. This is what we would expect based on the interpretation of a confidence interval.\nHere is a plot to show the first 200 confidence intervals we calculated above, where the color indicates if the interval covers the true mean or not. Think of each row (interval) as a different sample of size 100 and the 95% confidence interval we would calculate based on that sample. Statistical theory tells us that 95% of these intervals should cover the true population mean, and 5% will not. .\n\nPlotPlot Code\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n```{webr-r}\n# plotting the first 200 intervals\nsampdist100 %&gt;%\n  slice(1:200) %&gt;%\n  mutate(pop_mean = mean(pop$x)) %&gt;%\n  mutate(iteration = row_number()) %&gt;%\n  mutate(covers = case_when(lower &lt;= pop_mean & upper &gt;= pop_mean ~ \"Covers mean\",\n                           lower &gt; pop_mean | upper &lt; pop_mean ~ \"Does not cover mean\")) %&gt;%\n  ggplot(aes(x = mean, y = iteration, color = covers)) + \n  geom_point(size = 0.5) + \n  geom_errorbarh(aes(xmin=lower, xmax = upper), linewidth = 0.25) + \n  theme_bw() + \n  labs(color = element_blank(), x = \"x\") + \n  geom_vline(aes(xintercept = pop_mean)) + \n  scale_color_manual(values = c(\"navy\",\"red\"))\n```\n\n\n\nIn this set of 200 resampling iterations, we see that 9 out of 200 (4.5%) of the iterations produced a confidence interval that did not contain the population mean, and the remaining 191 (95.5%) did contain the true mean.\nIn practice, we typically only have one sample. We have no way of knowing if our sample is one of the unlucky 5% of samples that doesn’t produce a confidence interval that covers the true mean, but since in the long run most confidence intervals will cover the true mean, we say “we are 95% confident that our interval covers the true mean.”"
  },
  {
    "objectID": "index.html#recitation-materials",
    "href": "index.html#recitation-materials",
    "title": "Intro Biostatistics Resources",
    "section": "Recitation Materials",
    "text": "Recitation Materials\n\n\n\n\n\n\n\n\n\n\nBootstrapping\n\n\n\n\n\n\nStatistical Inference\n\n\n\n\n\n\n\n\n\nHaley Grant\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "About",
      "Intro Biostatistics Resources"
    ]
  },
  {
    "objectID": "posts/Tutorial-6/Tutorial6.html",
    "href": "posts/Tutorial-6/Tutorial6.html",
    "title": "Tutorial 6: Data Summarization in R",
    "section": "",
    "text": "In this tutorial, we will be covering how to summarize data using R. This can include:\n\nsingle variable summaries\n\ncounts,\nproportions,\nmeasures of center (mean, median),\nmeasures of spread (standard deviation, variance, IQR)\n\nbivariate summaries\n\ncounts by group,\nproportions by group,\nmeasures of center by group,\nmeasures of spread by group,\ncorrelation\n\n\nWe will once again be using the census data from Tutorials 3 and 5 to demonstrate how to create numerical summaries using R. I’ve already read the data in for you; feel free to run the code below to remind yourself of the variables in the data set that we will be working with.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWe will also be utilizing the tidyverse package again, so let’s go ahead and load that package into our work space so we don’t forget!\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "posts/Tutorial-6/Tutorial6.html#introduction",
    "href": "posts/Tutorial-6/Tutorial6.html#introduction",
    "title": "Tutorial 6: Data Summarization in R",
    "section": "",
    "text": "In this tutorial, we will be covering how to summarize data using R. This can include:\n\nsingle variable summaries\n\ncounts,\nproportions,\nmeasures of center (mean, median),\nmeasures of spread (standard deviation, variance, IQR)\n\nbivariate summaries\n\ncounts by group,\nproportions by group,\nmeasures of center by group,\nmeasures of spread by group,\ncorrelation\n\n\nWe will once again be using the census data from Tutorials 3 and 5 to demonstrate how to create numerical summaries using R. I’ve already read the data in for you; feel free to run the code below to remind yourself of the variables in the data set that we will be working with.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWe will also be utilizing the tidyverse package again, so let’s go ahead and load that package into our work space so we don’t forget!\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "posts/Tutorial-6/Tutorial6.html#single-variable-summaries",
    "href": "posts/Tutorial-6/Tutorial6.html#single-variable-summaries",
    "title": "Tutorial 6: Data Summarization in R",
    "section": "Single variable summaries",
    "text": "Single variable summaries\nWe’ll start with single variable summaries, that is, getting summary metrics for just one variable at a time."
  },
  {
    "objectID": "posts/Tutorial-6/Tutorial6.html#quantitative-variable",
    "href": "posts/Tutorial-6/Tutorial6.html#quantitative-variable",
    "title": "Tutorial 6: Data Summarization in R",
    "section": "Quantitative variable",
    "text": "Quantitative variable\nIn tutorial 5, we made a histogram and box plot to display the variable total_personal_income. This is a quantitative variable, so the summary metrics that we can use are measures of center such as mean or median and measures of spread such as standard deviation, variance, and interquartile range (IQR).\n\nThe summarise() function\nWe can calculate these summary statistics within the data set, we can utilize the summarise() function from the dplyr package (part of the tidyverse). This function is similar to the mutate() function that we used in Tutorial 4 in that it can create new columns. However, instead of just adding new columns to an existing data set, the summarise() function condenses the data and only shows the summarized information. To see this, let’s try taking the mean of the variable total_personal_income both with the mutate() function and with the summarise() function.\nTry running the following two code chunks to see the difference between mutate() and summarise()\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNotice how the mutate() implementation adds a new column with the mean income in the data set repeated for every row, whereas the summarise() implementation just prints the mean income and exludes all individual rows.\n\n\nThe drop_na() function\nNotice that we had to drop the missing values (NA values) from the total_personal_income column to calculate the mean. We will have to do this to calculate all of the additional summary statistics, so one option we have is to exclude all of the rows with a missing value in the total_personal_income column before applying the summarise() function. We can do this with the drop_na() function (from the tidyr package also within the tidyverse). Inside the parentheses, we can include the names of all of the columns that we want drop missing observations from. If we leave this blank (just write drop_na() with nothing in the parentheses, R will remove any row with a missing value in any column). In this case we’ll just drop the rows with missing total personal income. This will be helpful when we want to compute multiple statistics and don’t want to include a na.rm = T argument in each function.\nTo see how the drop_na() function works, we can run the following code to check the number of rows in the data frame with and without applying the drop_na() function.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nNote\n\n\n\nNote that drop_na() doesn’t permanently remove the rows with missing values unless save you save the data frame with an assign operator (= or &lt;-). For example,\ncensus2 &lt;- census %&gt;%\n  drop_na(total_personal_income)\nWould save the filtered data set with no missing values in total_personal_income under the new name census2. If we had used the old name (census instead of census2), this would overwrite our old data frame. Be careful with this and only overwrite your data if you know you want to keep the changes you’re making!\n\n\nIf we use the filtered data with no missing values in the total_personal_income column, we can omit the na.rm = T argument when we take the mean:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nCalculating multiple statistics\nWe don’t have to just calculate one summary statistic at a time. For example, we can calculate the mean, median, minimum, maximum, 25th percentile, 75th percentile, standard deviation, and variance, all within one sumamrise() function.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "posts/Tutorial-6/Tutorial6.html#quantitative-variables",
    "href": "posts/Tutorial-6/Tutorial6.html#quantitative-variables",
    "title": "Tutorial 6: Data Summarization in R",
    "section": "Quantitative variables",
    "text": "Quantitative variables\nIn Tutorial 5, we made a histogram and box plot to display the variable total_personal_income. This is a quantitative variable, so the summary metrics that we can use are measures of center such as mean or median and measures of spread such as standard deviation, variance, and interquartile range (IQR).\n\nThe summarise() function\nWe can calculate these summary statistics within the data set, we can utilize the summarise() function from the dplyr package (part of the tidyverse). This function is similar to the mutate() function that we used in Tutorial 4 in that it can create new columns. However, instead of just adding new columns to an existing data set, the summarise() function condenses the data and only shows the summarized information. To see this, let’s try taking the mean of the variable total_personal_income both with the mutate() function and with the summarise() function.\nTry running the following two code chunks to see the difference between mutate() and summarise()\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNotice how the mutate() implementation adds a new column with the mean income in the data set repeated for every row, whereas the summarise() implementation just prints the mean income and exludes all individual rows.\n\n\nThe drop_na() function\nNotice that we had to drop the missing values (NA values) from the total_personal_income column to calculate the mean. We will have to do this to calculate all of the additional summary statistics, so one option we have is to exclude all of the rows with a missing value in the total_personal_income column before applying the summarise() function. We can do this with the drop_na() function (from the tidyr package also within the tidyverse). Inside the parentheses, we can include the names of all of the columns that we want drop missing observations from. If we leave this blank (just write drop_na() with nothing in the parentheses, R will remove any row with a missing value in any column). In this case we’ll just drop the rows with missing total personal income. This will be helpful when we want to compute multiple statistics and don’t want to include a na.rm = T argument in each function.\nTo see how the drop_na() function works, we can run the following code to check the number of rows in the data frame with and without applying the drop_na() function.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nNote\n\n\n\nNote that drop_na() doesn’t permanently remove the rows with missing values unless save you save the data frame with an assign operator (= or &lt;-). For example,\ncensus2 &lt;- census %&gt;%\n  drop_na(total_personal_income)\nWould save the filtered data set with no missing values in total_personal_income under the new name census2. If we had used the old name (census instead of census2), this would overwrite our old data frame. Be careful with this and only overwrite your data if you know you want to keep the changes you’re making!\n\n\nIf we use the filtered data with no missing values in the total_personal_income column, we can omit the na.rm = T argument when we take the mean:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nCalculating multiple statistics\nWe don’t have to just calculate one summary statistic at a time. For example, we can calculate the mean, median, minimum, maximum, 25th percentile, 75th percentile, standard deviation, and variance, all within one sumamrise() function.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNotice that the mean is much larger than the median, indicate left skew in the data.\nWe can couple these statistics with a histogram to get a fuller picture of the distribution.\n\nHistogramCode\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nThis is the code used to produce the plot:\n```{webr-r}\ncensus %&gt;%\n  ggplot(aes(x = total_personal_income)) +\n  geom_histogram(binwidth = 10000, fill = \"skyblue\", color = \"black\") + # bins of size $10,000\n  theme_bw() + \n  labs(x = \"Total personal income ($)\")\n```"
  },
  {
    "objectID": "posts/Tutorial-6/Tutorial6.html#qualitative-variables",
    "href": "posts/Tutorial-6/Tutorial6.html#qualitative-variables",
    "title": "Tutorial 6: Data Summarization in R",
    "section": "Qualitative variables",
    "text": "Qualitative variables\nIn Tutorial 5, we made a bar plot showing the breakdown of marital status in the census data. We can also compute summary statistics for this variable. For categorical variables like this, there aren’t as many summary statistics we can compute; we generally stick to counts and proportions."
  },
  {
    "objectID": "posts/Tutorial-6/Tutorial6.html#the-xtabs-function",
    "href": "posts/Tutorial-6/Tutorial6.html#the-xtabs-function",
    "title": "Tutorial 6: Data Summarization in R",
    "section": "The xtabs() function",
    "text": "The xtabs() function\nOne way to do this is to use the xtabs() function from the stats package (which comes pre-loaded in R). The syntax for this function is:\n\nxtabs( ~ variable_name, data = data_name)\n\nWe will also use this function later when we want to make a contingency table in which we tabulate an outcome across different groups.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nIf we want to show this in terms of proportions instead of raw counts, we can apply the prop.table() function after this:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nHere we can see that never married/single is the most frequent category in the data (n = 222, 44.4%), followed by married with spouse present (n = 192, 38.4%), divorced (n = 38, 7.6%), widowed (n = 31, 6.2%), married with spouse absent (n = 14, 2.8%), and the least common was separated (n = 3, 0.6%)."
  },
  {
    "objectID": "posts/Tutorial-6/Tutorial6.html#the-n-and-group_by-functions",
    "href": "posts/Tutorial-6/Tutorial6.html#the-n-and-group_by-functions",
    "title": "Tutorial 6: Data Summarization in R",
    "section": "The n() and group_by() functions",
    "text": "The n() and group_by() functions\nWe can also make these tables using the summarise function like we did above. However, to do this, we are going to need to first utilize the group_by() function. The group_by() function from the dplyr package allows us to specify groups within which we will calculate summary statistics. To make a table of counts, we will first group by martial status and then use the n() function, which simply counts the number of observations present. By grouping first, we will ensure that we are counting the number of observations within each level of the marital_status column separately.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nIf we want to calculate proportions, we can add an additional line of code:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nAgain, we can add a plot to visualize this difference:\n\nBar plotCode\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nThis is the code used to produce the plot:\n```{webr-r}\ncensus %&gt;%\n  ggplot(aes(x = marital_status, fill = marital_status)) +\n  geom_bar(color = \"black\") + \n  theme_classic() + \n  labs(title = \"Marital Status\", x = element_blank()) + \n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1), # rotate axis labels\n      legend.position = \"none\"  ) # remove color labels (labeled on x-axis, color is just for fun :) )\n\n```"
  },
  {
    "objectID": "posts/Tutorial-6/Tutorial6.html#one-quantitative-and-one-qualitative",
    "href": "posts/Tutorial-6/Tutorial6.html#one-quantitative-and-one-qualitative",
    "title": "Tutorial 6: Data Summarization in R",
    "section": "One quantitative and one qualitative",
    "text": "One quantitative and one qualitative\nSuppose we want to compare total personal income between biological sexes. To do this, we can calculate the same summary statistics we did above for total personal income, but first group by sex to calculate these statistics within each group. We can then make comparisons to see how similar/different they are. We will again utilize the group_by() function.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nHere we can see that within this sample, the mean income for female respondents was $17,441 and median was $14,000 while for male respondents these figures were $39,809 and $24,050, respectively. There was also a lot more variability in income reported by male respondents, with a standard deviation of $59,926 compared to $16,774 among female respondents.\nWe can also see this in side-by-side boxplots or histograms.\n\nHistogramsCode\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nThis is the code used to produce the plot:\n```{webr-r}\ncensus %&gt;%\n  ggplot(aes(x = total_personal_income, fill = sex)) +\n  geom_histogram(binwidth = 10000,  color = \"black\") + # bins of size $10,000\n  theme_bw() + \n  labs(x = \"Total personal income ($)\") + \n  facet_wrap(. ~ sex, nrow = 2) + \n  theme(legend.position = \"none\")\n\n```\n\n\n\n\nHistogramsCode\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nThis is the code used to produce the plot:\n```{webr-r}\ncensus %&gt;%\n  ggplot(aes(y = total_personal_income, x = sex, color = sex)) +\n  geom_boxplot() + \n  theme_bw() + \n  labs(y = \"Total personal income ($)\", x = \"Biological Sex\") + \n  theme(legend.position = \"none\")\n\n```"
  },
  {
    "objectID": "posts/Tutorial-6/Tutorial6.html#two-quantitative-variables",
    "href": "posts/Tutorial-6/Tutorial6.html#two-quantitative-variables",
    "title": "Tutorial 6: Data Summarization in R",
    "section": "Two quantitative variables",
    "text": "Two quantitative variables\nIf we want to evaluate the association between two quantitative variables, we typically use the correlation between the two variables (denoted R or r).\n\nCorrelation\nTo take the correlation between two variables, we can use the cor() function from the stats package. The function is expecting data in the form of two vectors. For example, if we want to take the correlation between age and total personal income, we can grab them both from the data set using the data_name$variable_name notation and then take the correlation. Once again, we will need to remove missing values to get a numeric value here. The argument to do this within the cor() function is the use argument, which we will set equal to \"pairwise.complete.obs\", which tells R to only use rows of the data that are complete (non-missing) for both age and total_personal_income columns.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWe can also do this within a summarise() function :\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nHere we can see that there is a slight positive correlation of 0.131 between age and total personal income. We can also see this somewhat in a scatterplot:\n\nBar plotCode\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nThis is the code used to produce the plot:\n```{webr-r}\ncensus %&gt;%\n  ggplot(aes(x = age, y = total_personal_income)) + \n  geom_point() + \n  theme_bw() + \n  labs(x = \"Age (years)\", y = \"Total Personal Income ($)\")\n```"
  },
  {
    "objectID": "posts/Tutorial-6/Tutorial6.html#two-qualitative-variables",
    "href": "posts/Tutorial-6/Tutorial6.html#two-qualitative-variables",
    "title": "Tutorial 6: Data Summarization in R",
    "section": "Two qualitative variables",
    "text": "Two qualitative variables\nFor two categorical variables, we can again make tables of counts and proportions and compare across groups. For example, we could check the breakdown of marital status by biological sex. We can do this using the xtabs() function again by simply adding in the extra variable:\n\nxtabs( ~ variable_name1 + variable_name2, data = data_name)\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nIn this case, adding proportions (or at least marginal totals) will be helpful if the groups are different sizes. In this case we will have options for how we want to take the proportions. We can:\n\ntake the proportion overall\ntake the proportion within rows\ntake the proportion within columns\n\nWhich one of these we want to use will depend on the question we’re trying to answer.\n\nTable with margins (row and column sums)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nTable of proportions (overall)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThis table shows the overall proportion. It shows that 20% of our sample is male and married with a spouse present and 18.4% of our sample is female and married with a spouse present.\n\n\nTable of proportions (by row)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThis table shows the proportion within rows. The proportions sum to 1 along the rows. This tells us that 48% of male respondents were never married/single compared to 40% of female respondents who were never married/single. About 8% of the female respondents were widowed, compared to only 4% of the male respondents.\n\n\nTable of proportions (by column)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nFinally, this table shows the proportion within columns. The proportions sum to 1 along the columns. This tells us that among those who were widowed, 64.5% were female and 35.5% were male.\n\n\nTables with summarise()\nWe can also make these tables by using the summarise() function paired with group_by as before:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nEach of these tables shows something slightly different and the one that is most relevant will depend on the trend we are trying to evaluate and possibly the sampling mechanism.\nTo view these in a plot, we have a lot of options. Two good options are to either calculate proportions and plot the proportions side-by-side, or to plot the counts for each group separately and place the plots next to/ on top of each other.\n\nBar plotCode\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nThis is the code used to produce the plot:\n```{webr-r}\ncensus %&gt;%\n  group_by(sex, marital_status) %&gt;%\n  summarise(count = n()) %&gt;%\n  mutate(prop = count/sum(count)) %&gt;%\n  ggplot(aes(x = marital_status, y = prop, fill = sex)) +\n  geom_bar(color = \"black\", position = \"dodge\", stat = \"identity\") + \n  theme_classic() + \n  labs(title = \"Marital Status Proportions\", x = element_blank(),\n       y = \"Proportion\", fill = element_blank()) + \n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)  )# rotate axis labels\n\n```\n\n\n\n\nBar plotCode\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nThis is the code used to produce the plot:\n```{webr-r}\ncensus %&gt;%\n  ggplot(aes(x = marital_status, fill = marital_status)) +\n  geom_bar(color = \"black\") + \n  theme_classic() + \n  labs(title = \"Marital Status by Sex\", x = element_blank()) + \n  facet_wrap(. ~ sex, nrow = 1) +\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1), # rotate axis labels\n      legend.position = \"none\"  ) # remove color labels (labeled on x-axis, color is just for fun :) )\n```"
  },
  {
    "objectID": "posts/Tutorial-2/Tutorial2.html#solution",
    "href": "posts/Tutorial-2/Tutorial2.html#solution",
    "title": "Tutorial 2: R Objects, Functions, and Packages",
    "section": "Solution",
    "text": "Solution\nThe problem with the code above is that I accidentally included the name of the vector object (x_vector) in quotation marks (\"x_vector\"). If you include the name of an object in quotation marks, R will just think it’s a character string and not the name of a saved object in the directory. If you remove the quotation marks, the code should work as expected!\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "posts/Tutorial-3/Tutorial3.html#files-and-file-structures",
    "href": "posts/Tutorial-3/Tutorial3.html#files-and-file-structures",
    "title": "Tutorial 3: Importing Data into R",
    "section": "Files and File Structures",
    "text": "Files and File Structures\n\nFiles on your local computer\nWhen you are working in R on your local computer and you want to import a data file into your R session for an analysis, you will need to tell R where it can find the data file. This is why I suggested creating a ‘Data’ folder in your class folder. If you save all of the data files for this class in that folder, you can always use the same general syntax for telling R where your file is.\nFor this tutorial, we are working on the web, so R doesn’t have access to the local files on your device. I have included all of the data files we will be using in this tutorial on a webpage that we can access online. You may need to change this code slightly to when running code for your assignments in this class to work with your computer’s file structure.\n\n\nChecking your working directory\nOne good idea when you start working on a new analysis is to make sure you know where within your computer’s file structure you are working so you can figure out how to access various files.\nWe can use the function getwd() to have R print out the path to the directory (folder) we are currently working in.\nTry running the code in this block:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nYou should see the output is:\n\n“/home/web_user”\n\nThis is because we are working in R on the web. This is telling us that we are in a sub-directory of the “home” directory called “web_user”. That is, “web_user” is a directory (folder) inside the larger directory (folder) called “home”. You read file paths from left to right.\n\nTry running this in your Console in RStudio on your computer, and you should see a file path that corresponds to the file structure on your computer.\n\n\n\nFile paths\nFile paths are a way of specifying the location of a file within a computer’s file system. There are two kinds of file paths, absolute paths and relative paths. Both can be useful in different situations.\n\nAbsolute file paths are file paths that start at the root node of your computer (often starting with something like “C:” in Windows and “/Users/” in Unix-like operating systems like macOS). Absolute paths can get fairly long if files are contained within many levels of sub-directories.\nRelative file paths are paths that start at the current working directory, and are therefore often shorter than absolute paths.\n\nThe function we used above, getwd(), prints absolute paths, so we are currently working in the “web_user” sub-directory of the root directory called “home”. The image below is a visual representation of the file structure.\n\n\n\nList files in working directory\nTo check the files that exist in our current directory, we can use the function list.files() to print a list of all the files that are stored in the directory where we are currently working. If we just want to print the files in our working directory, we can run the function without giving it a file path and just leave the inside of the parentheses blank (this will assume you want to list the files in your current directory). We could also input a file path to the function.\nTry running the code in this block:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nExercise:\n\n\n\nTry running the line of code above with but remove everything from inside the set of parentheses. Do you notice a difference?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThere shouldn’t be any difference since we used the absolute path to the current working directory!\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\nThe output should look something like this:\n\n[1] “Data” “Rplots.pdf”\n\nThis tells us that there are 2 objects that we have access to in this directory:\n\nA folder called “Data”\n\nOne clue that it’s a folder instead of a file is that it doesn’t have a file extension (like “.pdf”) on the end\n\nA file called “Rplots.pdf”\n\nWe won’t be working with this file\n\n\nIf we want to see the files contained within the sub-folder “Data”, we can add this to the end of our absolute file path within the path argument:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nEquivalently, with Relative Path\n\n\n\n\n\nThis code will give us the same output as above:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nAlternatively, we could add an extra argument to the original code that allows us to print files within subdirectories recursively. This argument tells R to print the contents of any subfolders contained within our directory (stopping when there are no further nested folders).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nAll of these tell us that within the sub-folder called “Data”, we have three files:\n\na file called “cdc_samp.csv”\na file called “census.rda”\na file called “dds.xlsx”\n\nThese are the data files that we will be working with in this tutorial."
  },
  {
    "objectID": "posts/Tutorial-5/Tutorial5.html#histograms",
    "href": "posts/Tutorial-5/Tutorial5.html#histograms",
    "title": "Tutorial 5: Data Visualization in R",
    "section": "Histograms",
    "text": "Histograms\nA histogram is a visual representation of quantitative data in which the range of values is split into adjacent, non-overlapping intervals (or “bins”) and the number of observations that fall into each interval is counted and depicted on the plot.\nLet’s make a histogram of the variable total_personal_income.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nYou should see a few messages shown in the output. These messages aren’t errors (they aren’t a problem), but it’s good to know what they mean.\nThe first message:\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\nis telling us that the geom_histogram() function defaulted to splitting the range into 30 intervals (bins). We can change this if we want using either the bins argument to specify the number of bins desired, or the bindwidth argument to specify the size of the bins/intervals, in geom_histogram().\nFor example, if we want to make more, smaller width bins we could specify bins = 50 instead of the default of 30 using the following code:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWe could also specify the size of the bins, rather than the number of bins. For example, since this variable refers to annual income, maybe we would want to show bins of size $10,000. Specifying the binwidth argument is highly data-dependent (we wouldn’t want to use a bin size of 10,000 if the variable was height measured in inches, for example 🙂 ). Here’s an example of specifying binwidth:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe other message is a warning message:\n\nWarning: Removed 108 rows containing non-finite outside the scale range (`stat_bin()`)\n\nThis is R’s way of telling us that some of the rows were removed and were not included in the plot. We can see that 108 observations (rows) were removed for plotting. This is generally because there are missing values. The ggplot2 functions don’t have any way of plotting missing values, so they get skipped in these plotting functions.\nTo see that these observations came from missing values, we can look a bit more into the data. For example, we can count the number of rows for which the column total_personal_income is an NA value using the is.na() function:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nSum of logical values\n\n\n\n\n\nNote here that is.na(census$total_personal_income) returns a vector of TRUE/FALSE (logical) values. When you take the sum of TRUE/FALSE values in R, it returns the number that are TRUE.\nFor example:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nWe can see from these histograms that we have a highly right-skewed variable. There are a lot of observations under $100,000 (1e+05) and then a handful of observations all the way to over $400,000."
  },
  {
    "objectID": "posts/Tutorial-5/Tutorial5.html#box-plots",
    "href": "posts/Tutorial-5/Tutorial5.html#box-plots",
    "title": "Tutorial 5: Data Visualization in R",
    "section": "Box plots",
    "text": "Box plots\nAnother way we can visualize quantitative data is using box plots. Box plots can be particularly helpful if you want to compare the distribution of a particular quantitative variable across different groups. For example, maybe we want to compare the distribution of total_personal_income across different levels of marital_status. We can do this with box plots.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nNote\n\n\n\nHere we can see that the labels on the x-axis are overlapping, making it hard to read the plot. We’ll get more into this later when we go over other aesthetic changes we can make to plots made with ggplot."
  },
  {
    "objectID": "posts/Tutorial-5/Tutorial5.html#bar-plots",
    "href": "posts/Tutorial-5/Tutorial5.html#bar-plots",
    "title": "Tutorial 5: Data Visualization in R",
    "section": "Bar plots",
    "text": "Bar plots\nA bar plot is a tool to visualize a categorical variable. It is similar to a histogram in that it shows the number of times each level of a variable is observed in a data set. For example, in the plot above we showed the distribution of personal income across marital status, but maybe we want to know how many people fell into each of these marital status categories. We can use a bar plot for this.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nFrom this plot we can see that “Never married/single” is the most commonly observed marital status in our data, followed closely by “Married/spouse present”. The status “Separated” was the last common, followed by “Married/spouse absent”. The categories “Divorced” and “Widowed” were somewhere in between."
  },
  {
    "objectID": "posts/Tutorial-5/Tutorial5.html#scatter-plots",
    "href": "posts/Tutorial-5/Tutorial5.html#scatter-plots",
    "title": "Tutorial 5: Data Visualization in R",
    "section": "Scatter plots",
    "text": "Scatter plots\nA scatter plot is a way of visualizing the relationship between two numeric variables. For example, if we want to know how total_personal_income relates to age in this data set, we can use a scatter plot. Here is some example code to make a scatter plot:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "posts/HeightActivityShiny/HeightActivity_shiny.html",
    "href": "posts/HeightActivityShiny/HeightActivity_shiny.html",
    "title": "Sampling Activity",
    "section": "",
    "text": "#| standalone: true\n#| viewerHeight: 1000\n\n# ui.R\nlibrary(shiny)\nlibrary(plotly)\nlibrary(tidyverse)\n\nui &lt;- fluidPage(\n  titlePanel(\"Sampling Distribution Simulation\"),\n  sidebarLayout(\n    sidebarPanel(\n      fileInput(\"file1\", \"Choose CSV File\", accept = \".csv\"),\n      uiOutput(\"columnSelectUI\"),  # Dropdown for selecting the column\n      numericInput(\"sampleSize\", \"Sample size:\", min = 1, value = 10),\n      numericInput(\"numSamples\", \"Number of resamples:\", min = 1, value = 1000),\n      actionButton(\"update\", \"Draw Samples\")\n      \n    ),\n    mainPanel(\n      fluidRow(\n        conditionalPanel(\"output.showHeader==true\" ,\n                         h3(\"Original Data Distriubtion\", align = \"center\")),\n        splitLayout(cellWidths = c(\"50%\", \"50%\"), \n                    plotlyOutput(\"dataPlot\"),  # Interactive scatter plot for data points\n                    plotOutput(\"dataHist\"))    # Histogram for data distribution\n      ),\n      actionButton(\"removePoint\", \"Remove Selected Point\"),\n      conditionalPanel(\n        condition = \"output.showSimPanel == true\", \n        h3(\"Simulated Samples\",align = \"center\"),\n        numericInput(\"index\", \"Index of resample to plot\", value = 1, min = 1, max = 1000)\n      ,\n      fluidRow(\n        splitLayout(cellWidths = c(\"50%\", \"50%\"), cellArgs = list(align = \"center\", style = \"vertical-align: middle\"),\n                    plotOutput(\"samplePlot\", width = \"80%\", height = \"325px\"),  # Plot of specific sample \n                    plotOutput(\"distPlot\"))   # Plot for sampling distribution of sample means\n      ),\n      tableOutput(\"stats\"))\n    )\n  )\n)\n\nserver &lt;- function(input, output, session) {\n  data &lt;- reactiveVal(data.frame())\n  counter &lt;- reactiveVal(0)\n  showSimPanel &lt;- reactiveVal(FALSE)\n  showHeader &lt;- reactiveVal(FALSE)\n  \n  observeEvent(input$file1, {\n    req(input$file1)\n    df &lt;- read.csv(input$file1$datapath)\n    data(df)\n    \n    counter(0)\n    showSimPanel(FALSE)  # Hide the Simulated Samples section\n    showHeader(TRUE)\n    # Update the dropdown with column names after data is loaded\n    updateSelectInput(session, \"colName\", choices = colnames(df))\n     updateNumericInput(session, \"index\", value = 1)\n     \n    # Clear any previous plots or outputs\n  output$samplePlot &lt;- renderPlot({ NULL })\n  output$distPlot &lt;- renderPlot({ NULL })\n  output$sampleMeans &lt;- renderTable({ NULL })\n  output$stats &lt;- renderTable({ NULL })\n  })\n output$showHeader &lt;- reactive({\n    showHeader()\n  })\n  \n  outputOptions(output, \"showHeader\", suspendWhenHidden = FALSE) \n  \n  # UI for selecting the column\n  output$columnSelectUI &lt;- renderUI({\n    req(ncol(data()) &gt; 0)  # Ensure there are columns in the data\n    selectInput(\"colName\", \"Select Column:\", choices = colnames(data()), selected = colnames(data())[1])\n  })\n  \n  selected_point &lt;- reactiveVal(NULL)  # Initialize as NULL\n  \n  observe({\n    df &lt;- data()\n    req(input$colName %in% colnames(df))  # Ensure the column name exists\n    \n    output$dataPlot &lt;- renderPlotly({\n      req(nrow(df) &gt; 0)  # Ensure there is data to plot\n      plot_ly(df %&gt;% mutate(index = row_number()) %&gt;% highlight_key(~index), x = seq_len(nrow(df)),\n              y = ~df[[input$colName]], type = 'scatter', mode = 'markers',\n              marker = list(color = '#1f77b4', size = 8),\n              text = ~paste(\"Index:\", seq_len(nrow(df)), \"&lt;br&gt;Value:\", df[[input$colName]]),\n              hoverinfo = \"text\") %&gt;%\n        layout(title = paste0(\"Data Points: \", input$colName),\n               xaxis = list(title = \"Index\"),\n               yaxis = list(title = \"Value\")) %&gt;%\n        highlight(on = \"plotly_click\", off = \"plotly_doubleclick\")\n    })\n    \n    output$dataHist &lt;- renderPlot({\n      req(nrow(df) &gt; 0)  # Ensure there is data to plot\n      hist(df[[input$colName]], main = paste0(\"Population Distribution\\n n = \", nrow(df)), xlab = \"Values\", col = \"lightgreen\", border = \"white\", breaks = 15)\n    })\n  })\n  \n  observeEvent(event_data(\"plotly_click\"), {\n    click_data &lt;- event_data(\"plotly_click\")\n    if (!is.null(click_data) && !is.null(click_data$pointNumber)) {\n      selected_point(click_data$pointNumber + 1)  # +1 to match R's 1-based indexing\n    }\n  })\n  \n  observeEvent(input$removePoint, {\n    selected &lt;- selected_point()\n    req(!is.null(selected))  # Ensure a point is selected\n    df &lt;- data()\n    if (nrow(df) &gt; 0 && selected &lt;= nrow(df)) {\n      df &lt;- df[-selected, , drop = FALSE]\n      data(df)\n      selected_point(NULL)  # Clear the selection after removal\n    }\n  })\n  \n  observeEvent(input$update,{\n    counter(counter()+1)\n    showSimPanel(TRUE) \n  })\n   \n\n  observeEvent({input$numSamples \n    input$removePoint \n    input$sampleSize \n    input$colName},{\n  counter(0) \n    showSimPanel(FALSE) \n    updateNumericInput(session, \"index\", value = 1)\n    })\n\n\n\noutput$showSimPanel &lt;- reactive({\n    showSimPanel()\n  })\n  \n  outputOptions(output, \"showSimPanel\", suspendWhenHidden = FALSE) \n  observeEvent(counter(), {\n    if(counter()&gt;0){\n    req(data())\n    req(nrow(data()) &gt; 0)  # Check if there are rows in the data\n    req(input$sampleSize, input$numSamples, input$colName)\n    df &lt;- data()\n    \n    if (ncol(df) &gt; 0) {\n      sample_means &lt;- numeric(input$numSamples)\n      samples &lt;- vector(length = input$numSamples, mode = \"list\")\n      for (i in 1:input$numSamples) {\n        sample_data &lt;- df[sample(nrow(df), input$sampleSize, replace = TRUE), input$colName] %&gt;% as.data.frame()\n        samples[i] &lt;- sample_data \n        sample_means[i] &lt;- mean(sample_data[,1],na.rm=T)\n      }\n      \n      output$samplePlot &lt;- renderPlot({\n        samples[[input$index]] %&gt;%\n          data.frame() %&gt;%\n          ggplot(aes(x = .)) +\n          geom_dotplot(fill = \"indianred1\", color = \"white\") +\n          theme_classic() +\n          labs(x = \"Values\", title = paste0(\"Re-sample index: \", input$index)) +\n          xlim(c(min(data()[[input$colName]]), max(data()[[input$colName]]))) +\n          theme(axis.text.y = element_blank(),\n                axis.title.y = element_blank(),\n                axis.ticks = element_blank()) +\n          geom_vline(xintercept = mean(samples[[input$index]]),\n                     alpha = 0.5, color = \"indianred1\")\n      })\n      \n      output$distPlot &lt;- renderPlot({\n        req(input$sampleSize &gt; 0)\n        hist(sample_means,\n             breaks = seq(from = min(data()[[input$colName]]), to = max(data()[[input$colName]]),\n                          length.out = round(15 * log(input$sampleSize))),\n             main = \"Sampling Distribution of Sample Means\",\n             xlab = \"Sample Means\", col = \"lightblue\", border = \"white\",\n             xlim = c(min(data()[[input$colName]]), max(data()[[input$colName]])))\n      })\n      \n      output$sampleMeans &lt;- renderTable({\n        data.frame(SampleMeans = sample_means)\n      })\n      \n      output$stats &lt;- renderTable({\n        dt = data.frame(Mean = c(mean(data()[[input$colName]]), mean(sample_means)),\n                        SD = c(sd(data()[[input$colName]]), sd(sample_means)))\n        rownames(dt) &lt;- c(\"Population\", \"Sample Means\")\n        dt\n      }, bordered = T, rownames = T, align = \"c\")\n    } }\n  })\n}\n\nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "posts/NormalZ_Shiny/normalz_shiny.html",
    "href": "posts/NormalZ_Shiny/normalz_shiny.html",
    "title": "Standard Normal Distribution Visualization",
    "section": "",
    "text": "#| standalone: true\n#| viewerHeight: 800\n#| \nlibrary(shiny)\nlibrary(ggplot2)\n\nui &lt;- fluidPage(\n  titlePanel(\"Standard Normal Distribution Explorer\"),\n  \n  sidebarLayout(\n    sidebarPanel(\n      radioButtons(\"toggle\", \"Choose Input:\",\n                  choices = list(\"Z Statistic\" = \"z\", \"Probability\" = \"p\")),\n      \n      conditionalPanel(\n        condition = \"input.toggle == 'z'\",\n        sliderInput(\"z_value\", \"Z Statistic:\", min = -4, max = 4, value = 0, step = 0.01)\n      ),\n      \n      conditionalPanel(\n        condition = \"input.toggle == 'p'\",\n        sliderInput(\"p_value\", \"Probability:\", min = 0, max = 1, value = 0.5, step = 0.01)\n      ),\n      \n      selectInput(\"prob_type\", \"Probability Type:\",\n                  choices = list(\"P(Z &lt; z)\" = \"less\", \n                                 \"P(Z &gt; z)\" = \"greater\", \n                                 \"P(|Z| &gt; z)\" = \"two_sided_outside\",\n                                 \"P(|Z| &lt; z)\" = \"two_sided_inside\"))\n    ),\n    \n    mainPanel(\n      plotOutput(\"distPlot\")\n    )\n  )\n)\n\n\n\n\n\nserver &lt;- function(input, output) {\n  \n  # Reactive expression to calculate the Z or Probability based on input\n  calc_values &lt;- reactive({\n    if (input$toggle == \"z\") {\n      p &lt;- switch(input$prob_type,\n                  \"less\" = pnorm(input$z_value),\n                  \"greater\" = 1 - pnorm(input$z_value),\n                  \"two_sided_outside\" = 2 * (1 - pnorm(abs(input$z_value))),\n                  \"two_sided_inside\" = 1-(2 * (1 - pnorm(abs(input$z_value))) ))\n      return(list(z = input$z_value, p = p))\n    } else {\n      z &lt;- switch(input$prob_type,\n                  \"less\" = qnorm(input$p_value),\n                  \"greater\" = qnorm(1 - input$p_value),\n                  \"two_sided_outside\" = qnorm(1 - input$p_value / 2),\n                  \"two_sided_inside\" = abs(qnorm( abs((1-input$p_value) / 2) )))\n      return(list(z = z, p = input$p_value))\n    }\n  })\n  \n  output$distPlot &lt;- renderPlot({\n    values &lt;- calc_values()\n    \n    x &lt;- seq(-4, 4, length = 1000)\n    y &lt;- dnorm(x)\n    \n    if(input$prob_type==\"less\"){\n    p &lt;- ggplot(data.frame(x, y), aes(x, y)) +\n      geom_line() +\n      geom_area(data = data.frame(x = x[x &lt;= values$z], y = y[x &lt;= values$z]),\n                aes(x = x, y = y), fill = \"blue\", alpha = 0.3) +\n      geom_vline(xintercept = values$z, color = \"red\") +\n      ggtitle(paste(\"z =\", round(values$z, 2), \" | P =\", round(values$p, 4))) +\n      theme_minimal()\n    } else if(input$prob_type==\"greater\"){\n      p &lt;- ggplot(data.frame(x, y), aes(x, y)) +\n        geom_line() +\n        geom_area(data = data.frame(x = x[x &gt;= values$z], y = y[x &gt;= values$z]),\n                  aes(x = x, y = y), fill = \"blue\", alpha = 0.3) +\n        geom_vline(xintercept = values$z, color = \"red\") +\n        ggtitle(paste(\"z =\", round(values$z, 2), \" | P =\", round(values$p, 4))) +\n        theme_minimal()\n      \n      } else if (input$prob_type==\"two_sided_outside\"){\n      p &lt;- ggplot(data.frame(x, y), aes(x, y)) +\n        geom_line() +\n        geom_area(data = data.frame(x = x[x &gt;= values$z  ], \n                                    y = y[x &gt;= values$z ]),\n                  aes(x = x, y = y), fill = \"blue\", alpha = 0.3) +\n        geom_area(data = data.frame(x = x[x &lt;= -values$z  ], \n                                    y = y[x &lt;= -values$z ]),\n                  aes(x = x, y = y), fill = \"blue\", alpha = 0.3)+ \n        geom_vline(xintercept = values$z, color = \"red\") +\n        geom_vline(xintercept = -values$z, color = \"red\") +\n        ggtitle(paste(\"z =\", round(values$z, 2), \" | P =\", round(values$p, 4))) +\n        theme_minimal()\n      if(values$z!=0){p = p+\n        annotate(\"text\", x = -values$z, y = - 0.02, \n                 label = paste(\"-z =\", round(-values$z, 2)), color = \"red\", vjust = -0.5, hjust = -.1)}\n      } else{\n        p &lt;- ggplot(data.frame(x, y), aes(x, y)) +\n          geom_line() +\n          geom_area(data = data.frame(x = x[x &lt;= values$z & x &gt;= -values$z ], \n                                      y = y[x &lt;= values$z &x &gt;= -values$z ]),\n                    aes(x = x, y = y), fill = \"blue\", alpha = 0.3) +\n          geom_vline(xintercept = values$z, color = \"red\") +\n          geom_vline(xintercept = -values$z, color = \"red\") +\n          ggtitle(paste(\"z =\", round(values$z, 2), \" | P =\", round(values$p, 4))) +\n          theme_minimal() \n        if(values$z!=0){p = p+\n          annotate(\"text\", x = -values$z, y = - 0.02, \n                   label = paste(\"-z =\", round(-values$z, 2)), color = \"red\", vjust = -0.5, hjust = -.1)}\n    }\n    \n    p + labs(x = \"Z\") +\n      annotate(\"text\", x = values$z, y = - 0.02, \n               label = paste(\"z =\", round(values$z, 2)), color = \"red\", vjust = -0.5,hjust = -.1)\n  })\n}\n\nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "posts/Inference_shiny/inference_shiny.html",
    "href": "posts/Inference_shiny/inference_shiny.html",
    "title": "Inference Visualization",
    "section": "",
    "text": "#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 1000\n \nlibrary(shiny)\nlibrary(ggplot2)\nlibrary(tidyverse)\n\n# Define UI\nui &lt;- fluidPage(\n  titlePanel(\"Inference Visualization\"),\n  \n  sidebarLayout(\n    sidebarPanel(\n      numericInput(\"xbar\", \"Sample Mean (x̄):\", value = 98.450),\n      numericInput(\"s\", \"Sample Standard Deviation (s):\", value = 0.62),\n      numericInput(\"n\", \"Sample Size (n):\", value = 43),\n      uiOutput(\"muSlider\"),  # Use uiOutput for dynamic slider\n      numericInput(\"alpha\", \"Significance Level (α):\", value = 0.05, min = 0.01, max = 0.25, step = 0.01),\n      selectInput(\"sides\", \"1- vs 2-sided\",choices = c(\"1-sided (upper)\",\"1-sided (lower)\",\"2-sided\"),selected = \"2-sided\"),\n      actionButton(\"ci\", \"Show/Hide Confidence Interval\")\n    ),\n    \n    mainPanel(\n      plotOutput(\"densityPlot\"),\n      textOutput(\"distance\"),\n      textOutput(\"distanceSE\"),\n      textOutput(\"pValueText\")\n    )\n  )\n)\n\n# Define server logic\nserver &lt;- function(input, output, session) {\n  \n  # Dynamically update the slider input for mu based on xbar, s, and n\n  output$muSlider &lt;- renderUI({\n    se &lt;- input$s / sqrt(input$n)\n    min_mu &lt;- round(input$xbar - 4 * se, digits = 2)\n    max_mu &lt;- round(input$xbar + 4 * se, digits = 2)\n    \n    sliderInput(\"mu\", \"Possible Mean Value (μ):\", min = min_mu, max = max_mu, value = input$xbar - se, step = 0.01)\n  })\n  \n  showCI &lt;- reactiveVal(FALSE)\n  \n  observeEvent(input$ci,{\n    showCI(input$ci %% 2 == 1 )\n  })\n  \n  output$densityPlot &lt;- renderPlot({\n    # Calculate standard error\n    se &lt;- input$s / sqrt(input$n)\n    \n    # Calculate the z statistic\n    z &lt;- (input$xbar - input$mu) / se\n    \n    # Calculate p-value\n    if(input$sides==\"2-sided\"){\n      p_value &lt;- 2 * (1 - pnorm(abs(z)))\n    } else if(input$sides==\"1-sided (upper)\"){ \n      p_value &lt;-  pnorm(z,lower.tail = F)} else{p_value &lt;-  pnorm(z)}\n    \n    # Define the color based on p-value and alpha\n    tail_color &lt;- ifelse(p_value &lt; input$alpha, \"red\", \"blue\")\n    \n    # Generate x values for the plot\n    x_values &lt;- seq(input$xbar - 5*se, input$xbar + 5*se, length.out = 1000)\n    if(input$sides==\"2-sided\"){\n      shade_vals1 = x_values[x_values&lt;=min(input$xbar, 2*input$mu-input$xbar)]\n    } else if(input$sides==\"1-sided (upper)\"){ \n      shade_vals1 = NA\n    } else{shade_vals1 = x_values[x_values&lt;=input$xbar]}\n    \n    if(input$sides==\"2-sided\"){\n      shade_vals2 = x_values[ x_values&gt;=max(input$xbar, 2*input$mu-input$xbar)]\n    } else if(input$sides==\"1-sided (upper)\"){ \n      shade_vals2 = x_values[x_values&gt;=input$xbar]\n    } else{shade_vals2 = NA}\n    # Calculate y values for the density function\n    y_values &lt;- dnorm(x_values, mean = input$mu, sd = se)\n    \n    # Generate the plot\n    p &lt;- ggplot(data.frame(x = x_values, y = y_values), aes(x = x)) +\n      geom_line(aes(y = y), color = \"darkgrey\", size = 0.6) +\n      \n      # Shade the left tail\n      geom_area(data = data.frame(x = x_values, y = y_values)%&gt;% filter( x %in% shade_vals1),\n                aes(x = x, y = y), fill = tail_color, alpha = 0.3) +\n      \n      # Shade the right tail\n      geom_area(data = data.frame(x = x_values, y = y_values)%&gt;% filter( x %in% shade_vals2),\n                aes(x = x, y = y), fill = tail_color, alpha = 0.3) +\n      geom_segment(aes(x = input$xbar, y = 0, xend = input$mu, yend = 0), color = \"black\", size = .75,\n                            arrow = grid::arrow(angle = 90, ends = \"both\", length = unit(.1, \"inches\"))) +\n      # Add vertical lines for xbar and mu\n      geom_vline(xintercept = input$xbar, linetype = \"dashed\", color = \"cornflowerblue\", size = 0.75) +\n      geom_vline(xintercept = input$mu, linetype = \"dashed\", color = \"darkorange2\", size = 0.75) +\n        # Add line segment to show the distance between xbar and mu\n      geom_segment(aes(x = input$xbar, y = 0, xend = input$mu, yend = 0), color = \"black\", size = .75,\n                       arrow = grid::arrow(angle = 90, ends = \"both\", length = unit(.1, \"inches\"))) +\n      # Add labels for xbar and mu\n      annotate(\"text\", x = input$xbar, y = -0.1, label = \"x̄\", color= \"cornflowerblue\", hjust = -0.2, size = 5) +\n      annotate(\"text\", x = input$mu, y = -0.1, label = \"μ\", color = \"darkorange2\",  hjust = 1.2, size = 5) +\n      labs(title = \"Normal Density with Selected Mean\",\n           x = \"Value\",\n           y = \"Density\") +\n      theme_minimal() + ylim(-max(y_values)/16, max(y_values))\n      \n    if(input$sides == \"2-sided\"){\n      # Add line segment to show the distance between xbar and mu\n       p &lt;- p + geom_segment(aes(x = 2*input$mu-input$xbar, y = 0, xend = input$mu, yend = 0), color = \"black\", \n                     size = .75, arrow = grid::arrow(angle = 90,ends = \"both\",length = unit(.1, \"inches\")) )\n    }\n    \n    \n    if(showCI()){\n      if(input$sides==\"2-sided\"){\n        p &lt;- p + \n          geom_segment(aes(x = input$xbar +qnorm(input$alpha/2)*se, y = -max(y_values)/16, xend = input$xbar -qnorm(input$alpha/2)*se, yend = -max(y_values)/16),lineend = \"square\", color = \"blue\", alpha = 0.3,\n                       size = .75 )\n      } else if(input$sides==\"1-sided (upper)\"){\n        p &lt;- p + \n          geom_segment(aes(x = input$xbar -qnorm(input$alpha,lower.tail = F)*se, y = -max(y_values)/16, xend = Inf, yend = -max(y_values)/16),lineend = \"square\", color = \"blue\", alpha = 0.3,\n                       size = .75 )\n      } else{\n        p &lt;- p + \n          geom_segment(aes(x = input$xbar + qnorm(input$alpha,lower.tail = F)*se, y = -max(y_values)/16, xend = -Inf, yend = -max(y_values)/16),lineend = \"square\", color = \"blue\", alpha = 0.3,\n                       size = .75 )\n      }\n    }\n    \n    print(p)\n  })\n  \n  output$distance &lt;- renderText({\n    paste0(\"Distance of x̄ from μ: \", round(abs(input$mu - input$xbar), 4))\n  })\n  \n  output$distanceSE &lt;- renderText({\n    paste0(\"Distance in standard errors: \", round(abs(input$mu - input$xbar)/(input$s/sqrt(input$n)), 4))\n  })\n  \n  output$pValueText &lt;- renderText({\n    # Calculate standard error\n    se &lt;- input$s / sqrt(input$n)\n    \n    # Calculate the z statistic\n    z &lt;- (input$xbar - input$mu) / se\n    \n    # Calculate p-value\n    if(input$sides==\"2-sided\"){\n      p_value &lt;- 2 * (1 - pnorm(abs(z)))\n    } else if(input$sides==\"1-sided (upper)\"){ \n      p_value &lt;-  pnorm(z,lower.tail = F)} else{p_value &lt;-  pnorm(z)}\n    \n    # Display p-value\n    paste0(\"Probability of getting x̄ this extreme : \", round(p_value, 4))\n  })\n}\n\n# Run the application \nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "posts/power_Shiny/power_shiny.html",
    "href": "posts/power_Shiny/power_shiny.html",
    "title": "Power and Sample Size",
    "section": "",
    "text": "#| standalone: true\n#| viewerHeight: 1000\n \nlibrary(shiny)\nlibrary(tidyverse)\n\n# Define UI for application that draws a histogram\nui &lt;- fluidPage(\n   \n   # Application title\n   titlePanel(\"Power and Sample Size\"),\n   \n   # Sidebar with a slider input for number of bins \n   sidebarLayout(\n      sidebarPanel(\n         sliderInput(\"n\",\n                     \"Sample Size (n):\",\n                     min = 1,\n                     max = 5000,\n                     value = 500),\n         sliderInput(\"sd\",\n                     HTML(\"Standard Deviation (&#x3C3;):\"),\n                     min = 1,\n                     max = 20,\n                     value = 10),\n  \n      sliderInput(\"diff\",\n                  HTML(\"True Difference (   &#x3BC&lt;sub&gt;A&lt;/sub&gt;- &#x3BC&lt;sub&gt;0&lt;/sub&gt;)\"),\n                  min = 0.1,\n                  max = 5,\n                  value = 2),\n      numericInput(\"alpha\",\n                   HTML(\"&#945; (type I error threshold)\") ,\n                   min = 0.01,\n                   max = 0.1,\n                   value = 0.05),\n      radioButtons(\"sides\", \"One vs. Two-Tailed\", \n                  choices = list(\"1-tailed\"  , \"2-tailed\" ), selected = \"2-tailed\"),\n      actionButton(\"rescale\",\"Rescale Plot\")),\n      \n      # Show a plot of the generated distribution\n      mainPanel(\n        tabsetPanel(type = \"tabs\",\n                    tabPanel(\"One-Sample\\nT-test\",\n                             plotOutput(\"distPlot1\"),\n                             textOutput(\"power1\"), \n                             textOutput(\"print1\")),\n         tabPanel(\"Two-Sample\\n Difference in Means\", plotOutput(\"distPlot\"),\n         textOutput(\"power\"), \n         textOutput(\"note\"),\n         textOutput(\"print\"))\n      ))\n   )\n)\n\nserver &lt;- function(input, output) {\n\n  rvmin &lt;- reactiveValues(lim = NULL)\n  rvmax &lt;- reactiveValues(lim = NULL)\n  l &lt;- reactiveValues(val = 0)\n\n  observeEvent(input$rescale, {\n    newmn = -5*sqrt(2*input$sd^2/input$n)\n    newmx =  input$diff + 5*sqrt(2*input$sd^2/input$n)\n    rvmin$lim &lt;- c(rvmin$lim,newmn)\n    rvmax$lim &lt;- c(rvmax$lim,newmx)\n    l$val = l$val+1\n  })\n  \n  \n\n   output$distPlot &lt;- renderPlot({\n     mn &lt;- ifelse(l$val&lt;1, -5*sqrt(2*10^2/500), rvmin$lim[l$val] )\n     mx &lt;- ifelse(l$val&lt;1, 2 + 5*sqrt(2*10^2/500), rvmax$lim[l$val] )\n\n      if(input$sides == \"2-tailed\"){\n      ct = sqrt(input$sd^2/input$n)*qnorm(1-(input$alpha/2))\n      ctl = -sqrt(input$sd^2/input$n)*qnorm(1-(input$alpha/2))}\n      \n      if(input$sides ==\"1-tailed\"){\n        ct = sqrt(input$sd^2/input$n)*qnorm(1-(input$alpha))\n        ctl =-Inf\n      }\n      \n        funcShaded &lt;- function(x,ct,ctl) {\n          y &lt;- dnorm(x, mean = input$diff, sd = sqrt(input$sd^2/input$n))\n          y[x &lt; ct] &lt;- NA\n          return(y)\n        }\n        funcShadedRej &lt;- function(x,ct,ctl) {\n          y &lt;- dnorm(x, mean = 0, sd = sqrt(input$sd^2/input$n))\n          y[x &lt; ct & x&gt;ctl] &lt;- NA\n          return(y)\n        }\n      \n     p1 &lt;- ggplot(data.frame(x =c(seq(mn,mx,by=0.00001),ct,ctl)), \n                    aes(x = x))+\n        stat_function(fun = dnorm, args = list(mean = 0, sd = sqrt(input$sd^2/input$n)),\n                      aes(color = \"Null\"))+\n        stat_function(fun = dnorm, args = list(mean = input$diff, sd = sqrt(input$sd^2/input$n)),\n                      aes(color =  \"Alternative\"))+\n        theme_bw()+\n        labs(color = \"Hypothesis\")+\n        geom_vline(xintercept = ct, linetype = 2, linewidth = 0.8, color = \"darkcyan\")+\n        xlab(expression(mu[A]-mu[0]))+\n        labs( y = \"Density\", fill = element_blank())+\n        stat_function(fun=funcShaded, geom=\"area\", aes(fill = \"Power\"), alpha=0.5,args = list(ct=ct,ctl=ctl))+\n       stat_function(fun=funcShadedRej, geom=\"area\", aes(fill = \"Rejection Region\"), alpha=0.25,args = list(ct=ct,ctl=ctl))+\n       theme(legend.text = element_text(size = 10))\n\n     if(input$sides == \"2-tailed\"){\n       p1 &lt;- p1+ geom_vline(xintercept = ctl, linetype = 2,  linewidth =0.8,color = \"darkcyan\")\n     }\n     p1\n\n   })\n   \n\n\n   \n   output$power &lt;- renderText({\n     if(input$sides == \"2-tailed\"){\n     power = power.t.test(n=input$n, delta=input$diff, sd=input$sd, sig.leve=input$alpha, power=NULL, \n                          type=\"two.sample\", alternative=\"two.sided\")$power%&gt;%round(digits = 4)}\n     if(input$sides == \"1-tailed\"){\n       power = power.t.test(n=input$n, delta=input$diff, sd=input$sd, sig.leve=input$alpha, power=NULL, \n                            type=\"two.sample\", alternative=\"one.sided\")$power%&gt;%round(digits = 4)}\n     \n     paste(\"Power: \", power, collapse = \"\")\n     \n   })\n   \n   output$note&lt;-renderText( \"Note: Here we assume equal sample size and equal standard deviation in both groups.\")\n   \n   output$distPlot1 &lt;- renderPlot({\n     mn &lt;- ifelse(l$val&lt;1, -5*sqrt(10^2/500), rvmin$lim[l$val] )\n     mx &lt;- ifelse(l$val&lt;1, 2 + 5*sqrt(10^2/500), rvmax$lim[l$val] )\n     \n     if(input$sides == \"2-tailed\"){\n       ct = sqrt(input$sd^2/input$n)*qnorm(1-(input$alpha/2))\n       ctl = -sqrt(input$sd^2/input$n)*qnorm(1-(input$alpha/2))}\n     \n     if(input$sides ==\"1-tailed\"){\n       ct = sqrt(input$sd^2/input$n)*qnorm(1-(input$alpha))\n       ctl =-Inf\n     }\n     \n     funcShaded &lt;- function(x,ct,ctl) {\n       y &lt;- dnorm(x, mean = input$diff, sd = sqrt(input$sd^2/input$n))\n       y[x &lt; ct] &lt;- NA\n       return(y)\n     }\n     funcShadedRej &lt;- function(x,ct,ctl) {\n       y &lt;- dnorm(x, mean = 0, sd = sqrt(input$sd^2/input$n))\n       y[x &lt; ct & x&gt;ctl] &lt;- NA\n       return(y)\n     }\n     \n     p2 &lt;- ggplot(data.frame(x = rep(seq(mn,mx,by=0.00001))), \n                  aes(x = x))+\n       stat_function(fun = dnorm, args = list(mean = 0, sd = sqrt(input$sd^2/input$n)),\n                     aes(color = \"Null\"))+\n       stat_function(fun = dnorm, args = list(mean = input$diff, sd = sqrt(input$sd^2/input$n)),\n                     aes(color =  \"Alternative\"))+\n       theme_bw()+\n       labs(color = \"Hypothesis\")+\n       geom_vline(xintercept = ct, linetype = 2, size = 0.8, color = \"darkcyan\")+\n       xlab(expression(mu[A]-mu[0]))+\n       labs( y = \"Density\", fill = element_blank())+\n       stat_function(fun=funcShaded, geom=\"area\", aes(fill = \"Power\"), alpha=0.5,args = list(ct=ct,ctl=ctl))+\n       stat_function(fun=funcShadedRej, geom=\"area\", aes(fill = \"Rejection Region\"), alpha=0.25,args = list(ct=ct,ctl=ctl))+\n       theme(legend.text = element_text(size = 10))\n     \n     if(input$sides == \"2-tailed\"){\n       p2 &lt;- p2 + geom_vline(xintercept = ctl, linetype = 2, size = 0.8,color = \"darkcyan\")\n     }\n     p2\n     \n   })\n   \n   \n   \n   \n   output$power1 &lt;- renderText({\n     if(input$sides == \"2-tailed\"){\n       power = power.t.test(n=input$n, delta=input$diff, sd=input$sd, sig.leve=input$alpha, power=NULL, \n                            type=\"one.sample\", alternative=\"two.sided\")$power%&gt;%round(digits = 4)}\n     if(input$sides == \"1-tailed\"){\n       power = power.t.test(n=input$n, delta=input$diff, sd=input$sd, sig.leve=input$alpha, power=NULL, \n                            type=\"one.sample\", alternative=\"one.sided\")$power%&gt;%round(digits = 4)}\n     \n     paste(\"Power: \", power, collapse = \"\")\n\n   })\n}\n\n# Run the application \nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "posts/T-test_shiny/ttest_shiny.html",
    "href": "posts/T-test_shiny/ttest_shiny.html",
    "title": "T Test Visualization",
    "section": "",
    "text": "#| standalone: true\n#| viewerHeight: 800\nlibrary(shiny)\nlibrary(ggplot2)\nlibrary(extraDistr)\nlibrary(bslib)\nlibrary(bsicons)\n\nui &lt;- page_sidebar(\n  theme = bs_theme(bootswatch = \"materia\"),\n  titlePanel(\"T-test Visualization\"),\n  sidebar = sidebar(\n    numericInput(\"n\", \"Sample size (n):\", value = 30, min = 2),\n    numericInput(\"mu0\", HTML(\"Null hypothesis mean (&mu;&lt;sub&gt;0&lt;/sub&gt;):\"), value = 0),\n    numericInput(\"mu_true\", HTML(\"True mean (&mu;&lt;sub&gt;true&lt;/sub&gt;):\"), value = 0), # True mean input\n    numericInput(\"sigma\", \"Population standard deviation (σ):\", value = 1),\n    numericInput(\"alpha\", \"Significance level (α):\", value = 0.05),\n    radioButtons(\"test_type\", \"Test Type:\", choices = list(\"One-sided (left)\" = \"one left\",\"One-sided (right)\" = \"one right\", \"Two-sided\" = \"two\"),\n                 selected = \"two\"),\n    actionButton(\"toggleAltPlot\", \"Show/Hide Alternative Distribution\"),  # Button to toggle alternative plot\n    actionButton(\"toggleCI\", \"Show/Hide C.I. & Rejection Region\")  # Button to toggle CI and rejection region\n    \n  )\n  ,    actionButton(\"draw\", \"Draw Sample\"),\n  \n  card(\n    card_header(\"Sample\"),\n    height = \"550px\",\n    fluidRow(\n      column(6,\n             style = \"justify-content: center; align-items: center\",  # Center vertically and control height\n             uiOutput(\"sample_stats\")  # Summary stats on the left\n      ), \n      column(6, \n             plotOutput(\"samplePlot\", height = \"175px\")  # Sample plot on the right, fixed height\n      )\n    )\n    \n  ),\n  \n  card(card_header(\"Sample Mean\"), plotOutput(\"meanDensityPlot\", height = \"500px\") ), # New density plot for sample mean\n  card( \n    card_header(\"Test Statistic\"),\n    plotOutput(\"densityPlot\", height = \"500px\")),  # Larger density plot below\n  card(card_header(\"Power\"),\n       height = \"250px\",\n       card_body(\n       textOutput(\"power\")))\n  \n)\n\nserver &lt;- function(input, output, session) {\n  # Reactive values to track the sample, alternative plot visibility, and plot data\n  sample_data &lt;- reactiveVal(NULL)\n  plot_data &lt;- reactiveValues(\n    t_stat = NULL,\n    sample_mean = NULL,\n    sample_sd = NULL,\n    x_limits_null = NULL,\n    mean_x_limits = NULL\n  )\n  showAlt &lt;- reactiveVal(FALSE)\n  \n  observeEvent(input$toggleAltPlot, {\n    showAlt(!showAlt())\n  })\n  \n  showCI &lt;- reactiveVal(FALSE)\n  \n  observeEvent(input$toggleCI, {\n    showCI(!showCI())  # Toggle CI and rejection region visibility\n  })\n  \n  \n  observeEvent(input$draw, {\n    # Create a bimodal sample using the true mean (µ_true)\n    n1 &lt;- floor(input$n / 2)\n    n2 &lt;- input$n - n1\n    sample1 &lt;- rnorm(n1, mean = input$mu_true - 0.5, sd = (4 * input$sigma - 1) / 4)  # First mode\n    sample2 &lt;- rnorm(n2, mean = input$mu_true + 0.5, sd = (4 * input$sigma - 1) / 4)  # Second mode\n    sample &lt;- c(sample1, sample2)\n    \n    sample_data(sample)  # Store sample data\n    \n    # Store plot-specific values in reactiveValues\n    plot_data$sample_mean &lt;- mean(sample)\n    plot_data$sample_sd &lt;- sd(sample)\n    plot_data$t_stat &lt;- (plot_data$sample_mean - input$mu0) / (plot_data$sample_sd / sqrt(input$n))  # t-statistic\n    \n    # Dynamically set x-axis limits for density plots, based on current input values\n    plot_data$x_limits_null &lt;- c(\n      qt(0.0001, df = input$n - 1),\n      qt(0.9999, df = input$n - 1) + (input$mu_true - input$mu0) / (plot_data$sample_sd / sqrt(input$n))\n    )\n    plot_data$mean_x_limits &lt;- c(\n      qnorm(0.0001, mean = input$mu0, sd = (input$sigma / sqrt(input$n))),\n      qnorm(0.9999, mean = input$mu_true, sd = (input$sigma / sqrt(input$n)))\n    )\n    \n    # Render the summary statistics in the left panel\n    output$sample_stats &lt;- renderUI({\n      summary_stats &lt;- data.frame(\n        Statistic = c(\"Sample Mean\", \"Sample Standard Deviation\", \"Estimated Standard Error\", \"T-test Statistic\"),\n        Value = c(\n          round(plot_data$sample_mean, 3),\n          round(plot_data$sample_sd, 3),\n          round(plot_data$sample_sd / sqrt(input$n), 3),\n          paste0(\"&lt;span style='color:springgreen4;'&gt;\", round(plot_data$t_stat, 3), \"&lt;/span&gt;\")\n        ),\n        stringsAsFactors = FALSE\n      )\n      \n      HTML(\n        paste0(\"&lt;table style='border-collapse: collapse; width: 100%;font-size: 16px;'&gt;\",\n               \"&lt;tr&gt;&lt;th style='text-align: center; border: 1px solid black;'&gt;Statistic&lt;/th&gt;\",\n               \"&lt;th style='text-align: center; border: 1px solid black;'&gt;Value&lt;/th&gt;&lt;/tr&gt;\",\n               paste0(\"&lt;tr&gt;&lt;td style='text-align: center; border: 1px solid black;'&gt;\", summary_stats$Statistic, \"&lt;/td&gt;\",\n                      \"&lt;td style='text-align: center;border: 1px solid black;'&gt;\", summary_stats$Value, \"&lt;/td&gt;&lt;/tr&gt;\",\n                      collapse = \"\"), \n               \"&lt;/table&gt;\")\n      )\n    })\n    \n    # Plot for the t-test statistic distribution\n    output$densityPlot &lt;- renderPlot({\n      # Base plot for the null hypothesis density\n      p &lt;- ggplot(data.frame(x = plot_data$x_limits_null), aes(x)) +\n        stat_function(fun = dt, args = list(df = input$n - 1), color = \"firebrick2\") +\n        geom_vline(xintercept = plot_data$t_stat, color = \"springgreen4\", linetype = \"dashed\") +\n        geom_text(aes(x = plot_data$t_stat, label = paste(\"T =\", round(plot_data$t_stat, 2)), y = Inf), \n                  color = \"springgreen4\", angle = 90, vjust = 0, hjust = 1, size = 4.5) +\n        labs(title = \"Test Statistic Distribution under Null Hypothesis\", \n             x = \"T statistic\", y = \"Density\") + theme_classic()\n      \n      # Add alternative distribution if showAlt is TRUE\n      if (showAlt()) {\n        p &lt;- p + stat_function(fun = dlst, args = list(mu = input$mu_true/(plot_data$sample_sd/sqrt(input$n)), df = input$n-1), \n                               color = \"lightblue\", alpha = 0.7) + \n          labs(title = \"Test Statistic Distribution: Null vs Alternative\")\n        \n        \n      }\n      \n      # Show rejection region if the toggle is on\n      if (showCI()) {\n        alpha &lt;- input$alpha\n        test_type &lt;- input$test_type\n        \n        if (test_type == \"two\") {\n          # Calculate critical t-values for two-sided test\n          critical_value_low &lt;- qt(alpha / 2, df = input$n - 1)\n          critical_value_high &lt;- qt(1 - alpha / 2, df = input$n - 1)\n          # Add shaded rejection regions using geom_rect\n          p &lt;- p + geom_rect(aes(xmin = -Inf, xmax = critical_value_low, ymin = 0, ymax = Inf), \n                             fill = \"red\", alpha = 0.05) + \n            geom_rect(aes(xmin = critical_value_high, xmax = Inf, ymin = 0, ymax = Inf), \n                      fill = \"red\", alpha = 0.05) \n        } else if (test_type == \"one left\") {\n          critical_value_high &lt;- qt(1-alpha, df = input$n - 1)\n          p &lt;- p + geom_rect(aes(xmin = -Inf, xmax = critical_value_high, ymin = 0, ymax = Inf), \n                             fill = \"red\", alpha = 0.05)\n          \n        } else {\n          \n          # One-sided test\n          critical_value_low &lt;- qt(1-alpha, df = input$n - 1)\n          \n          # Add a shaded rejection region for one-sided test\n          p &lt;- p + geom_rect(aes(xmin = critical_value_low, xmax = Inf, ymin = 0, ymax = Inf), \n                             fill = \"red\", alpha = 0.05)\n        } }\n      p\n    })\n    \n    # Plot for the sample histogram\n    output$samplePlot &lt;- renderPlot({\n      ggplot(data.frame(sample = sample_data()), aes(x = sample)) + \n        geom_histogram(bins = 10, fill = \"lightblue\", color = \"black\") + \n        labs(title = paste0(\"Sample (µ = \", input$mu_true,\")\"),  \n             x = \"Sample Values\", y = \"Frequency\") + theme_classic()\n    })\n    \n    # Plot for the expected sample mean distribution\n    output$meanDensityPlot &lt;- renderPlot({\n      # Set appropriate limits for the expected sample mean density plot\n      mean_x_limits &lt;- c(qnorm(0.0001, mean = input$mu0, sd = (input$sigma / sqrt(input$n))),\n                         qnorm(0.9999, mean = input$mu_true, sd = (input$sigma / sqrt(input$n))))\n      \n      se &lt;- plot_data$sample_sd / sqrt(input$n)\n      alpha &lt;- input$alpha\n      test_type &lt;- input$test_type\n      \n      if (test_type == \"one left\") {\n        ci_high&lt;- plot_data$sample_mean + qt(1-alpha, df = input$n-1)*se\n        ci_low &lt;- -Inf  # For one-sided, CI extends to infinity on the right side\n      } else if (test_type == \"one right\"){\n        ci_low &lt;- plot_data$sample_mean - qt(1-alpha, df = input$n-1)*se\n        ci_high &lt;- Inf  # For one-sided, CI extends to infinity on the right side\n      } else {\n        ci_low &lt;- plot_data$sample_mean - qt(1-alpha/2, df = input$n-1)*se\n        ci_high &lt;- plot_data$sample_mean + qt(1-alpha/2, df = input$n-1)*se\n      }\n      \n      p &lt;- ggplot(data.frame(x = plot_data$mean_x_limits), aes(x)) + \n        stat_function(fun = dnorm, args = list(mean = input$mu0, sd = input$sigma / sqrt(input$n)), color = \"firebrick2\") + \n        geom_vline(xintercept = plot_data$sample_mean, color = \"orange3\", linetype = \"dashed\") + \n        geom_text(aes(x = plot_data$sample_mean, label = paste(\"X̄ =\", round(plot_data$sample_mean, 2)), y = Inf), \n                  color = \"orange3\", angle = 90, vjust = 0, hjust = 1, size = 4.5) +\n        \n        labs(title = \"Distribution of Sample Mean\",\n             x = \"Sample Mean (X̄)\", y = \"Density\") + theme_classic()\n      \n      # Show confidence interval if the toggle is on\n      if (showCI()) {\n        p &lt;- p + geom_segment(aes(x = ci_low, xend = ci_high, y = 0, yend = 0), \n                              color = \"purple\", size = 2) + \n          geom_rect(aes(xmin = ci_low, xmax = ci_high, ymin = 0, ymax = Inf), \n                    fill = \"purple\", alpha = 0.05) +\n          geom_vline(aes(xintercept = input$mu0), color = \"firebrick1\", linetype = 2)\n        \n      }\n      \n      # Add alternative distribution if showAlt is TRUE\n      if (showAlt()) {\n        p &lt;- p + stat_function(fun = dnorm, args = list(mean = input$mu_true, sd = input$sigma / sqrt(input$n)), \n                               color = \"lightblue\", alpha = 0.7) + \n          labs(title = \"Sample Mean: Null vs Alternative\")\n        \n        \n      }\n      \n      \n      p  # Return the plot\n    })\n    \n    \n  })\n  \n  calc_power &lt;- reactive({\n    if(input$mu0 == input$mu_true) {\n      return(\"Power is not well-defined under the null hypothesis\")\n    } else {\n      # Map test type to appropriate alternative hypothesis for power.t.test()\n      sides &lt;- switch(input$test_type,\n                      \"two\" = \"two.sided\",\n                      \"one left\" = \"one.sided\",\n                      \"one right\" = \"one.sided\")\n      \n      # Calculate power\n      pwr &lt;- power.t.test(delta = abs(input$mu_true - input$mu0), \n                          n = input$n, \n                          sd = input$sigma, \n                          sig.level = input$alpha, \n                          type = \"one.sample\", \n                          alternative = sides)$power\n      \n      # Return power value as a string\n      return(paste0(\"Power: \", round(pwr, digits = 4)))\n    }\n  })\n  \n  # Output power as text\n  output$power &lt;- renderText({\n    calc_power()  # Use the reactive expression to get the power\n  })\n  \n  # Trigger power calculation on app startup (using an observer)\n  observe({\n    output$power &lt;- renderText({\n      calc_power()\n    })\n  })\n  \n  \n}\n\n\n\nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "posts/ANOVA_Shiny/ANOVA_shiny.html",
    "href": "posts/ANOVA_Shiny/ANOVA_shiny.html",
    "title": "ANOVA",
    "section": "",
    "text": "#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 600\n#| \nlibrary(shiny)\nlibrary(ggplot2)\n\nui &lt;- fluidPage(\n  titlePanel(\"ANOVA Simulation\"),\n  \n  sidebarLayout(\n    sidebarPanel(\n      numericInput(\"n_groups\", \"Number of Groups\", value = 4, min = 2),\n      uiOutput(\"group_mean_sliders\"),\n      numericInput(\"n_per_group\", \"Sample Size per Group\", value = 30, min = 5),\n      numericInput(\"within_var\", \"Within Group Variability (SD)\", value = 5, min = 1),\n      actionButton(\"draw_sample\", \"Draw Sample\"),\n      radioButtons(\"plot_type\", \"Select Plot Type:\",\n                   choices = c(\"Density Plots\" = \"density\", \"Boxplots\" = \"boxplot\"),\n                   selected = \"boxplot\")\n    ),\n    \n    mainPanel(\n      plotOutput(\"combined_plot\"),\n      textOutput(\"anova_result\"),\n      plotOutput(\"f_dist_plot\")\n    )\n  )\n)\n\nserver &lt;- function(input, output, session) {\n  \n  # Dynamically generate sliders for group means based on number of groups\n  output$group_mean_sliders &lt;- renderUI({\n    lapply(1:input$n_groups, function(i) {\n      sliderInput(paste0(\"mean_\", i), paste0(\"Mean for Group \", i), \n                  min = -10, max = 10, value = 2, step = 0.1)\n    })\n  })\n  \n  # Population data sampling large size (e.g., 10,000 per group)\n  pop_data &lt;- reactive({\n    means &lt;- sapply(1:input$n_groups, function(i) input[[paste0(\"mean_\", i)]])\n    group &lt;- rep(1:input$n_groups, each = 10000)\n    values &lt;- unlist(lapply(1:input$n_groups, function(i) {\n      rnorm(10000, mean = means[i], sd = input$within_var)\n    }))\n    data.frame(group = as.factor(group), values = values)\n  })\n  \n  # Reactive for sample data\n  sample_data &lt;- eventReactive(input$draw_sample, {\n    means &lt;- sapply(1:input$n_groups, function(i) input[[paste0(\"mean_\", i)]])\n    group &lt;- rep(1:input$n_groups, each = input$n_per_group)\n    values &lt;- unlist(lapply(1:input$n_groups, function(i) {\n      rnorm(input$n_per_group, mean = means[i], sd = input$within_var)\n    }))\n    data.frame(group = as.factor(group), values = values)\n  })\n  \n  # Combined plot for population and sample distributions\n  output$combined_plot &lt;- renderPlot({\n    \n    if (input$plot_type == \"density\") {\n    p &lt;- ggplot(pop_data(), aes(x = values, fill = group)) +\n      geom_density(alpha = 0.4) +\n      facet_wrap(~ group, ncol = 1) +\n      labs(title = \"Population Distributions\", y = \"Density\", x = \"Values\") +\n      theme_minimal() +\n      theme(legend.position = \"none\")\n    } else{\n      p &lt;- ggplot(pop_data(), aes(y = values, x=group, color = group)) +\n        geom_boxplot(alpha = 0.4) +\n        labs(title = \"Population Distributions\", y = \"Values\", x = \"Group\") +\n        theme_minimal() +\n        theme(legend.position = \"none\")\n    }\n    \n    if (input$draw_sample &gt; 0) {\n      req(sample_data())\n      if (input$plot_type == \"density\") {\n        p &lt;- p +\n          geom_histogram(data = sample_data(), aes(x = values, fill = group, y = ..density..), \n                         color = \"black\", alpha = 0.6, position = \"identity\", bins = 30)  +\n          geom_vline(aes(xintercept = mean(values)), data = sample_data(), \n                    linetype = \"dashed\", color = \"blue\", size = 1) +\n          labs(subtitle = \"+ Sample Distributions\")\n      } else {\n        p &lt;- p +\n          geom_boxplot(data = sample_data(), aes(x = group, y = values, fill = group), color = \"black\", \n                       alpha = 0.7, position = position_dodge(width = 0.8))+\n          geom_hline(aes(yintercept = mean(values)), data = sample_data(), \n                     linetype = \"dashed\", color = \"blue\", size = 1) +\n          labs(subtitle = \"+ Sample Distributions\")\n      }\n    }\n    \n    print(p)\n  })\n  \n  # Perform ANOVA and display F statistic\n  output$anova_result &lt;- renderText({\n    req(sample_data())\n    fit &lt;- aov(values ~ group, data = sample_data())\n    anova_res &lt;- summary(fit)\n    f_stat &lt;- anova_res[[1]]$`F value`[1]\n    p_value &lt;- anova_res[[1]]$`Pr(&gt;F)`[1]\n    paste(\"ANOVA F-statistic:\", round(f_stat, 3), \"with p-value:\", round(p_value, 3))\n  })\n  \n  # Plot F distribution with shaded p-value\n  output$f_dist_plot &lt;- renderPlot({\n    req(sample_data())\n    fit &lt;- aov(values ~ group, data = sample_data())\n    f_stat &lt;- summary(fit)[[1]]$`F value`[1]\n    df1 &lt;- input$n_groups - 1\n    df2 &lt;- input$n_groups * (input$n_per_group - 1)\n    \n    x &lt;- seq(0, max(10, f_stat + 1), length.out = 500)\n    f_dist &lt;- df(x, df1, df2)\n    \n    ggplot(data.frame(x = x, y = f_dist), aes(x = x, y = y)) +\n      geom_line() +\n      geom_area(data = data.frame(x = x[x &gt;= f_stat], y = f_dist[x &gt;= f_stat]), \n                aes(x = x, y = y), fill = \"red\", alpha = 0.5) +\n      geom_vline(xintercept = f_stat, linetype = \"dashed\", color = \"forestgreen\") +\n      labs(title = \"F Distribution\", x = \"F value\", y = \"Density\") +\n      annotate(\"text\", x = f_stat + 0.3, y = max(f_dist)/2, \n               label = paste(\"F =\", round(f_stat, 3)), color = \"forestgreen\") +\n      theme_bw()\n  })\n}\n\nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "posts/Proportions-shiny/Proportions_shiny.html",
    "href": "posts/Proportions-shiny/Proportions_shiny.html",
    "title": "Inference For Proportions",
    "section": "",
    "text": "#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 1000\n \nlibrary(shiny)\nlibrary(ggplot2)\nlibrary(tidyverse)\n\n# Define UI\nui &lt;- fluidPage(\n  titlePanel(\"Inference for Proportions\"),\n  \n  tabsetPanel(\n    tabPanel(\"Normal Approximation\",\n  sidebarLayout(\n    sidebarPanel(\n      uiOutput(\"phatSlider1\"),\n      numericInput(\"n\", \"Sample Size (n):\", value = 50),\n      sliderInput(\"p\", \"True Proportion (p):\", min = 0, max = 1, value = 0.5, step = 0.01),\n      numericInput(\"alpha\", \"Significance Level (α):\", value = 0.05, min = 0.001, max = 0.25, step = 0.01),\n      selectInput(\"sides\", \"1- vs 2-sided\",choices = c(\"1-sided (upper)\",\"1-sided (lower)\",\"2-sided\"),selected = \"2-sided\"),\n      actionButton(\"ci\", \"Show/Hide Confidence Interval\")\n    ),\n    \n    mainPanel(\n      plotOutput(\"densityPlot\"),\n      textOutput(\"distance\"),\n      textOutput(\"distanceSE\"),\n      textOutput(\"pValueText\")\n    )\n  )),\n  tabPanel(\"Exact Binomial\",\n           sidebarLayout(\n             sidebarPanel(\n               uiOutput(\"phatSlider2\"),\n               numericInput(\"n2\", \"Sample Size (n):\", value = 50),\n               sliderInput(\"p2\", \"True Proportion (p):\", min = 0, max = 1, value = 0.5, step = 0.01),\n               numericInput(\"alpha2\", \"Significance Level (α):\", value = 0.05, min = 0.001, max = 0.25, step = 0.01),\n               selectInput(\"sides2\", \"1- vs 2-sided\",choices = c(\"1-sided (upper)\",\"1-sided (lower)\",\"2-sided\"),selected = \"2-sided\"),\n               actionButton(\"ci2\", \"Show/Hide Confidence Interval\")\n             ),\n             \n             mainPanel(\n               plotOutput(\"binomPlot\"),\n               textOutput(\"pValueText_binom\")\n             )\n           )))\n  \n)\n\n# Define server logic\nserver &lt;- function(input, output, session) {\n  output$phatSlider1 &lt;- renderUI({\n    sliderInput(\"phat\", \"Sample Proportion (p̂):\", min = 0, max =1, value =round(input$n/4)/input$n, step = 1/input$n)\n  })\n  output$phatSlider2 &lt;- renderUI({\n    sliderInput(\"phat2\", \"Sample Proportion (p̂):\", min = 0, max =1, value =round(input$n2/4)/input$n2, step = 1/input$n2)\n  })\n  \n  showCI &lt;- reactiveVal(FALSE)\n  \n  observeEvent(input$ci,{\n    showCI(input$ci %% 2 == 1 )\n  })\n    showCI2 &lt;- reactiveVal(FALSE)\n  \n  observeEvent(input$ci2,{\n    showCI(input$ci2 %% 2 == 1 )\n  })\n  \n  output$densityPlot &lt;- renderPlot({\n    # Calculate standard error\n    se_est &lt;- sqrt(input$phat*(1-input$phat)/input$n)\n    se_true &lt;-  sqrt(input$p*(1-input$p)/input$n)\n    \n    # Calculate the z statistic\n    z &lt;- (input$phat - input$p) / se_true\n    \n    # Calculate p-value\n    if(input$sides==\"2-sided\"){\n      p_value &lt;- 2 * (1 - pnorm(abs(z)))\n    } else if(input$sides==\"1-sided (upper)\"){ \n      p_value &lt;-  pnorm(z,lower.tail = F)} else{p_value &lt;-  pnorm(z)}\n    \n    # Define the color based on p-value and alpha\n    tail_color &lt;- ifelse(p_value &lt; input$alpha, \"red\", \"blue\")\n    \n    # Generate x values for the plot\n    x_values &lt;- seq(-0.1, 1.1, length.out = 1000)\n    if(input$sides==\"2-sided\"){\n      shade_vals1 = x_values[x_values&lt;=min(input$phat, 2*input$p-input$phat)]\n    } else if(input$sides==\"1-sided (upper)\"){ \n      shade_vals1 = NA\n    } else{shade_vals1 = x_values[x_values&lt;=input$phat]}\n    \n    if(input$sides==\"2-sided\"){\n      shade_vals2 = x_values[ x_values&gt;=max(input$phat, 2*input$p-input$phat)]\n    } else if(input$sides==\"1-sided (upper)\"){ \n      shade_vals2 = x_values[x_values&gt;=input$phat]\n    } else{shade_vals2 = NA}\n    # Calculate y values for the density function\n    y_values &lt;- dnorm(x_values, mean = input$p, sd = se_true)\n    \n    # Generate the plot\n    p &lt;- ggplot(data.frame(x = x_values, y = y_values), aes(x = x)) +\n      geom_line(aes(y = y), color = \"darkgrey\", size = 0.6) +\n      \n      # Shade the left tail\n      geom_area(data = data.frame(x = x_values, y = y_values)%&gt;% filter( x %in% shade_vals1),\n                aes(x = x, y = y), fill = tail_color, alpha = 0.3) +\n      \n      # Shade the right tail\n      geom_area(data = data.frame(x = x_values, y = y_values)%&gt;% filter( x %in% shade_vals2),\n                aes(x = x, y = y), fill = tail_color, alpha = 0.3) +\n      geom_segment(aes(x = input$phat, y = 0, xend = input$p, yend = 0), color = \"black\", size = .75,\n                   arrow = grid::arrow(angle = 90, ends = \"both\", length = unit(.1, \"inches\"))) +\n      # Add vertical lines for xbar and mu\n      geom_vline(xintercept = input$phat, linetype = \"dashed\", color = \"cornflowerblue\", size = 0.75) +\n      geom_vline(xintercept = input$p, linetype = \"dashed\", color = \"darkorange2\", size = 0.75) +\n      # Add line segment to show the distance between xbar and mu\n      geom_segment(aes(x = input$phat, y = 0, xend = input$p, yend = 0), color = \"black\", size = .75,\n                   arrow = grid::arrow(angle = 90, ends = \"both\", length = unit(.1, \"inches\"))) +\n      # Add labels for xbar and mu\n      annotate(\"text\", x = input$phat, y = -0.1, label = \"p̂\", color= \"cornflowerblue\", hjust = -0.2, size = 5) +\n      annotate(\"text\", x = input$p, y = -0.1, label = \"p\", color = \"darkorange2\",  hjust = 1.2, size = 5) +\n      labs(title = \"Normal Density with Selected Proportion\",\n           x = \"Value\",\n           y = \"Density\") +\n      theme_minimal() + ylim(-max(y_values)/16, max(y_values))\n    \n    if(input$sides == \"2-sided\"){\n      # Add line segment to show the distance between xbar and mu\n      p &lt;- p + geom_segment(aes(x = 2*input$p-input$phat, y = 0, xend = input$p, yend = 0), color = \"black\", \n                            size = .75, arrow = grid::arrow(angle = 90,ends = \"both\",length = unit(.1, \"inches\")) )\n    }\n    \n    \n    if(showCI()){\n      if(input$sides==\"2-sided\"){\n        p &lt;- p + \n          geom_segment(aes(x = input$phat +qnorm(input$alpha/2)*se_est, y = -max(y_values)/16, xend = input$phat -qnorm(input$alpha/2)*se_true, yend = -max(y_values)/16),lineend = \"square\", color = \"purple\", alpha = 0.3,\n                       size = .75 )\n      } else if(input$sides==\"1-sided (upper)\"){\n        p &lt;- p + \n          geom_segment(aes(x = input$phat -qnorm(input$alpha,lower.tail = F)*se_est, y = -max(y_values)/16, xend = Inf, yend = -max(y_values)/16),lineend = \"square\", color = \"purple\", alpha = 0.3,\n                       size = .75 )\n      } else{\n        p &lt;- p + \n          geom_segment(aes(x = input$phat + qnorm(input$alpha,lower.tail = F)*se_est, y = -max(y_values)/16, xend = -Inf, yend = -max(y_values)/16),lineend = \"square\", color = \"purple\", alpha = 0.3,\n                       size = .75 )\n      }\n    }\n    \n    print(p)\n  })\n  \n  output$distance &lt;- renderText({\n    paste0(\"Distance of p̂ from μ: \", round(abs(input$p - input$phat), 4))\n  })\n  \n  output$distanceSE &lt;- renderText({\n    paste0(\"Distance in standard errors: \", round(abs(input$p - input$phat)/(sqrt(input$p*(1-input$p)/sqrt(input$n))), 4))\n  })\n  \n  output$pValueText &lt;- renderText({\n    # Calculate standard error\n    se &lt;- sqrt(input$p*(1-input$p)/sqrt(input$n))\n    \n    # Calculate the z statistic\n    z &lt;- (input$phat - input$p) / se\n    \n    # Calculate p-value\n    if(input$sides==\"2-sided\"){\n      p_value &lt;- 2 * (1 - pnorm(abs(z)))\n    } else if(input$sides==\"1-sided (upper)\"){ \n      p_value &lt;-  pnorm(z,lower.tail = F)} else{p_value &lt;-  pnorm(z)}\n    \n    # Display p-value\n    paste0(\"Probability of getting p̂ this extreme : \", round(p_value, 4))\n  })\n  output$pValueText_binom &lt;- renderText({\n    # Calculate p-value\n    if(input$sides2==\"2-sided\"){\n      tst = binom.test(x = input$phat2*input$n2, n = input$n2, p = input$p2, alternative = \"two.sided\",conf.level = 1-input$alpha2)\n    } else if(input$sides2==\"1-sided (upper)\"){ \n      tst = binom.test(x = input$phat2*input$n2, n = input$n2, p = input$p2, alternative = \"greater\",conf.level = 1-input$alpha2)\n    } else{      tst = binom.test(x = input$phat2*input$n2, n = input$n2, p = input$p2, alternative = \"less\",conf.level = 1-input$alpha2)}\n    \n    p_value = tst$p.value\n    # Display p-value\n    paste0(\"Probability of getting p̂ this extreme : \", round(p_value, 4))\n  })\n  \n  output$binomPlot &lt;- renderPlot({\n    # Calculate standard error\n    se_est &lt;- sqrt(input$phat2*(1-input$phat2)/input$n2)\n    se_true &lt;-  sqrt(input$p2*(1-input$p2)/input$n2)\n    \n  \n    # Calculate p-value\n    if(input$sides2==\"2-sided\"){\n      tst = binom.test(x = input$phat2*input$n2, n = input$n2, p = input$p2, alternative = \"two.sided\",conf.level = 1-input$alpha2)\n    } else if(input$sides2==\"1-sided (upper)\"){ \n      tst = binom.test(x = input$phat2*input$n2, n = input$n2, p = input$p2, alternative = \"greater\",conf.level = 1-input$alpha2)\n      } else{      tst = binom.test(x = input$phat2*input$n2, n = input$n2, p = input$p2, alternative = \"less\",conf.level = 1-input$alpha2)}\n    \n    p_value = tst$p.value\n    # Define the color based on p-value and alpha\n    tail_color &lt;- ifelse(p_value &lt; input$alpha2, \"red\", \"blue\")\n    \n    # Generate x values for the plot\n    x_values &lt;- seq(0,1,by = 1/input$n2)\n    if(input$sides2==\"2-sided\"){\n      shade_vals1 = x_values[x_values&lt;=min(input$phat2, 2*input$p2-input$phat2)| \n                               near(x_values,max(input$phat2, 2*input$p2-input$phat2) )]\n    } else if(input$sides2==\"1-sided (upper)\"){ \n      shade_vals1 = NA\n    } else{shade_vals1 = x_values[x_values&lt;=input$phat2]}\n    \n    if(input$sides2==\"2-sided\"){\n      shade_vals2 = x_values[ x_values&gt;=max(input$phat2, 2*input$p2-input$phat2) | \n                                near(x_values,max(input$phat2, 2*input$p2-input$phat2) )]\n    } else if(input$sides2==\"1-sided (upper)\"){ \n      shade_vals2 = x_values[x_values&gt;=input$phat2]\n    } else{shade_vals2 = NA}\n    # Calculate y values for the density function\n    y_values &lt;- dbinom(x_values*input$n2, p = input$p2, size = input$n2)\n    \n    # Generate the plot\n    \n    p &lt;- data.frame(x = x_values, y = y_values) %&gt;%\n      filter(y &gt;= 4.025758e-73) %&gt;%\n      mutate(extreme = x %in% c(shade_vals1,shade_vals2)) %&gt;%\n      ggplot(., aes(x = x)) +\n      geom_bar(aes(y = y, fill = extreme), stat = \"identity\") +\n      scale_fill_manual(values = c(`FALSE` = \"lightgrey\",`TRUE` = tail_color),\n                        levels)+\n      geom_segment(aes(x = input$phat2, y = 0, xend = input$p2, yend = 0), color = \"black\", \n                     size = .75, arrow = grid::arrow(angle = 90,ends = \"both\",length = unit(.1, \"inches\")) )+\n      # Add vertical lines for xbar and mu\n      geom_vline(xintercept = input$phat2, linetype = \"dashed\", color = \"cornflowerblue\", size = 0.75) +\n      geom_vline(xintercept = input$p2, linetype = \"dashed\", color = \"darkorange2\", size = 0.75) +\n      # Add labels for xbar and mu\n      annotate(\"text\", x = input$phat2, y = -0.005, label = \"p̂\", color= \"cornflowerblue\", hjust = -0.2, size = 5) +\n      annotate(\"text\", x = input$p2, y = -0.005, label = \"p\", color = \"darkorange2\",  hjust = 1.2, size = 5) +\n      labs(title = \"Binomial Distribution With Selected Proportion\",\n           x = \"Value\",\n           y = \"Density\") +\n      theme_minimal() + theme(legend.position = \"none\") + ylim(-max(y_values)/16, max(y_values))\n    \n    if(input$sides == \"2-sided\"){\n      # Add line segment to show the distance between xbar and mu\n      p &lt;- p + geom_segment(aes(x = 2*input$p2-input$phat2, y = 0, xend = input$p2, yend = 0), color = \"black\", \n                            size = .75, arrow = grid::arrow(angle = 90,ends = \"both\",length = unit(.1, \"inches\")) )\n    }\n    \n    \n    if(showCI()){\n     \n        p &lt;- p + \n          geom_segment(aes(x = tst$conf.int[1], y = -max(y_values)/16, xend = tst$conf.int[2], yend = -max(y_values)/16),lineend = \"square\", color = \"purple\", alpha = 0.3,\n                       size = .75 )\n    }\n    \n    print(p)\n  })\n}\n\n\n# Run the application \nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "posts/VIF_shiny2/vif2_shiny.html",
    "href": "posts/VIF_shiny2/vif2_shiny.html",
    "title": "Variance Inflation",
    "section": "",
    "text": "#| standalone: true\n#| viewerHeight: 600\n\n\nlibrary(shiny)\nlibrary(tidyverse)\nlibrary(GGally)\n\n# Define UI for application that draws a histogram\nui &lt;- fluidPage(\n  \n  # Application title\n  titlePanel(\"Added-Variable Plots and VIF\"),\n  \n  \n  # Show a plot of the generated distribution\n  tabsetPanel(type = \"tabs\",\n              tabPanel(\"Changing the variability in x\",\n                       sidebarLayout( \n                         sidebarPanel(\n                           sliderInput(\"c\", \"Scaling Constant\", \n                                       min = 0.1, max = 3,value = 1)),\n                         mainPanel( \n                           strong(\"Description:\"),\n                           p(\"The goal of this part of the app is to show you how changing the amount of variability in x impacts the standard error of our coefficient estimate for \\u03B2. That is, if we increase or decrease the amount of variability in the predictor (x) relative to the amount of variability in the outcome (y), what happens to the standard error of the slope coefficient? \"),\n                           p(\"We will demonstrate this by scaling x by a constant factor while keeping y the same.\"),\n                           p(\"Below, I have simulated some data with predictor x and outcome y. Move the slider above to increase or decrease the standard deviation of x (scale by &lt;1 to decrease and &gt;1 to increase the standard deviation). The outcome y will stay the same\\u2013only x is changing. Notice how the standard error of the slope coefficient changes as we increase or decrease the variability in x.\"),\n                           plotOutput(\"xplot\",height = \"300px\"),\n                           span(textOutput(\"sd_orig\"), style=\"font-weight:bold\"),\n                           span(textOutput(\"se_orig\"), style=\"font-weight:bold\"),\n                           span(textOutput(\"sd\"), style=\"font-weight:bold; color:green\"),\n                           span(textOutput(\"se\"), style=\"font-weight:bold; color:blue\"),\n                           p(),\n                           strong(\"What's the trend?\"),\n                           p(\"As we decrease the variability in the predictor, x, we increase our uncertainty (the standard error) in our estimate of \\u03B2. Likewise, the standard error decreases if we increase the variability in x.  \"\n                           ),\n                           strong(\"Intuition (example: changing units)\"),\n                           p(\"As a simple example of this to provide a bit more intuition for this phenomenon, imagine that the predictor x represents height and y represents shoe size. If we measure x in inches, the variance or standard deviation of x will be smaller than if we measure x in centimeters, due to the difference in units. For example, a standard deviation of 2 inches would be equivalent to a standard deviation of about 5 centimeters (the smaller the unit, the bigger the standard deviation measured in those units). If we wanted to measure the association between height and shoe size, it makes sense that we would need a wider interval to describe our uncertainty in the expected change in shoe size for a one-inch change in height compared to the interval we need for the expected change in shoe size for a one-centimeter change in height, since a one-inch change in height is a lot bigger than a one-centimeter change! Again we see that the version of x that had the larger standard deviation (centimeters) resulted in the lower standard error for the slope estimate (and vice versa).\n                             \n                             We don't just have to change the variability in X based on scale, this was just a simple example. Generally this will remain true: if you have more varaibility in x then you will see smaller standard errors for the slope coefficient for x. \"\n                           )\n                         )))\n                           \n                           \n                         ) )\n\n\n\n\n# Define server logic required to draw a histogram\nserver &lt;- function(input, output) {\n  \n  set.seed(234)\n  N = 150\n  x1 = runif(n = N, max = 10) %&gt;% round()\n  y = 4.2 + 1.5*x1 + rnorm(n = N, sd = 1.3)\n \n\n\n  vals&lt;-reactiveValues(c=1)\n  \n  observeEvent({input$c},{ vals$c=input$c})\n  \n  \n  output$xplot &lt;- renderPlot({\n    dt = data.frame(x1,y) %&gt;% mutate(x1c = x1*vals$c)\n    dt %&gt;% \n      ggplot(aes(x = x1c, y=y)) + \n      geom_point() +\n      theme_bw() + \n      labs(x = paste0(vals$c,\" * x\")) + \n      xlim(0, 30) + \n      geom_smooth(method = \"lm\", formula = y~x, se = F)\n  })\n  \n  output$se &lt;- renderText({\n    dt = data.frame(x1,y) %&gt;% mutate(x1c = x1*vals$c)\n    se = (summary(lm(y~x1c, data = dt ))$coef[2,2]) %&gt;% \n      round(digits=5)\n    print(paste0(\"Standard error for slope coefficient (\\u03B2): \",se))\n  })\n  \n  output$se_orig &lt;- renderText({\n    dt = data.frame(x1,y) %&gt;% mutate(x1c = x1*vals$c)\n    se = (summary(lm(y~x1, data = dt ))$coef[2,2]) %&gt;% \n      round(digits=5)\n    print(paste0(\"Standard error for original slope coefficient (\\u03B2): \",se))\n  })\n  \n  \n  output$sd &lt;- renderText({\n    dt = data.frame(x1,y) %&gt;% mutate(x1c = x1*vals$c)\n    sd = sd(dt$x1c) %&gt;% round(digits = 5)\n    print(paste0(\"Standard deviation of scaled x (\",vals$c,\"x): \",sd))\n  })\n  \n  output$sd_orig &lt;- renderText({\n    sd = sd(x1) %&gt;% round(digits = 5)\n    print(paste0(\"Standard deviation of x (original): \",sd))\n  })\n  \n  \n  \n  \n}\n\n# Run the application \nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "posts/VIF_shiny/VIF_shiny.html",
    "href": "posts/VIF_shiny/VIF_shiny.html",
    "title": "Collinearity in MLR",
    "section": "",
    "text": "#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 600\n\n\nlibrary(shiny)\nlibrary(tidyverse)\nlibrary(GGally)\n\n# Define UI for application that draws a histogram\nui &lt;- fluidPage(\n  \n  # Application title\n  titlePanel(\"Collinearity in MLR\"),\n  \n  \n  # Show a plot of the generated distribution\n  tabsetPanel(type = \"tabs\",\n              tabPanel(\"Changing the variability in x\",\n                        strong(\"Description:\"),\n                           p(\"The goal of this part of the app is to show you how changing the amount of variability in x impacts the standard error of our coefficient estimate for \\u03B2. That is, if we increase or decrease the amount of variability in the predictor (x) relative to the amount of variability in the outcome (y), what happens to the standard error of the slope coefficient? \"),\n                           p(\"We will demonstrate this by scaling x by a constant factor while keeping y the same.\"),\n                           p(\"Below, I have simulated some data with predictor x and outcome y. Move the slider above to increase or decrease the standard deviation of x (scale by &lt;1 to decrease and &gt;1 to increase the standard deviation). The outcome y will stay the same\\u2013only x is changing. Notice how the standard error of the slope coefficient changes as we increase or decrease the variability in x.\"),\n                      sidebarLayout( \n                         sidebarPanel(\n                           sliderInput(\"c\", \"Scaling Constant\", \n                                       min = 0.1, max = 3,value = 1)),\n                         mainPanel( \n                          \n                           plotOutput(\"xplot\",height = \"300px\"),\n                           span(textOutput(\"sd_orig\"), style=\"font-weight:bold\"),\n                           span(textOutput(\"se_orig\"), style=\"font-weight:bold\"),\n                           span(textOutput(\"sd\"), style=\"font-weight:bold; color:green\"),\n                           span(textOutput(\"se\"), style=\"font-weight:bold; color:blue\"),\n                           p(),\n                           strong(\"What's the trend?\"),\n                           p(\"As we decrease the variability in the predictor, x, we increase our uncertainty (the standard error) in our estimate of \\u03B2. Likewise, the standard error decreases if we increase the variability in x.  \"\n                           )\n                         ))),\n              tabPanel(\"MLR and VIF\",\n                       h3(\"Simulating the data\"),\n                           p(\"Here we've simulated some data with one outcome (y) and two predictors (x1 and x2). \n                             You can control the amount of correlation between x1 and x2 using the radio buttons on the left panel\"),\n                      sidebarLayout( \n                         sidebarPanel(\n                           sliderInput(\"cor1\", \"Correlation betweel x1 and x2\",\n                                       min = -1, max = 1, step = 0.02,\n                                       value= 0.8)\n                         ),\n                         mainPanel(\n                           \n                           \n                           h3(\"Plotting the data\"),\n                           p(\"Here we can see the scatterplots between each pair of variables in the data.\"),\n                           plotOutput(\"corplot\",height = \"300px\"),\n                           p(\"Points colored by x2:\"),\n                           \n                           plotOutput(\"dataPlot1\", height = \"300px\"),\n                           \n                           p('Split by approximate x2 value (holding it \"constant\"):'),\n                           \n                           plotOutput(\"dataPlot3\", height = \"300px\"),\n                           p(\"Notice how if we picked a non-zero correlation between x1 and x2, the range of values of x1 for any value we fix for x2 is \n                            smaller than the overall range of x1 that we originally saw.\"),\n                           \n                           p(),\n                         \n                           p(\"Now imagine that we combine all of these plots together, but first we center them both in terms of x1 and y. \"),\n                           \n                          # plotOutput(\"dataPlot3\", height = \"300px\"),\n                           p(\"This is similar to what an added variable plot is (if x2 is categorical, this is exactly what an added variable plot is; if it is continuous, we add a linearity constraint to the centering process). If we combine all of the centered scatter plots above, we can see that there doesn't appear to be any relationship between x2 and either x1 or y (the colors are scattered without a clear pattern). This is what we mean by \\\"removing the effects of x2.\\\" What we are visualizing now is the relationship between x1 and y, adjusted for x2 (the relationship between x1 and y that is completely independent of x2). The overall slope for x1 in the MLR is the slope in the added variable plot, which you can think of as a sort of average of the slopes across the panels in the plot above.\"),\n                           #fluidRow(\n                           #  column(12, plotOutput(\"dataPlot4\", height = \"300px\"))\n                           # ),\n                           \n                           plotOutput(\"AVplot1\", height = \"300px\"),\n                           strong(\"How does this relate to standard error?\"),\n                           p(\"Remember that changing the variability in x relatuve to y impacted the standard error for our \\u03B2 estimate. When we fit a multiple linear regression model we are looking at the association between each variable and the outcome, holding the other variable(s) constant. But if x1 and x2 are correlated, then for each fixed value of x2, the range of values we observe for x1 is smaller than the total amount of variability in x1 overall. So including correlated predictors in a MLR model results in higher standard errors for slope coefficients than if predictors were uncorrelated.\"),\n                           p(\" If x1 and x2 are perfectly correlated, we cannot fix one variable while moving the other. Changing one means the other must change as well. In this case, when we fix the value of x2, we know exactly what x1 will be and there is no variability left in x1 (and vice versa), so the standard error for the slope coefficients for x1 and x2 will be infinity.\"),\n                           p(),\n                           \n                           h3(\"VIF\"),\n                           textOutput(\"vif\")\n                           \n                           \n                         ) )\n              )\n              \n  ) \n  \n)\n\n\n\n# Define server logic required to draw a histogram\nserver &lt;- function(input, output) {\n  \n  set.seed(234)\n  N = 150\n  x1 = runif(n = N, max = 10) %&gt;% round()\n  y = 4.2 + 1.5*x1 + rnorm(n = N, sd = 1.3)\n  origx2&lt;-(3 +rnorm(n = N, sd =.5)) \n  \n  X = cbind(scale(x1),scale(origx2))\n  c1 = var(X)\n  chol1 = solve(chol(c1))\n  newx = X %*% chol1 \n  R2 = matrix(c(1,0.8, 0.8, 1), nrow = 2)\n  \n  chol2 = chol(R2)\n  finalx = newx %*% chol2 * sd(x1) + mean(x1)\n  \n  x2 = finalx[,2]/1.9\n  \n  \n  \n  vals&lt;-reactiveValues( x2=x2,c=1,av.data=NULL,dt=data.frame(x1, x2 =x2,y),cor = 0.8)\n  \n  observeEvent({input$c},{ vals$c=input$c})\n  \n  observeEvent({input$cor1},{ \n    cr = as.numeric(input$cor1)\n    if(!cr%in%c(1,-1)){\n      \n      R2 = matrix(c(1,cr, cr, 1), nrow = 2)\n      \n      chol2 = chol(R2)\n      finalx = newx %*% chol2 * sd(x1) + mean(x1)\n      \n      x2 = finalx[,2]/1.9\n    } else {x2 = cr * x1}\n    \n    \n\n    \n    vals$x2 = x2\n    vals$dt = data.frame(x1, x2 = vals$x2,y) %&gt;%\n      mutate(r_x2 = plyr::round_any(vals$x2, .5)) \n    vals$cor = as.numeric(input$cor1)\n    \n    \n    xres1 = round(lm(x1 ~ x2, data = vals$dt)$residuals,digits = 6)\n    yres1 = round(lm(y ~ x2, data = vals$dt)$residuals , digits = 6)\n    xres2 = round(lm(x2 ~ x1, data = vals$dt)$residuals, digits = 6) \n    yres2 = round(lm(y ~ x1, data = vals$dt)$residuals, digits = 6)\n    \n    vals$av.data = data.frame(x_axis = c(xres1, xres2), \n                              y_axis = c(yres1, yres2),\n                              variable = rep(c(\"Removing x2\", \"Removing x1\"), \n                                             each = 50))\n  })\n  \n  output$xplot &lt;- renderPlot({\n    dt = data.frame(x1,y) %&gt;% mutate(x1c = x1*vals$c)\n    dt %&gt;% \n      ggplot(aes(x = x1c, y=y)) + \n      geom_point() +\n      theme_bw() + \n      labs(x = paste0(vals$c,\" * x\")) + \n      xlim(0, 30) + \n      geom_smooth(method = \"lm\", formula = \"y ~ x\", se = FALSE)\n  })\n  \n  output$se &lt;- renderText({\n    dt = data.frame(x1,y) %&gt;% mutate(x1c = x1*vals$c)\n    se = (summary(lm(y~x1c, data = dt ))$coef[2,2]) %&gt;% \n      round(digits=5)\n    print(paste0(\"Standard error for slope coefficient (\\u03B2): \",se))\n  })\n  \n  output$se_orig &lt;- renderText({\n    dt = data.frame(x1,y) %&gt;% mutate(x1c = x1*vals$c)\n    se = (summary(lm(y~x1, data = dt ))$coef[2,2]) %&gt;% \n      round(digits=5)\n    print(paste0(\"Standard error for original slope coefficient (\\u03B2): \",se))\n  })\n  \n  \n  output$sd &lt;- renderText({\n    dt = data.frame(x1,y) %&gt;% mutate(x1c = x1*vals$c)\n    sd = sd(dt$x1c) %&gt;% round(digits = 5)\n    print(paste0(\"Standard deviation of scaled x (\",vals$c,\"x): \",sd))\n  })\n  \n  output$sd_orig &lt;- renderText({\n    sd = sd(x1) %&gt;% round(digits = 5)\n    print(paste0(\"Standard deviation of x (original): \",sd))\n  })\n  \n  output$corplot &lt;- renderPlot({\n    \n    #psych::pairs.panels(vals$dt, ellipses = F, hist.col = \"skyblue1\")\n    ggpairs(vals$dt %&gt;% dplyr::select(-r_x2), \n            # upper = list(continuous = wrap(\"blank\")),\n            lower = list(continuous = \"points\"),\n            diag = list(continuous = \"densityDiag\")) + \n      theme_bw()\n  })\n  \n  output$dataPlot1 &lt;- renderPlot({\n    \n    vals$dt %&gt;% \n      ggplot(aes(x = x1, y=y, color = x2)) + \n      geom_point() +\n      theme_bw() + \n      xlim(0, 10) +\n      scale_color_viridis_c(option=\"turbo\") + \n      labs(title  = \"Data colored by x2 value\")\n  })\n  \n  output$dataPlot2 &lt;- renderPlot({\n    \n    vals$dt %&gt;% \n      ggplot(aes(x = x1, y=y)) + \n      geom_point(aes(color = x2)) +\n      theme_bw() + \n      xlim(0, 10) +\n      scale_color_viridis_c(option=\"turbo\") + \n      facet_wrap(.~r_x2)+\n      labs(title  = \"Data split by x2 value\") + \n      geom_smooth(method = \"lm\", se = F, linewidth = 0.5, aes(color = r_x2)) + \n      labs(color = \"x2\")\n  })\n  \n  output$dataPlot3 &lt;- renderPlot({\n    \n    vals$dt %&gt;% \n      ggplot(aes(x = x1, y=y)) + \n      geom_point(aes(color = x2)) +\n      theme_bw() + \n      xlim(0, 10) +\n      scale_color_viridis_c(option=\"turbo\") + \n      facet_wrap(.~r_x2)+\n      labs(title  = \"Data split by x2 value\") + \n      geom_smooth(method = \"lm\", se = F, size = 0.5, aes(color = r_x2)) + \n      labs(color = \"x2\")+  \n      geom_vline(data = vals$dt %&gt;%  group_by(r_x2) %&gt;% summarize(mean_x = mean(x1)), aes(xintercept = mean_x), linetype = \"dashed\", color = \"darkgrey\") +\n      geom_hline(data = vals$dt %&gt;% group_by(r_x2) %&gt;% summarize(mean_y = mean(y)), aes(yintercept = mean_y), linetype = \"dashed\", color = \"darkgrey\") + \n      theme(legend.position = \"none\")\n  })\n  \n  \n  \n  output$AVplot1 &lt;- renderPlot({\n    \n    vals$av.data %&gt;%\n      filter(variable==\"Removing x2\") %&gt;%\n      mutate(x2 = vals$x2)%&gt;%\n      ggplot(aes(x = x_axis, y = y_axis)) + \n      theme_bw() + \n      geom_smooth(method = \"lm\",color = \"black\", se = F,linewidth = 0.5) + \n      geom_point(aes(color = x2)) + \n      # geom_smooth(method = \"lm\", aes(color = x2, group = x2), linewidth = 0.5, alpha = 0.1, se = F)+\n      labs(x = \"Residuals (x1 | x2)\", y = \"Residuals (Y | x2)\",\n           title = \"Added Variable Plot\",\n           subtitle = \"Adjusting for x2\") +\n      scale_color_viridis_c(option=\"turbo\") +\n      geom_hline(yintercept = 0, linetype = \"dashed\", color = \"darkgrey\") + \n      geom_vline(xintercept = 0,linetype = \"dashed\", color = \"darkgrey\") +   \n      xlim(c(-1,1)*diff(range(vals$dt$x1))/2)\n    \n  })\n  \n  \n  \n  output$vif &lt;- renderText({\n    vif = round(1/(1-as.numeric(vals$cor)^2),5)\n    print(paste0(\"Variance Inflation Factor: \",vif))\n  })\n  \n  \n  \n}\n\n# Run the application \nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "posts/Conf_Pred_int_shiny/confpredinf_shiny.html",
    "href": "posts/Conf_Pred_int_shiny/confpredinf_shiny.html",
    "title": "Confidence Intervals and Prediction Intervals",
    "section": "",
    "text": "#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 600\n\n\nlibrary(shiny)\nlibrary(tidyverse)\nlibrary(cowplot)\n\n\n# Define UI for application with tabs\nui &lt;- fluidPage(\n  \n  # Application title\n  titlePanel(\"Regression: Confidence and Prediction Intervals\"),\n  \n  tabsetPanel(\n    tabPanel(\"Confidence Interval for Regression Line\",\n             sidebarLayout(\n               sidebarPanel(\n                 sliderInput(\"slope\", \"True Slope\", min = -2, max = 2, value = 0, step = .01),\n                 sliderInput(\"intercept\", \"True Intercept\", min = -10, max = 10, value = 0, step = .01),\n                 sliderInput(\"slopetry\", \"Slope to try\", min = -2, max = 2, value = 0, step = .01),\n                 sliderInput(\"intercepttry\", \"Intercept to try\", min = -10, max = 10, value = 0, step = .01),\n                 numericInput(\"alpha\", \"Significance Level\", value = 0.05, min = 0, max = 1),\n                 numericInput(\"n\", \"Sample size\", min = 1, max = 1000, value = 30)\n               ),\n               \n               # Show a plot of the generated distribution\n               mainPanel(\n                 plotOutput(\"slopePlot\")\n               )\n             )\n    ),\n    tabPanel(\"Confidence vs Prediction Intervals\",\n             sidebarLayout(\n               sidebarPanel(\n                 numericInput(\"xval\", \"Choose X value\", value = 25, min = 18, max = 40, step = 1),\n                 radioButtons(\"interval_type\", \"Confidence vs Prediction Interval\",\n                              c(\"Confidence Interval\" = \"ci\", \"Prediction Interval\" = \"pi\"),\n                              selected = \"ci\")\n               ),\n               \n               # Show a plot of the generated distribution\n               mainPanel(\n                 plotOutput(\"intervalPlot\")\n               )\n             )\n    )\n  )\n)\n\n\nserver &lt;- function(input, output, session) {\n  \n  vals &lt;- reactive({\n    x &lt;- runif(input$n, min = 18, max = 40)\n    y &lt;- input$intercept + input$slope * x + rnorm(input$n, sd = 2)\n    data.frame(x = x, y = y)\n  \n  })\n  \n  \n  observe({\n    # Fit the regression model with current slope and intercept\n    mdl &lt;- lm(y ~ x, data = vals())\n    se_estimates &lt;- sqrt(diag(vcov(mdl)))\n    \n    # Default values if standard errors are NaN or NULL\n    slope_se &lt;- ifelse(is.na(se_estimates[\"x\"]), 0.1, se_estimates[\"x\"])\n    intercept_se &lt;- ifelse(is.na(se_estimates[\"(Intercept)\"]), 1, se_estimates[\"(Intercept)\"])\n    \n    # Minimum range width to avoid too narrow sliders\n    slope_min &lt;- max(input$slope - 2 * slope_se, input$slope - 0.5) %&gt;% round(digits = 3)\n    slope_max &lt;- min(input$slope + 2 * slope_se, input$slope + 0.5) %&gt;% round(digits = 3)\n    intercept_min &lt;- max(input$intercept - 2 * intercept_se, input$intercept - 5) %&gt;% round(digits = 3)\n    intercept_max &lt;- min(input$intercept + 2 * intercept_se, input$intercept + 5) %&gt;% round(digits = 3)\n    \n    # Step size calculation\n    slope_step &lt;- max(slope_se / 10, 0.001) %&gt;% round(digits = 4)\n    intercept_step &lt;- max(intercept_se / 10, 0.05) %&gt;% round(digits = 4)\n    \n    # Update sliders with dynamic range and step\n    updateSliderInput(session, \"slopetry\", \n                      min = slope_min, \n                      max = slope_max, \n                      step = slope_step, \n                      value = input$slope)\n    \n    updateSliderInput(session, \"intercepttry\", \n                      min = intercept_min, \n                      max = intercept_max, \n                      step = intercept_step, \n                      value = input$intercept)\n  })\n  \n  # Plot for Slope Comparison\n  output$slopePlot &lt;- renderPlot({\n    mdl &lt;- lm(y ~ x, data = vals())\n    coef_estimates &lt;- coef(mdl)\n    coef_cov &lt;- vcov(mdl)\n    \n    user_coef &lt;- c(input$intercepttry, input$slopetry)\n    delta &lt;- user_coef - coef_estimates\n    mahalanobis_dist &lt;- t(delta) %*% solve(coef_cov) %*% delta\n    \n    critical_value &lt;- qchisq(1 - input$alpha, df = 2)\n    within_ci &lt;- as.numeric(mahalanobis_dist) &lt;= critical_value\n    clr &lt;- if (within_ci) \"blue\" else \"red\"\n    \n    ggplot(vals(), aes(x = x, y = y)) +\n      geom_point() +\n      geom_smooth(method = \"lm\", formula = y ~ x, level = 1 - input$alpha, color = \"black\") +\n      geom_abline(slope = input$slopetry, intercept = input$intercepttry, color = clr, linetype = \"dashed\") +\n      labs(title = \"Regression Line and Confidence Interval\",\n           x = \"X\", y = \"Y\") +\n      theme_bw()\n  })\n  \n  # Plot for Interval Comparison\n  output$intervalPlot &lt;- renderPlot({\n    \n    mdl &lt;- lm(y ~ x, data = vals())\n    pred &lt;- predict(mdl, newdata = data.frame(x = input$xval), \n                    interval = \"predict\", level = 1 - input$alpha)\n    conf &lt;- predict(mdl, newdata = data.frame(x = input$xval), \n                    interval = \"confidence\", level = 1 - input$alpha)\n    \n    mean_y &lt;- pred[1]\n    \n    if (input$interval_type == \"ci\") {\n      sd_y &lt;- (conf[3] - conf[2]) /(2 * qnorm(1 - input$alpha / 2))\n      clr &lt;- \"purple3\"\n      ymn &lt;- conf[2]\n      ymx &lt;- conf[3]\n    } else {\n      sd_y &lt;- (pred[3] - pred[2]) / (2 * qnorm(1 - input$alpha / 2))\n      clr &lt;- \"magenta\"\n      ymn &lt;- pred[2]\n      ymx &lt;- pred[3]\n    }\n    \n    p &lt;- ggplot(vals(), aes(x = x, y = y)) +\n      geom_point() +\n      geom_smooth(method = \"lm\", formula = y ~ x, level = 1 - input$alpha, color = \"black\") +\n      geom_errorbar(aes(x = input$xval, ymin = ymn, ymax = ymx), color = clr, width = 0.2) +\n      geom_point(aes(x = input$xval, y = pred[1]), color = \"purple\", size = 3) +\n      labs(title = \"Regression Line and Confidence/Prediction Intervals\",\n           x = \"X\", y = \"Y\") +\n      theme_bw() + \n      geom_vline(aes(xintercept = input$xval), color = \"purple\",\n                     linewidth = 0.5, linetype = 2) \n      \n      \n  \n  \n    \n    y_density &lt;- axis_canvas(p, axis = \"y\", coord_flip = TRUE) +\n      geom_function(fun = dnorm, args = list(mean = pred[1], sd = sd_y), color = clr) +\n      coord_flip()\n    \n    # Create the combined plot\n    combined_plot &lt;- insert_yaxis_grob(p, y_density, position = \"right\")\n    \n    # Show the result\n    ggdraw(combined_plot)\n  })\n}\n\n# Run the application \nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "posts/ROC_shiny/ROC_shiny.html",
    "href": "posts/ROC_shiny/ROC_shiny.html",
    "title": "ROC Curves",
    "section": "",
    "text": "#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 600\n\nlibrary(shiny)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(pROC)\n\n# Simulated data\ngenerate_simulated_data &lt;- function(n = 100) {\n  set.seed(123)\n  data.frame(\n    ID = 1:n,\n    TrueLabel = sample(c(0, 1), n, replace = TRUE),\n    Score = runif(n)\n  )\n}\n\nui &lt;- fluidPage(\n  titlePanel(\"Classification with Custom Data\"),\n  sidebarLayout(\n    sidebarPanel(\n      radioButtons(\"data_source\", \"Data Source:\",\n                   choices = c(\"Simulated\", \"User-Provided\")),\n      \n      conditionalPanel(\n        condition = \"input.data_source == 'User-Provided'\",\n        radioButtons(\"user_input_method\", \"Input Method:\",\n                     choices = c(\"Upload Full CSV\", \n                                 \"Manual Entry\", \n                                 \"Upload Outcomes and Scores Separately\"))\n      ),\n      \n      conditionalPanel(\n        condition = \"input.data_source == 'User-Provided' && input.user_input_method == 'Upload Full CSV'\",\n        fileInput(\"csv_file\", \"Upload CSV\", accept = \".csv\")\n      ),\n      \n      conditionalPanel(\n        condition = \"input.data_source == 'User-Provided' && input.user_input_method == 'Manual Entry'\",\n        textAreaInput(\"manual_input\", \"Paste data (TrueLabel, Score):\",\n                      value = \"0,0.2\\n1,0.8\\n0,0.3\", rows = 5),\n        actionButton(\"submit_btn\", \"Submit Data\")\n      ),\n      \n      conditionalPanel(\n        condition = \"input.data_source == 'User-Provided' && input.user_input_method == 'Upload Outcomes and Scores Separately'\",\n        textAreaInput(\"outcome_text\", \"Enter True Labels (comma-separated):\",\n                      value = \"0,1,1,0,1\", rows = 2),\n        textAreaInput(\"score_text\", \"Enter Scores (comma-separated):\",\n                      value = \"0.2,0.9,0.8,0.1,0.7\", rows = 2),\n        actionButton(\"submit_btn\", \"Submit Data\")\n      ),\n      \n      radioButtons(\"roc_direction\", \"ROC Direction:\",\n                   choices = c(\"controls &lt; cases\" = \"&lt;\", \"controls &gt; cases\" = \"&gt;\")),\n      \n      sliderInput(\"threshold\", \"Classification Threshold\", min = 0, max = 1, value = 0.5, step = 0.01),\n      verbatimTextOutput(\"metrics\")\n    ),\n    \n    mainPanel(\n      plotOutput(\"roc_plot\", height = \"300px\"),\n      plotOutput(\"prob_plot\", height = \"300px\"),\n      plotOutput(\"split_plot\", height = \"300px\")\n    )\n  )\n)\n\nserver &lt;- function(input, output, session) {\n  \n  user_data &lt;- reactive({\n    if (input$data_source == \"Simulated\") {\n      return(generate_simulated_data())\n    } else if (input$data_source == \"User-Provided\" && input$user_input_method == \"Upload Full CSV\" && !is.null(input$csv_file)) {\n      return(read.csv(input$csv_file$datapath))\n    } else {\n      return(NULL)\n    }\n  })\n  \n  manual_data &lt;- eventReactive(input$submit_btn, {\n    if (is.null(input$data_source) || input$data_source != \"User-Provided\") return(NULL)\n    if (is.null(input$user_input_method)) return(NULL)\n    \n    tryCatch({\n      if (input$user_input_method == \"Manual Entry\") {\n        con &lt;- textConnection(input$manual_input)\n        df &lt;- read.csv(con, header = FALSE)\n        close(con)\n        colnames(df) &lt;- c(\"TrueLabel\", \"Score\")\n        df$ID &lt;- 1:nrow(df)\n        return(df)\n        \n      } else if (input$user_input_method == \"Upload Outcomes and Scores Separately\") {\n        y &lt;- as.numeric(unlist(strsplit(input$outcome_text, \",\")))\n        x &lt;- as.numeric(unlist(strsplit(input$score_text, \",\")))\n        \n        if (length(y) != length(x)) stop(\"Outcome and score vectors must have the same length.\")\n        if (any(is.na(y)) || any(is.na(x))) stop(\"Non-numeric or missing values detected.\")\n        \n        df &lt;- data.frame(ID = 1:length(x), TrueLabel = y, Score = x)\n        return(df)\n      }\n      \n      return(NULL)\n    }, error = function(e) {\n      showNotification(paste(\"Error:\", e$message), type = \"error\")\n      return(data.frame())\n    })\n  })\n  \n  final_data &lt;- reactive({\n    if (input$data_source == \"User-Provided\" &&\n        input$user_input_method %in% c(\"Manual Entry\", \"Upload Outcomes and Scores Separately\")) {\n      return(manual_data())\n    } else {\n      return(user_data())\n    }\n  })\n  \n  processed_data &lt;- reactive({\n    df &lt;- final_data()\n    req(nrow(df) &gt; 0)\n    df %&gt;%\n      mutate(\n        Prediction = ifelse(Score &gt;= input$threshold, 1, 0),\n        Type = case_when(\n          Prediction == 1 & TrueLabel == 1 ~ \"TP\",\n          Prediction == 0 & TrueLabel == 0 ~ \"TN\",\n          Prediction == 1 & TrueLabel == 0 ~ \"FP\",\n          Prediction == 0 & TrueLabel == 1 ~ \"FN\"\n        )\n      ) %&gt;%\n      arrange(desc(Score)) %&gt;%\n      mutate(label = factor(TrueLabel, levels = 0:1, labels = c(\"Control\", \"Case\")))\n  })\n  \n  output$prob_plot &lt;- renderPlot({\n    df &lt;- processed_data()\n    if(input$roc_direction == \"&lt;\"){clrs = list(H = \"blue\",L = \"red\")\n    } else {clrs = list(L = \"blue\",H = \"red\")}\n    ggplot(df, aes(x = reorder(factor(ID), Score), y = Score,  color = Type)) +\n      geom_point() +\n      geom_hline(yintercept = input$threshold, color = \"black\", linetype = \"dashed\", size = 1) +\n      scale_color_manual(values = c(\"TP\" = \"blue\", \"TN\" = \"red\", \"FP\" = \"#f08080\", \"FN\" = \"#add8e6\")) +\n      labs(x = \"Subject\", y = \"Predicted Probability\", fill = \"Type\") +\n      theme_classic() +\n      theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +\n      annotate(\"rect\", xmin = -Inf, xmax = Inf, ymin = input$threshold, ymax = 1, \n               fill = clrs$H, alpha = 0.1) + \n      annotate(\"rect\", xmin = -Inf, xmax = Inf, ymax = input$threshold, ymin = 0, \n               fill = clrs$L, alpha = 0.1) \n  })\n  \n  output$split_plot &lt;- renderPlot({\n    df &lt;- processed_data()\n    if(input$roc_direction == \"&lt;\"){clrs = list(H = \"blue\",L = \"red\")\n    } else {clrs = list(L = \"blue\",H = \"red\")}\n    ggplot(df, aes(x = reorder(factor(ID), Score), y = Score,  color = Type)) +\n      geom_point() +\n      geom_hline(yintercept = input$threshold, color = \"black\", linetype = \"dashed\", size = 1) +\n      scale_color_manual(values = c(\"TP\" = \"blue\", \"TN\" = \"red\", \"FP\" = \"#f08080\", \"FN\" = \"#add8e6\")) +\n      labs(x = \"Subject\", y = \"Predicted Probability\", fill = \"Type\") +\n      theme_classic() +\n      theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +\n      facet_wrap(~label, scales = \"free_x\") + \n      annotate(\"rect\", xmin = -Inf, xmax = Inf, ymin = input$threshold, ymax = 1, \n               fill = clrs$H, alpha = 0.1) + \n      annotate(\"rect\", xmin = -Inf, xmax = Inf, ymax = input$threshold, ymin = 0, \n               fill = clrs$L, alpha = 0.11) \n  })\n  \n  output$roc_plot &lt;- renderPlot({\n    df &lt;- final_data()\n    req(nrow(df) &gt; 0)\n    roc_obj &lt;- roc(df$TrueLabel, df$Score, direction = input$roc_direction)\n    ggroc(roc_obj) +\n      geom_vline(xintercept = input$threshold, linetype = \"dashed\", color = \"black\") +\n      labs(title = \"ROC Curve\", x = \"Specificity\", y = \"Sensitivity\") +\n      theme_minimal() +\n      geom_segment(aes(x = 1, xend = 0, y = 0, yend = 1), color=\"darkgrey\", linetype=\"dashed\")\n    \n  })\n  \n  output$metrics &lt;- renderPrint({\n    df &lt;- final_data()\n    req(nrow(df) &gt; 0)\n    roc_obj &lt;- roc(df$TrueLabel, df$Score, direction = input$roc_direction)\n    ts &lt;- roc_obj$thresholds[is.finite(roc_obj$thresholds)]\n    thresh &lt;- which.min(abs(ts - as.numeric(input$threshold)))\n    coords_res &lt;- coords(roc_obj, x = ts[thresh], input = \"threshold\", ret = c(\"sensitivity\", \"specificity\"))\n    auc_val &lt;- auc(roc_obj)\n    cat(sprintf(\"AUC: %.3f\\n\", auc_val))\n    cat(sprintf(\"Sensitivity at Threshold: %.3f\\n\", coords_res['sensitivity']))\n    cat(sprintf(\"Specificity at Threshold: %.3f\\n\", coords_res['specificity']))\n  })\n}\n\nshinyApp(ui, server)"
  },
  {
    "objectID": "posts/LOESS_shiny/loess_shiny.html",
    "href": "posts/LOESS_shiny/loess_shiny.html",
    "title": "LOESS Smoother",
    "section": "",
    "text": "#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 600\n#\n# This is a Shiny web application. You can run the application by clicking\n# the 'Run App' button above.\n#\n# Find out more about building applications with Shiny here:\n#\n#    http://shiny.rstudio.com/\n#\n\nlibrary(shiny)\nlibrary(tidyverse)\n\n\n\n# Define UI for application that draws a histogram\nui &lt;- fluidPage(\n  \n  # Application title\n  titlePanel(\"LOESS Smoother\"),\n  \n             sidebarLayout(\n               sidebarPanel(\n                 sliderInput(\"x0\",\n                             HTML(paste0(\"x\",tags$sub(\"0\"))),\n                             min = 10,\n                             max = 25,\n                             value = 15, step = .01),\n                 sliderInput(\"alpha\",\n                             label = HTML(\"&alpha;:\"),\n                             min = 0.05,\n                             max = 3,\n                             value = 0.75, step = .01),\n                 selectInput(\"deg\",\n                             label = \"degree\",\n                             choices = c(1,2), selected = 2)\n               ),\n               \n               # Show a plot of the generated distribution\n               mainPanel(\n                 plotOutput(\"loessplot\"),\n                 plotOutput(\"loessplot2\")\n                \n               )\n  )\n  )\n\n\n\n\n# Define server logic required to draw a histogram\nserver &lt;- function(input, output) {\n\n data_url &lt;- \"https://haleykgrant.github.io/tutorial_data/data/bmd.csv\"\n \n\n     download.file(data_url, \"bmd.csv\")\n     df = read.csv(\"bmd.csv\")\n  \n\n\n \n  \n  \n  \n  x = df$age[df$sex==\"Female\"]\n  y = df$relative_diff[df$sex==\"Female\"]\n  trim &lt;- ceiling(0.1 * length(x))\n  N = length(x)\n  sv &lt;-\n    sqrt(apply(apply(x%&gt;%as.matrix(), 2L, sort)[seq(trim+1, N-trim), , drop = FALSE],\n               2L, var))\n  \n  df0 = data.frame(x=x, y=y, x0 = 15)%&gt;% \n    mutate(\n           dist = abs(x-x0)/(sv),\n           dist.rank = rank(dist),\n           nbr = (dist.rank &lt;= N*.75)%&gt;%as.numeric(),\n           maxdist = max(dist*nbr),\n           wt = nbr*(1-(dist/maxdist)^3)^3)\n  \n  fit = lm(y~poly(x,degree = 2), weights = df0$wt)\n\n  \n\n  pred0 = data.frame(x = df0$x,\n                         pred = predict(fit, \n                                        newdata = data.frame(x = df0$x))) %&gt;%\n    mutate(\n      dist = abs(x-15)/(sv),\n      dist.rank = rank(dist),\n      nbr = (dist.rank &lt;= N*.75)%&gt;%as.numeric(),\n      maxdist = max(dist*nbr),\n      wt = nbr*(1-(dist/maxdist)^3)^3)\n  \n  predx0 = data.frame(x = 15, y = predict(fit, data.frame(x=15)))\n  vals&lt;-reactiveValues(df = df0, pred = pred0, predx0 = predx0)\n  observeEvent({ input$x0\n    input$alpha\n    input$deg},\n    { \n    \n    \n    if(input$alpha&lt;1){\n    vals$df = data.frame(x=x, y=y, x0 = input$x0)%&gt;% \n      mutate(s = sd(x),\n             dist = abs(x-x0)/(sv),\n             dist.rank = rank(dist),\n             nbr = (dist.rank &lt;= N*input$alpha)%&gt;%as.numeric(),\n             maxdist = max(dist*nbr),\n             wt = nbr*(1-(dist/maxdist)^3)^3)\n    } else{\n      vals$df = data.frame(x=x, y=y, x0 = input$x0)%&gt;% \n        mutate(s = sd(x),\n               dist = abs(x-x0)/(sv),\n               dist.rank = rank(dist),\n               nbr = (dist.rank &lt;= N*input$alpha)%&gt;%as.numeric(),\n               maxdist = max(dist*nbr)*input$alpha,\n               wt = nbr*(1-(dist/maxdist)^3)^3) }\n    \n    fit = lm(y~poly(x,degree = input$deg%&gt;%as.numeric()), weights = vals$df$wt)\n    \n    #sv = sd(vals$df$x)\n    vals$pred = data.frame(x = df0$x,\n                           pred = predict(fit, \n                                          newdata = data.frame(x = df0$x))) %&gt;%\n     mutate( dist = abs(x-input$x0)/(sv),\n        dist.rank = rank(dist),\n       nbr = (dist.rank &lt;= N*input$alpha)%&gt;%as.numeric(),\n       a = max(1, input$alpha),\n       maxdist = max(dist*nbr)*a,\n       wt = nbr*(1-(dist/maxdist)^3)^3)\n    # seq(9.9, 25.6, by = 0.02)\n    vals$predx0 = data.frame(x = input$x0, y = predict(fit, data.frame(x=input$x0)))\n    \n    \n    })\n  \n  \n  output$loessplot &lt;- renderPlot({\n    vals$df %&gt;%\n      ggplot(aes(x = x, y=y)) + \n      geom_point(aes(alpha = wt)) +\n      geom_line(aes(y = pred, alpha = wt), data = vals$pred, linewidth = 2) +\n      geom_vline(aes(xintercept = x0), color = \"red\") + \n      geom_point(aes(x=x, y = y), color = \"red\", shape = 4, data = vals$predx0, size = 6) +\n      theme_bw() + \n      ylim(-.05,.2) +\n      labs(title = \"Local Polynomial Fit\") + \n      theme(legend.position = \"none\")\n     \n  })\n  output$loessplot2 &lt;- renderPlot({\n    #vals$df %&gt;%\n    #  ggplot(aes(x = x, y=y)) + \n    #  geom_point() +\n    #  geom_smooth(method = loess, method.args = list(degree = input$deg%&gt;%as.numeric(),\n    #                                                 span = input$alpha)) +\n    #  theme_bw() + \n    #  ylim(-.05,.2) +\n    #  labs(title = \"Full LOESS Curve\")\n    vals$df %&gt;%\n      ggplot(aes(x = x, y=y)) + \n      geom_point(aes(alpha = wt)) +\n      geom_line(aes(y = pred, alpha = wt), data = vals$pred, linewidth = 2) +\n      geom_vline(aes(xintercept = x0), color = \"red\") + \n      geom_point(aes(x=x, y = y), color = \"red\", shape = 4, data = vals$predx0, size = 6) +\n      geom_smooth(method = loess, method.args = list(degree = input$deg%&gt;%as.numeric(),\n                                                     span = input$alpha)) +\n      theme_bw() + \n      ylim(-.05,.2) +\n      labs(title = \"Local Polynomial Fit with Full LOESS Curve\") + \n      theme(legend.position = \"none\")\n    \n  })\n  \n  \n  \n}\n\n# Run the application \nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "posts/MLR_shiny/MLR_shiny.html",
    "href": "posts/MLR_shiny/MLR_shiny.html",
    "title": "Multiple Linear Regression",
    "section": "",
    "text": "#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 100vh\nlibrary(shiny)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(dplyr)\nlibrary(viridis)\nlibrary(tidyverse)\nlibrary(shinyWidgets)\n\n\n\n\n\n\nui &lt;- fluidPage(\n  titlePanel(\"Cross-Section Viewer\"),\n  \n  # Tab layout\n  tabsetPanel(\n    \n    # Original Plot Tab\n    tabPanel(\"3D Data Plot\",\n             sidebarLayout(\n               sidebarPanel(\n                 # Toggle for showing the red surface (cross-section)\n                 switchInput(\"show_cross_section\", label = \"Show Cross-Section\", value = TRUE),  # This is the toggle switch\n                 conditionalPanel(\n                   condition = \"input.show_cross_section == true\",  # Only show if cross-section is toggled\n                   selectInput(\"var\", \"Choose variable for cross-section:\",\n                               choices = c(\"Education\" = \"educ\", \"Infant Mortality\" = \"inf\")),\n                   uiOutput(\"dynamic_val\")  # Placeholder for dynamic slider\n                 )\n               ),\n               mainPanel(\n               #  verbatimTextOutput(\"colnames\"),\n                 plotlyOutput(\"plot3d\", height = \"700px\")\n               )\n             )\n    ),\n    \n    # Residuals Plot Tab\n    tabPanel(\"Residuals Plot\",\n             sidebarLayout(\n               sidebarPanel(\n                 # 5 Regression control buttons\n                 actionButton(\"reg_educ_outcome\", \"Regress out Education from Y\"),\n                 actionButton(\"reg_inf_outcome\", \"Regress out Infant Mortality from Y\"),\n                 actionButton(\"reg_educ_inf\", \"Regress out Education from X\"),\n                 actionButton(\"reg_inf_educ\", \"Regress out Infant Mortality from X\"),\n                 actionButton(\"reset\", \"Reset\")\n               ),\n               mainPanel(\n                 plotlyOutput(\"residuals_plot\", height = \"700px\")\n               )\n             )\n    )\n  )\n)\n\nserver &lt;- function(input, output, session) {\n   data_url &lt;- \"https://haleykgrant.github.io/tutorial_data/data/unhdd2020.rmph.rData\"\n \n     download.file(data_url, \"unhdd2020.rmph.rData\")\n     load(\"unhdd2020.rmph.rData\", verbose = T)\n  \n   \n\nunhdd = unhdd %&gt;%  \n  drop_na(life, educ_mean, mort_infant) %&gt;%  \n  mutate(row_num = row_number())\n\nm2 &lt;- lm(life ~ educ_mean + mort_infant, data = unhdd)\n\n\n\n# Save coefficients\nintercept &lt;- m2$coefficients[\"(Intercept)\"]\neduc_coef &lt;- m2$coefficients[\"educ_mean\"]\ninf_coef &lt;- m2$coefficients[\"mort_infant\"]\n\n# Range of x1 and x2 values to plot\neduc_range &lt;- seq(0, max(unhdd$educ_mean) + 1, length.out = 100)\ninf_range &lt;- seq(0, max(unhdd$mort_infant, na.rm = TRUE) + 1, length.out = 100)\n\nyhat &lt;- t(outer(educ_range, inf_range, function(x, y) intercept + educ_coef * x + inf_coef * y))\n  # Reactive value to store the camera angle\n  camera_eye &lt;- reactiveVal(list(x = 1.5, y = -1.5, z = 1.5))  # Default camera angle\n  resid_camera_eye &lt;- reactiveVal(list(x = 1.5, y = -1.5, z = 1.5))\n  \n  # Update camera when user moves the plot\n  observe({\n    req(input$plot3d_camera)\n    isolate({\n      camera_eye(input$plot3d_camera$eye)\n    })\n  })\n  observe({\n    req(input$residuals_plot_camera)\n    isolate({\n      resid_camera_eye(input$residuals_plot_camera$eye)\n    })\n  })\n  \n  \n  # Reset camera when cross-section variable changes\n  observeEvent(input$var, {\n    camera_eye(list(x = 1.5, y = -1.5, z = 1.5))  # Reset camera only when cross-section variable changes\n  })\n  \n  observeEvent(input$reset, {\n    resid_camera_eye(list(x = 1.5, y = -1.5, z = 1.5))  # Reset camera only when cross-section variable changes\n  })\n  \n  # Render the dynamic slider based on selected variable\n  output$dynamic_val &lt;- renderUI({\n    if (!input$show_cross_section) {\n      return(NULL)  # Return nothing if cross-section is hidden\n    }\n    \n    # Select the variable for the slider based on user input\n    if (input$var == \"educ\") {\n      v &lt;- unhdd$educ_mean\n      label &lt;- \"Education\"\n    } else if (input$var == \"inf\") {\n      v &lt;- unhdd$mort_infant\n      label &lt;- \"Infant Mortality\"\n    }\n    \n    # Set min, max, and median for the slider\n    min_val &lt;- floor(min(v, na.rm = TRUE))\n    max_val &lt;- ceiling(max(v, na.rm = TRUE))\n    default_val &lt;- round(median(v, na.rm = TRUE))\n    \n    sliderInput(\"val\", paste(\"Select\", label, \"value:\"),\n                min = min_val, max = max_val,\n                value = default_val, step = 1)\n  })\n  \n  # Render the original 3D plot\n  output$plot3d &lt;- renderPlotly({\n    # Calculate the model surface based on the linear model (yhat)\n    z_matrix &lt;- matrix(yhat, nrow = length(educ_range), ncol = length(inf_range))\n    \n    # Start the plot\n    p &lt;- plot_ly() %&gt;%\n      add_surface(\n        x = educ_range, y = inf_range,\n        z = z_matrix,\n        colorscale = list(c(0, 1), c(\"blue\", \"blue\")),\n        opacity = 0.3, showscale = FALSE,\n        name = \"Fitted Surface\"\n      )\n    \n    # If show_cross_section is TRUE, add the red surface and line\n    if (input$show_cross_section) {\n      if (input$var == \"inf\") {\n        # Fix y (infant mortality), vary x (educ) and z (life)\n        z_vals &lt;- seq(min(yhat), max(yhat), length.out = 50)\n        x_matrix &lt;- matrix(rep(educ_range, each = length(z_vals)), nrow = length(z_vals))\n        y_matrix &lt;- matrix(input$val, nrow = length(z_vals), ncol = length(educ_range))\n        z_matrix_red &lt;- matrix(rep(z_vals, times = length(educ_range)), nrow = length(z_vals))\n        \n        # Model prediction along educ_range\n        z_line &lt;- intercept + educ_coef * educ_range + inf_coef * input$val\n        \n        x_line &lt;- educ_range\n        y_line &lt;- rep(input$val, length(educ_range))\n        z_line &lt;- z_line\n        \n        p &lt;- p %&gt;%\n          add_surface(\n            x = x_matrix, y = y_matrix, z = z_matrix_red,\n            colorscale = list(c(0, 1), c(\"grey\", \"grey\")),\n            opacity = 0.25, showscale = FALSE,\n            name = \"Cross-section\"\n          ) %&gt;%\n          add_trace(\n            x = x_line,\n            y = y_line,\n            z = z_line,\n            type = \"scatter3d\",\n            mode = \"lines\",\n            line = list(color = \"blue\", width = 5),\n            name = \"Slope\"\n          )\n        \n      } else if (input$var == \"educ\") {\n        # Fix x (education), vary y (infant mortality) and z (life expectancy)\n        z_vals &lt;- seq(min(yhat), max(yhat), length.out = 50)\n        y_matrix &lt;- matrix(rep(inf_range, each = length(z_vals)), nrow = length(z_vals))\n        x_matrix &lt;- matrix(input$val, nrow = length(z_vals), ncol = length(inf_range))\n        z_matrix_red &lt;- matrix(rep(z_vals, times = length(inf_range)), nrow = length(z_vals))\n        \n        # Model prediction along inf_range\n        z_line &lt;- intercept + educ_coef * input$val + inf_coef * inf_range\n        \n        x_line &lt;- rep(input$val, length(inf_range))\n        y_line &lt;- inf_range\n        z_line &lt;- z_line\n        \n        p &lt;- p %&gt;%\n          add_surface(\n            x = x_matrix, y = y_matrix, z = z_matrix_red,\n            colorscale = list(c(0, 1), c(\"grey\", \"grey\")),\n            opacity = 0.5, showscale = FALSE,\n            name = \"Cross-section\"\n          ) %&gt;%\n          add_trace(\n            x = x_line,\n            y = y_line,\n            z = z_line,\n            type = \"scatter3d\",\n            mode = \"lines\",\n            line = list(color = \"blue\", width = 5),\n            name = \"Slope\"\n          )\n      }\n    }\n    \n    # Apply the camera angle when rendering the plot\n    p %&gt;%\n      add_markers(\n        x = unhdd$educ_mean, y = unhdd$mort_infant, z = unhdd$life,\n        marker = list(\n          color = unhdd$mort_infant, showscale = FALSE,\n          colorscale = \"Viridis\", size = unhdd$educ_mean,\n          line = list(color = 'rgba(0,0,0,0)', width = 0)\n        ),\n        hoverinfo = \"text\",  # Only show custom text (not the default x, y, z)\n        # Custom text with row number included\n        text = paste(\n          \"ID:\", unhdd$row_num, \"&lt;br&gt;\"  # Add row number\n        ),\n        name = \"Observed Data\"\n      ) %&gt;%\n      layout(\n        scene = list(\n          xaxis = list(title = \"Education\", showline = TRUE),\n          yaxis = list(title = \"Infant Mortality\", showline = TRUE),\n          zaxis = list(title = \"Life Expectancy\", showline = TRUE),\n          camera = list(eye = camera_eye())  # Use the reactive camera angle\n        )\n      ) %&gt;%\n      htmlwidgets::onRender(\"\n      function(el, x) {\n        el.on('plotly_relayout', function(eventData) {\n          if (eventData['scene.camera']) {\n            Shiny.setInputValue('plot3d_camera', eventData['scene.camera'], {priority: 'event'});\n          }\n        });\n      }\n    \")\n  })\n  \n  # Initialize with original data\n  initial_df &lt;- unhdd %&gt;%\n    mutate(y = life, x1 = educ_mean, x2 = mort_infant) \n  \n  \n  \n  residual_state &lt;- reactiveVal(initial_df)\n  \n  # Button 1: Regress Y ~ Education (update y)\n  observeEvent(input$reg_educ_outcome, {\n    df &lt;- residual_state()\n    df$y &lt;- resid(lm(y ~ x1, data = df))\n    residual_state(df)\n  })\n  \n  # Button 2: Regress Y ~ Infant Mortality (update y)\n  observeEvent(input$reg_inf_outcome, {\n    df &lt;- residual_state()\n    df$y &lt;- resid(lm(y ~ x2, data = df))\n    residual_state(df)\n  })\n  \n  # Button 3: Regress Infant Mortality (x2) ~ Education (x1) (update x2)\n  observeEvent(input$reg_educ_inf, {\n    df &lt;- residual_state()\n    df$x2 &lt;- resid(lm(x2 ~ x1, data = df))\n    residual_state(df)\n  })\n  \n  # Button 4: Regress Education (x1) ~ Infant Mortality (x2) (update x1)\n  observeEvent(input$reg_inf_educ, {\n    df &lt;- residual_state()\n    df$x1 &lt;- resid(lm(x1 ~ x2, data = df))\n    residual_state(df)\n  })\n  \n  # Reset everything\n  observeEvent(input$reset, {\n    residual_state(initial_df)\n  })\n  \n  # Render the plot using the current residual state\n  output$residuals_plot &lt;- renderPlotly({\n    data &lt;- residual_state()\n    \n    plot_ly() %&gt;%\n      add_markers(\n        x = data$x1, y = data$x2, z = data$y,\n        marker = list(\n          color = data$mort_infant,\n          colorscale = \"Viridis\",\n          size = data$educ_mean,\n          showscale = FALSE,\n          line = list(color = 'rgba(0,0,0,0)', width = 0)\n        ),\n        hoverinfo = \"text\",\n        text = paste(\"ID:\", data$row_num),\n        name = \"Residualized Points\"\n      ) %&gt;%\n      layout(\n        scene = list(\n          xaxis = list(title = \"X1 (Education)\"),\n          yaxis = list(title = \"X2 (Infant Mortality)\"),\n          zaxis = list(title = \"Y (Life Expectancy)\"),\n          camera = list(eye = resid_camera_eye())\n        )\n      )%&gt;%\n      htmlwidgets::onRender(\"\n      function(el, x) {\n        el.on('plotly_relayout', function(eventData) {\n          if (eventData['scene.camera']) {\n            Shiny.setInputValue('residuals_plot_camera', eventData['scene.camera'], {priority: 'event'});\n          }\n        });\n      }\n    \")\n  })\n  \n}\n\nshinyApp(ui, server)"
  },
  {
    "objectID": "posts/Regularization_shiny/regularization_shiny.html",
    "href": "posts/Regularization_shiny/regularization_shiny.html",
    "title": "Regularization",
    "section": "",
    "text": "#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 600\n#| \nlibrary(shiny)\nlibrary(plotly)\nlibrary(glmnet)\n\nset.seed(123)\nn &lt;- 100\nX &lt;- matrix(rnorm(n * 2), ncol = 2)\ncolnames(X) &lt;- c(\"x1\", \"x2\")\nbeta_true &lt;- c(3, -2)\ny &lt;- as.vector(X %*% beta_true + rnorm(n))\n\nui &lt;- fluidPage(\n  titlePanel(\"Penalized Regression\"),\n  sidebarLayout(\n    sidebarPanel(\n      sliderInput(\"lambda\", \"Lambda (penalty strength)\", min = 0.01, max = 3, value = 1, step = 0.01),\n      sliderInput(\"alpha\", \"Alpha (0 = Ridge, 1 = Lasso)\", min = 0, max = 1, value = 1, step = 0.05)\n    ),\n    mainPanel(\n      plotlyOutput(\"msePlot\", height = \"700px\", width = \"100%\")\n    )\n  )\n)\n\nserver &lt;- function(input, output) {\n  output$msePlot &lt;- renderPlotly({\n    lambda &lt;- input$lambda\n    alpha &lt;- input$alpha\n    \n    beta1_seq &lt;- seq(beta_true[1] - 5, beta_true[1] + 5, length.out = 50)\n    beta2_seq &lt;- seq(beta_true[2] - 5, beta_true[2] + 5, length.out = 50)\n    grid &lt;- expand.grid(beta1 = beta1_seq, beta2 = beta2_seq)\n    \n    # Calculate MSE with NO intercept for each beta pair\n    grid$MSE &lt;- apply(grid, 1, function(b) {\n      preds &lt;- X %*% as.numeric(b)\n      mean((y - preds)^2)\n    })\n    \n    z_matrix &lt;- matrix(grid$MSE, nrow = length(beta1_seq), byrow = FALSE)\n    \n    # Fit OLS with no intercept\n    ols_fit &lt;- lm(y ~ X - 1)\n    beta_ols &lt;- coef(ols_fit)\n    mse_min &lt;- min(grid$MSE)\n    mse_max &lt;- max(grid$MSE)\n    z_vals &lt;- seq(mse_min, mse_max, length.out = 50)\n    \n    # Fit glmnet penalized model with no intercept\n    fit &lt;- glmnet(X, y, alpha = alpha, lambda = lambda, intercept = FALSE, standardize = TRUE)\n    beta_pen &lt;- as.numeric(coef(fit))[-1]\n    mse_pen &lt;- mean((y - X %*% beta_pen)^2)\n    \n    # Compute penalty level 't' from the penalized solution (not scaled by n)\n    L1_norm &lt;- sum(abs(beta_pen))\n    L2_norm2 &lt;- sum(beta_pen^2)\n    t &lt;- alpha * L1_norm + (1 - alpha) * L2_norm2\n    if (t == 0) t &lt;- 1e-6\n    \n    plt &lt;- plot_ly() %&gt;%\n      add_surface(\n        x = ~beta1_seq,\n        y = ~beta2_seq,\n        z = ~z_matrix,\n        colorscale = list(c(0, 1), c(\"lightgrey\", \"black\")),\n        showscale = FALSE,\n        opacity = 0.9,\n        name = \"MSE Surface\"\n      ) %&gt;%\n      add_trace(\n        x = rep(beta_ols[1], 2),\n        y = rep(beta_ols[2], 2),\n        z = c(mse_min, mse_max),\n        type = \"scatter3d\",\n        mode = \"lines\",\n        line = list(color = \"red\", width = 6),\n        name = \"Unpenalized\"\n      ) %&gt;%\n      add_trace(\n        x = rep(beta_pen[1], 2),\n        y = rep(beta_pen[2], 2),\n        z = c(mse_min, mse_max),\n        type = \"scatter3d\",\n        mode = \"lines\",\n        line = list(color = \"turquoise\", width = 6),\n        name = \"Penalized\"\n      )\n    \n    ## === Constraint Wall === ##\n    if (alpha == 1) {\n      # === Lasso: Diamond (L1 norm constraint) ===\n      angles &lt;- seq(0, 2 * pi, length.out = 200)\n      diamond &lt;- data.frame(\n        beta1 = t * cos(angles) / (abs(cos(angles)) + abs(sin(angles))),\n        beta2 = t * sin(angles) / (abs(cos(angles)) + abs(sin(angles)))\n      )\n      \n      n &lt;- nrow(diamond)\n      beta1_mat &lt;- matrix(rep(diamond$beta1, length(z_vals)), nrow = n)\n      beta2_mat &lt;- matrix(rep(diamond$beta2, length(z_vals)), nrow = n)\n      z_mat &lt;- matrix(rep(z_vals, each = n), nrow = n)\n      \n      plt &lt;- plt %&gt;%\n        add_surface(\n          x = ~beta1_mat,\n          y = ~beta2_mat,\n          z = ~z_mat,\n          opacity = 0.3,\n          surfacecolor = matrix(1, nrow = n, ncol = length(z_vals)),\n          colorscale = list(c(0, 1), c(\"turquoise\", \"turquoise\")),\n          showscale = FALSE,\n          name = \"Lasso Constraint\"\n        )\n      \n    } else if (alpha == 0) {\n      # === Ridge: Circle (L2 norm constraint) ===\n      angles &lt;- seq(0, 2 * pi, length.out = 200)\n      radius &lt;- sqrt(t)\n      circle &lt;- data.frame(\n        beta1 = radius * cos(angles),\n        beta2 = radius * sin(angles)\n      )\n      \n      n &lt;- nrow(circle)\n      beta1_mat &lt;- matrix(rep(circle$beta1, length(z_vals)), nrow = n)\n      beta2_mat &lt;- matrix(rep(circle$beta2, length(z_vals)), nrow = n)\n      z_mat &lt;- matrix(rep(z_vals, each = n), nrow = n)\n      \n      plt &lt;- plt %&gt;%\n        add_surface(\n          x = ~beta1_mat,\n          y = ~beta2_mat,\n          z = ~z_mat,\n          opacity = 0.3,\n          surfacecolor = matrix(1, nrow = n, ncol = length(z_vals)),\n          colorscale = list(c(0, 1), c(\"turquoise\", \"turquoise\")),\n          showscale = FALSE,\n          name = \"Ridge Constraint\"\n        )\n      \n    } else {\n      # === Elastic Net: Numerical Solution for Boundary ===\n      theta &lt;- seq(0, 2 * pi, length.out = 200)\n      \n      get_radius &lt;- function(theta, t, alpha) {\n        fn &lt;- function(r) {\n          b1 &lt;- r * cos(theta)\n          b2 &lt;- r * sin(theta)\n          alpha * (abs(b1) + abs(b2)) + (1 - alpha) * (b1^2 + b2^2) - t\n        }\n        uniroot(fn, lower = 1e-6, upper = 1e3)$root\n      }\n      \n      radii &lt;- sapply(theta, get_radius, t = t, alpha = alpha)\n      \n      beta1_enet &lt;- radii * cos(theta)\n      beta2_enet &lt;- radii * sin(theta)\n      \n      n &lt;- length(beta1_enet)\n      beta1_mat &lt;- matrix(rep(beta1_enet, length(z_vals)), nrow = n)\n      beta2_mat &lt;- matrix(rep(beta2_enet, length(z_vals)), nrow = n)\n      z_mat &lt;- matrix(rep(z_vals, each = n), nrow = n)\n      \n      plt &lt;- plt %&gt;%\n        add_surface(\n          x = ~beta1_mat,\n          y = ~beta2_mat,\n          z = ~z_mat,\n          opacity = 0.3,\n          surfacecolor = matrix(1, nrow = n, ncol = length(z_vals)),\n          colorscale = list(c(0, 1), c(\"turquoise\", \"turquoise\")),\n          showscale = FALSE,\n          name = \"Elastic Net Constraint\"\n        )\n    }\n    \n    plt %&gt;%\n      layout(\n        scene = list(\n          xaxis = list(title = \"Beta 1\"),\n          yaxis = list(title = \"Beta 2\"),\n          zaxis = list(title = \"Loss Function\")\n        )\n      )\n  })\n}\n\n\n\nshinyApp(ui, server)"
  },
  {
    "objectID": "posts/PairedT_shiny/PairedT_shiny.html",
    "href": "posts/PairedT_shiny/PairedT_shiny.html",
    "title": "Paired vs Unpaired T: Variance",
    "section": "",
    "text": "#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 600\n\n\n\nlibrary(shiny)\nlibrary(ggplot2)\nlibrary(MASS)      # for mvrnorm\nlibrary(patchwork) # for combining plots\n\nui &lt;- fluidPage(\n  titlePanel(\"Paired vs Unpaired T-Tests\"),\n  sidebarLayout(\n    sidebarPanel(\n      sliderInput(\"rho\", \"Correlation (ρ):\", min = -1, max = 1, value = 0, step = 0.1),\n      sliderInput(\"vr\",\"Variance Ratio\", value = 1, min = 0.25, max = 2, step = .25),\n      actionButton(\"draw\", \"Draw One Sample\"),\n      actionButton(\"draw100\", \"Draw 100 Samples\"),\n      actionButton(\"reset\", \"Reset\")\n    ),\n    mainPanel(\n      plotOutput(\"plots\", height = \"600px\")\n    )\n  )\n)\n\nserver &lt;- function(input, output, session) {\n  set.seed(123)\n  # Fixed means & SDs\n  mu1 &lt;- 2;  sd1 &lt;- 1\n  mu2 &lt;- 5;  sd2 &lt;- 1\n  \n\n  \n  vals &lt;- reactiveValues(\n    draws1 = numeric(),\n    draws2 = numeric(),\n    diffs  = numeric()\n  )\n  \n  # Draw one sample\n  observeEvent(input$draw, {\n    mu &lt;- c(mu1, mu2)\n    sd2 &lt;- sqrt(sd1^2 * input$vr)\n    sigma &lt;- matrix(c(sd1^2, input$rho * sd1 * sd2,\n                      input$rho * sd1 * sd2, sd2^2), 2, 2)\n    \n    new_draw &lt;- MASS::mvrnorm(n = 1, mu = mu, Sigma = sigma)\n    \n    vals$draws1 &lt;- new_draw[1]\n    vals$draws2 &lt;- new_draw[2]\n    vals$diffs  &lt;- c(vals$diffs, new_draw[1] - new_draw[2])\n  })\n  \n  # Draw 100 samples\n  observeEvent(input$draw100, {\n    mu &lt;- c(mu1, mu2)\n    sd2 &lt;- sqrt(sd1^2 * input$vr)\n    sigma &lt;- matrix(c(sd1^2, input$rho * sd1 * sd2,\n                      input$rho * sd1 * sd2, sd2^2), 2, 2)\n    \n    bulk_draws &lt;- MASS::mvrnorm(n = 100, mu = mu, Sigma = sigma)\n    bulk_diffs &lt;- bulk_draws[,1] - bulk_draws[,2]\n    \n    vals$diffs &lt;- c(vals$diffs, bulk_diffs)\n  })\n  \n  # Reset everything\n  observeEvent(input$reset, {\n    vals$draws1 &lt;- numeric()\n    vals$draws2 &lt;- numeric()\n    vals$diffs  &lt;- numeric()\n  })\n  \n  output$plots &lt;- renderPlot({\n    sd2 &lt;- sqrt(sd1^2 * input$vr)\n    # Theoretical SD of the difference given correlation\n    diff_sd &lt;- sqrt(sd1^2 + sd2^2 - 2 * input$rho * sd1 * sd2)\n    x_range &lt;- seq(min(mu1 - 4*sd1, mu2 - 4*sd2),\n                   max(mu1 + 4*sd1, mu2 + 4*sd2),\n                   length.out = 600)\n    \n    # Data for the two theoretical normals\n    df &lt;- rbind(\n      data.frame(x = x_range, y = dnorm(x_range, mean = mu1, sd = sd1), dist = \"x̄1\"),\n      data.frame(x = x_range, y = dnorm(x_range, mean = mu2, sd = sd2), dist = \"x̄2\")\n    )\n    \n    # Top panel: curves + optional points & segment\n    p1 &lt;- ggplot(df, aes(x, y, color = dist)) +\n      geom_line(linewidth = 1.2) +\n      scale_color_manual(values = c(\"navy\",\"steelblue1\")) + \n      {\n        if (length(vals$draws1) &gt; 0) {\n          list(\n            geom_segment(aes(\n              x = vals$draws1,\n              xend = vals$draws2,\n              y = 0, yend = 0\n            ), color = \"firebrick1\", linewidth = 0.75, inherit.aes = FALSE),\n            geom_point(aes(x = vals$draws1, y = 0), color = \"navy\", size = 3, inherit.aes = FALSE),\n            geom_point(aes(x = vals$draws2, y = 0), color = \"steelblue1\", size = 3, inherit.aes = FALSE)\n          )\n        }\n      } +\n      theme_minimal(base_size = 14) +\n      labs(x = \"Value\", y = \"Density\", color = \"Distribution\") \n    \n    # Bottom panel: dot plot of differences\n    if (length(vals$diffs) &gt; 0) {\n     if(input$rho==0){cr = \"Uncorrelated\"\n     } else if(input$rho &gt; 0) {cr = \"Positively Correlated\"\n     } else {cr = \"Negatively Correlated\"}\n      n_points &lt;- length(vals$diffs)\n      binwidth &lt;- 0.2\n      \n      # Parameters for theoretical difference distribution\n      mu_diff &lt;- mu1 - mu2\n      sd_diff &lt;- sqrt(sd1^2 + sd2^2 - 2 * input$rho * sd1 * sd2)\n      sd_diff0 &lt;- sqrt(sd1^2 + sd2^2 )\n      # Maximum expected count occurs at the mode (center of normal)\n      expected_max &lt;- n_points * dnorm(mu_diff, mean = mu_diff, sd = sd_diff) * binwidth\n      \n      # Add a small margin\n      y_max &lt;- ceiling(expected_max) + ceiling(sqrt(n_points))\n      if(y_max==Inf) {y_max = n_points + ceiling(n_points/50) }\n      # Histogram\n     p2 &lt;-  ggplot() +\n        geom_histogram(aes(x = vals$diffs), binwidth = binwidth, fill = \"firebrick1\", color = \"black\") +\n        coord_cartesian(\n          xlim = c(mu_diff + -4*sd_diff0 - binwidth, mu_diff + 4*sd_diff0 + binwidth),\n          ylim = c(0, y_max)  # y-axis expands in steps\n        ) +\n        theme_minimal(base_size = 14) +\n        labs(x = \"x̄₁ - x̄₂\", y = \"Count\", title =paste0(\"Correlation: \", cr))\n     \n\n    } else {\n      p2 &lt;- ggplot() + theme_void() + ggtitle(\"No differences yet\")\n    }\n    \n    p1 / p2\n  })\n}\n\nshinyApp(ui, server)"
  },
  {
    "objectID": "posts/CLT_shiny/clt_shiny.html",
    "href": "posts/CLT_shiny/clt_shiny.html",
    "title": "Central Limit Theorem",
    "section": "",
    "text": "library(shiny)\nlibrary(tidyverse)\nlibrary(gganimate)\nlibrary(plyr)  #\n\nui &lt;- fluidPage(\n  titlePanel(\"Sampling Distributions\"),\n  \n  sidebarLayout(\n    sidebarPanel(\n      selectInput(\"dist\", \"Population distribution:\",\n                  choices = c(\"Normal\", \"Uniform\", \"Skewed\")),\n      sliderInput(\"n\", \"Sample size (n):\", min = 1, max = 50, value = 10),\n      radioButtons(\"samples\", \"Number of samples:\",\n                   choices = c(\"1 sample (animated)\" = \"animate\",\n                               \"1,000 samples\" = \"sampling1000\",\n                               \"10,000 samples\" = \"sampling10000\")),\n      actionButton(\"go\", \"Draw sample(s)\"),\n      actionButton(\"reset\", \"Reset\")\n    ),\n    \n    mainPanel(\n      h4(\"Population\"),\n      plotOutput(\"pop\", height = \"200px\"),\n      fluidRow(\n        column(6, h4(\"Sample\"), \n               conditionalPanel(\n                 condition = \"input.samples == 'animate'\",\n                 imageOutput(\"anim\", height = \"250px\")\n               ),\n               conditionalPanel(\n                 condition = \"input.samples != 'animate'\",\n                 plotOutput(\"lastSamplePlot\", height = \"250px\")\n               )\n        ),\n        column(6, h4(\"Sample Means\"), plotOutput(\"means\", height = \"250px\"))\n      ),\n      hr(),\n      h4(\"Summary Statistics\"),\n      fluidRow(\n        column(6, offset = 3,  # centers the 6-width column\n               tableOutput(\"summary\")\n        )\n      )\n    )\n  )\n)\n\nserver &lt;- function(input, output, session) {\n  \n  # save sample means and population distribution\n  rv &lt;- reactiveValues(means = numeric(), pop = NULL, last_sample = numeric())\n  \n\n  gen_population &lt;- reactive({\n    switch(input$dist,\n           \"Normal\"  = rnorm(200000, 0, 1),\n           \"Uniform\" = runif(200000, -2, 2),\n           \"Skewed\"  = rexp(200000, rate = 1.5) )\n  })\n  \n  observeEvent(input$dist, {\n    # population\n    rv$pop &lt;- gen_population()  \n    # sample means\n    rv$means &lt;- numeric()       \n    # one sample\n    rv$last_sample &lt;- NULL      \n  })\n  \n  output$pop &lt;- renderPlot({\n    req(rv$pop)\n    if (is.null(rv$pop)) {\n      rv$pop &lt;- gen_population()\n    }\n   # plot population\n    data.frame(x = rv$pop) %&gt;%\n      ggplot(aes(x = x)) + \n      geom_histogram(fill = \"lavender\",color=\"black\") + \n      theme_minimal() +\n      theme(axis.text.y = element_blank()) + \n      labs(x = element_blank(), y = element_blank())\n  })\n  \n\n  \n  observeEvent(input$go, {\n  \n    # draw one sample\n    sample_y &lt;- sample(rv$pop, input$n)\n    rv$last_sample &lt;- sample_y\n    \n    # save data\n    df &lt;- data.frame(id = 1:input$n, x = sample_y)\n    df_rep &lt;- lapply(1:input$n, function(i)\n      df[df$id &lt;= i, ] %&gt;% mutate(frame = i)) %&gt;% ldply()\n    \n    # animated plot\n    outfile &lt;- tempfile(fileext = \".gif\")\n    mn = round(mean(df$x), digits = 3)\n    s = round(sd(df$x), digits = 3)\n    p &lt;- ggplot(df_rep, aes(x = x)) +\n      geom_dotplot( fill = \"steelblue\") +\n      xlim(min(rv$pop), max(rv$pop)) +\n      theme_classic() +\n      transition_manual(frame) + \n      labs(x = element_blank(), y = element_blank()) + \n      theme(axis.text.y = element_blank())\n    \n    animate(p, nframes = input$n, fps = 3, renderer = gifski_renderer(outfile, loop = F))\n    \n    output$anim &lt;- renderImage({\n      list(src = outfile, contentType = \"image/gif\", width = 300, height = 250,res = 150)\n    }, deleteFile = TRUE)\n    \n   \n    # update means\n      if (input$samples == \"animate\") {\n      rv$means &lt;- c(rv$means, mean(sample_y))\n    } else if (input$samples == \"sampling1000\") {\n      new_means &lt;- replicate(1000 -1, mean(sample(rv$pop, input$n)))\n      rv$last_sample &lt;- sample(rv$pop, input$n)\n      rv$means &lt;- c(rv$means, new_means, mean(rv$last_sample))\n    } else if (input$samples == \"sampling10000\") {\n      new_means &lt;- replicate(10000 -1, mean(sample(rv$pop, input$n)))\n      rv$last_sample &lt;- sample(rv$pop, input$n)\n      rv$means &lt;- c(rv$means, new_means, mean(rv$last_sample))\n    } \n    \n  })\n  \n  # reset plots\n  observeEvent(input$reset, {\n    rv$means &lt;- numeric()\n    rv$last_sample &lt;- numeric()\n  })\n  \n  # sample means plot\n  output$means &lt;- renderPlot({\n    req(rv$means)\n    req(rv$pop)\n    mm &lt;- round(mean(rv$means), digits = 3)\n    ms &lt;- round(sd(rv$means), digits = 3)\n    ggplot(data.frame(means = rv$means), aes(x = means)) +\n      geom_histogram(bins = 30, fill = \"firebrick2\",color = \"black\") +\n      theme_minimal() +\n      theme(axis.text.y = element_blank(),\n            axis.ticks.y = element_blank()) + \n      ylim(0, max(20,ceiling(length(rv$means)/5))) + \n      xlim(mean(rv$pop)-4*sd(rv$pop)/sqrt(input$n),mean(rv$pop)+4*sd(rv$pop)/sqrt(input$n))  +\n      labs(x=element_blank(),y=element_blank())\n      \n  })\n  \n  # one sample plot\n  output$lastSamplePlot &lt;- renderPlot({\n    req(rv$last_sample)\n    \n    df &lt;- data.frame(x = rv$last_sample)\n    \n    ggplot(df, aes(x = x)) +\n      geom_dotplot(fill = \"steelblue\") +\n      xlim(min(rv$pop), max(rv$pop)) +\n      theme_classic() +\n      labs(x = \"\", y = \"\") +\n      theme(axis.text.y = element_blank())\n  })\n  # summary table w/ mean and sd\n  output$summary &lt;- renderTable({\n    req(rv$pop)\n    req(rv$last_sample)\n    req(rv$means)\n  \n    data.frame(\n      Type = c(\"Population\", \"Last Sample\", \"Sample Means\"),\n      Mean = c(mean(rv$pop),\n             mean(rv$last_sample),\n             mean(rv$means)),\n      SD = c(sd(rv$pop),\n           sd(rv$last_sample),\n           if(length(rv$means) &gt; 1) sd(rv$means) else NA)\n  )\n})\n}\n\nshinyApp(ui, server)"
  },
  {
    "objectID": "posts/t_alt_shiny/t_alt_shiny.html",
    "href": "posts/t_alt_shiny/t_alt_shiny.html",
    "title": "T under null vs alt",
    "section": "",
    "text": "#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 600\n#| \n\nlibrary(shiny)\nlibrary(ggplot2)\n\nui &lt;- fluidPage(\n  titlePanel(\"t-test statistics under Null vs Alternative\"),\n  \n  sidebarLayout(\n    sidebarPanel(\n      sliderInput(\"delta\", \"True mean difference (δ):\",\n                  min = -2, max = 2, value = 0, step = 0.1),\n      numericInput(\"n\", \"Sample size:\", value = 30, min = 5),\n      numericInput(\"alpha\", \"Alpha:\", value = 0.05, min = 0.001, max = 1),\n      radioButtons(\"sides\", \"One vs. two-sided:\", \n                   choices = c(\"Two-sided\",\"One-sided (&lt;)\", \"One-sided (&gt;)\"),\n                   selected = \"Two-sided\")\n    ),\n    \n    mainPanel(\n      plotOutput(\"distPlot\")\n    )\n  )\n)\n\nserver &lt;- function(input, output) {\n  \n  simData &lt;- reactive({\n    n &lt;- input$n\n    nsim &lt;- 5000\n    delta &lt;- input$delta\n    \n    # Simulate alternative distribution\n    alt_t &lt;- replicate(nsim, {\n      x &lt;- rnorm(n, mean = delta, sd = 1)\n      t.test(x, mu = 0)$statistic\n    })\n    \n    # Critical values under null\n    if (input$sides == \"Two-sided\") {\n      crit_lo &lt;- qt(input$alpha/2, df = n-1)\n      crit_hi &lt;- qt(1 - input$alpha/2, df = n-1)\n \n    } else if (input$sides == \"One-sided (&lt;)\") {\n      crit_lo &lt;- qt(input$alpha, df = n-1)\n      crit_hi &lt;- Inf\n   \n    } else {\n      crit_lo &lt;- -Inf\n      crit_hi &lt;- qt(1 - input$alpha, df = n-1)\n     \n    }\n    \n    data.frame(alt_t = alt_t, n = n,\n               crit_lo = crit_lo, crit_hi = crit_hi)\n  })\n  \n  output$distPlot &lt;- renderPlot({\n    sims &lt;- simData()\n    n &lt;- sims$n[1]\n    mn &lt;- min(-3, min(sims$alt_t))\n    mx &lt;- max(3, max(sims$alt_t))\n    \n    subt &lt;- ifelse(input$delta == 0, \"Under null\", \n                   paste0(\"Under alternative with difference: \", input$delta))\n    ch = sims$crit_hi[1]\n    cl = sims$crit_lo[1]\n    \n    p &lt;- ggplot(sims, aes(x = alt_t)) +\n      geom_histogram(aes(y = ..density..), fill = \"lightblue\",\n                     binwidth = 0.2, alpha = 0.6, color = \"white\") +\n      stat_function(fun = function(x) dt(x, df = n - 1),\n                    color = \"blue\", size = 0.9, \n                    data = data.frame(alt_t = seq(mn, mx, by = .1))) +\n    \n      stat_function(fun = function(x) dt(x, df = n-1),\n                    xlim = c(ch, mx),\n                    geom = \"area\", fill = \"red\", alpha = 0.2,\n                    data = data.frame(alt_t = seq(mn, mx, by = .1))) +\n      stat_function(fun = function(x) dt(x, df = n-1),\n                    xlim = c(mn, cl),\n                    geom = \"area\", fill = \"red\", alpha = 0.2, \n                    data = data.frame(alt_t = seq(mn, mx, by = .1))) +\n      labs(title = \"t-statistic Distribution\",\n           subtitle = subt,\n           x = \"t statistic\",\n           y = \"Density\") +\n      coord_cartesian(xlim = c(mn, mx)) +\n      theme_minimal(base_size = 14)\n      \n      if(input$sides == \"Two-sided\"){ \n        p = p +       \n          geom_vline(xintercept = ch, color = \"red\") + \n         geom_vline(xintercept = cl, color = \"red\")\n      } else if(input$sides == \"One-sided (&lt;)\"){\n        p = p +       \n          geom_vline(xintercept = cl, color = \"red\")\n      } else {\n        p = p +       \n        geom_vline(xintercept = ch, color = \"red\")}\n      \n      p\n  })\n}\n\n\nshinyApp(ui = ui, server = server)"
  }
]